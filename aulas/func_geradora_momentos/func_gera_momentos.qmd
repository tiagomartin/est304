---
title: "Função Geradora de Momentos"
format: 
  revealjs:
    width: 1600
    height: 900
    footer: ""
    theme: quartomonothemer.scss
    slide-number: c/t
    show-slide-number: all
    preview-links: auto
    self-contained: false
    embed-resources: false
  beamer:          # Slides em PDF (LaTeX/Beamer)
    aspectratio: 169   # 16:9
    keep-tex: true     # opcional, guarda o .tex gerado
incremental: false
code-link: true
bibliography: references.bib
title-slide-attributes:
    data-background-image: /images/back.png
    data-background-size: cover
    data-background-opacity: "0.3"
execute:
  echo: true
  freeze: auto
---


## Momentos

Calculamos algumas características de uma variável aleatória $X$, tais como $E(X)$ e $Var(X)$, através da distribuição de probabilidade de $X$

. . .

Vimos que a variância pode ser expressa como uma **função da esperança** das duas primeiras potências de $X$, ou seja,

$$Var(X) = E(X^2) - \Big[E(X)\Big]^2$$


. . .



Outras características da distribuição de probabilidade de $X$ podem ser expressas por meio das esperanças das potências de $X$ como por exemplo **coeficientes de assimetria** e **curtose**.


## Momentos

::: {.callout-note title="Definição 01: Momentos"}
Seja $X$ uma variável aleatória. Então, o **k-ésimo momento** de $X$, denotado por $\mu'_k$ é definido como,

$$\mu'_k = E(X^k)$$

desde que essa quantidade exista. O **k-ésimo momento central** de uma variável aleatória $X$, denotado por $\mu_k$ é definido como,

$$\mu^k = E\Big[X - E(X)\Big]^k$$

sempre que essa quantidade existir.
:::



## Momentos

Note que,

- $E(X) = \mu'_1$

. . .


- $Var(X) = \mu_2 = \mu'_2 - [\mu'_1]^2$


. . .


- Para qualquer variável aleatória, $\mu_1 = 0$.




## Momentos


- Se $X$ é uma variável aleatória discreta,

$$\mu'_k = E(X^k) = \sum_{i=1}^{\infty} x_i^k p(x_i)$$

. . .


- Se $X$ é uma variável aleatória contínua,

$$\mu'_k = E(X^k) = \int_{-\infty}^{\infty} x_i^k f(x) \, dx$$



## Momentos


::: {.callout-note title="Exemplo 01: Momentos da distribuição Gamma"}
Encontre o $k$-ésimo momento de $X \sim Gamma(\alpha, \lambda)$.
:::

. . . 

**Solução:** Temos que, se $X \sim Gamma(\alpha, \lambda)$, então sua função densidade é dada por,


$$
f(x \mid \alpha,\lambda) =
\begin{cases}
\dfrac{\lambda e^{-\lambda x}(\lambda x)^{\alpha-1}}{\Gamma(\alpha)}, & x\ge 0,\\[6pt]
0, & x<0
\end{cases}
$$


## Momentos


Assim, 

$$
\begin{aligned}
E(X^k) &= \int_0^\infty x^k f(x\mid \alpha,\lambda)\, dx = \int_0^\infty x^k 
\frac{\lambda e^{-\lambda x}(\lambda x)^{\alpha-1}}
{\Gamma(\alpha)}\, dx \\[6pt]
 &= \int_0^\infty x^k 
\frac{\lambda e^{-\lambda x}\lambda^{\alpha-1} \, x^{\alpha-1}}
{\Gamma(\alpha)}\, dx = \frac{\lambda^\alpha}{\Gamma(\alpha)}
\int_0^\infty x^{\alpha+k-1} e^{-\lambda x}\, dx
\end{aligned}
$$


Note que a integral é quase a função gama, a não ser pelo termo $e^{-\lambda x}$. Seja então a seguinte mudança de variável,


$$u = \lambda  x \,\,\, \Rightarrow \,\,\, x = \dfrac{u}{\lambda}, \qquad dx = \dfrac{du}{\lambda}$$


## Momentos

Assim, 


$$
\begin{aligned}
E(X^k) &=  \dfrac{\lambda^\alpha}{\Gamma(\alpha)}
\int_0^\infty x^{\alpha+k-1} e^{-\lambda x}\, dx  = \dfrac{\lambda^\alpha}{\Gamma(\alpha)}
\int_0^\infty \Big(\dfrac{u}{\lambda}\Big)^{\alpha+k-1} e^{-u}\, \dfrac{du}{\lambda} \\[6pt] &= \dfrac{\lambda^\alpha}{\lambda ^{\alpha + k}\,\Gamma(\alpha)}
\int_0^\infty u^{\alpha+k-1} e^{-u}\, du = \dfrac{\lambda^\alpha \Gamma(\alpha + k)}{\lambda ^{\alpha + k}\,\Gamma(\alpha)} \\[6pt] &= \dfrac{\Gamma(\alpha+k)}{\Gamma(\alpha)\lambda^k}
\end{aligned}
$$


Mas,

$$
\Gamma(\alpha+k) = (\alpha+k-1)(\alpha+k-2)\cdots(\alpha+1)\alpha\Gamma(\alpha)
$$




## Momentos

De forma que, o $k$-ésimo momento de uma variável aleatória $X \sim Gamma (\alpha, \lambda)$ é dado por

$$
E(X^k)
=
\frac{\alpha(\alpha+1)\cdots(\alpha+k-1)}{\lambda^k}
$$




## Momentos


::: {.callout-note title="Exemplo 02: Momentos da distribuição Weibull"}
Encontre o $k$-ésimo momento de $X \sim Weibull(\alpha, \beta)$.
:::

. . . 

**Solução:** Temos que, se $X \sim Weibull(\alpha, \beta)$, então sua função densidade é dada por,

$$
f(x \mid \alpha,\beta)=
\begin{cases}
\dfrac{\beta}{\alpha}
\left(\dfrac{x}{\alpha}\right)^{\beta-1}
\exp\!\left[-\left(\dfrac{x}{\alpha}\right)^{\beta}\right], & x\ge 0,\\[6pt]
0, & x<0.
\end{cases}
$$



## Momentos


Assim, 

$$
\begin{aligned}
E(X^k) &= \int_0^\infty x^k 
\frac{\beta}{\alpha}
\left(\frac{x}{\alpha}\right)^{\beta-1}
\exp\!\left[-\left(\frac{x}{\alpha}\right)^{\beta}\right] dx 
\end{aligned}
$$

Mudança de variável:

$$
u = \left(\frac{x}{\alpha}\right)^{\beta}
\quad\Rightarrow\quad
x = \alpha u^{1/\beta},\qquad
dx = \alpha \frac{1}{\beta} u^{1/\beta - 1} du
$$


Além disso:

$$
x^k = \alpha^k u^{k/\beta},
\qquad
\left(\frac{x}{\alpha}\right)^{\beta-1}=u^{(\beta-1)/\beta},
\qquad
\exp\!\left[-\left(\frac{x}{\alpha}\right)^{\beta}\right]=e^{-u}
$$


## Momentos


logo, 

$$
\begin{aligned}
E(X^k) &= \int_0^\infty x^k 
\frac{\beta}{\alpha}
\left(\frac{x}{\alpha}\right)^{\beta-1}
\exp\!\left[-\left(\frac{x}{\alpha}\right)^{\beta}\right] dx \\[6pt] &= \int_0^\infty 
\alpha^k u^{k/\beta}\,
\frac{\beta}{\alpha}\,
u^{(\beta-1)/\beta}\,
e^{-u}\,
\alpha \frac{1}{\beta}u^{1/\beta -1}\,du \\[6pt] &= \alpha^k \int_0^\infty 
u^{\frac{k+\beta}{\beta}-1} 
e^{-u}\,du = \alpha^k\,\,\Gamma\!\left(1+\frac{k}{\beta}\right)
\end{aligned}
$$




## Função Geradora de Momentos


::: {.callout-note title="Definição 02: Função Geradora de Momentos"}
Seja $X$ uma variável aleatória qualquer. A **função geradora de momentos** (FGM) de $X$, denotada por $M_X$, é definida por

$$
M_X(t)=E(e^{tX}),
$$

para valores de $t$ em um intervalo contendo $0$ onde a experença exista.
:::



**Importante:** a função geradora de momentos é função de $t$. Para ela existir basta que exista $\varepsilon > 0$ tal que $E(e^{tX})$ esteja bem definida para qualquer $t \in (-\varepsilon, \varepsilon)$.



<!-- ## -->

<!-- ```{r, echo=FALSE} -->
<!-- #| label: fig-mgf-exp -->
<!-- #| fig-cap: "Função geradora de momentos da Exponencial(λ = 1). A região sombreada indica um intervalo aberto em torno de 0 onde a MGF é bem definida." -->
<!-- #| warning: false -->
<!-- #| message: false -->

<!-- library(ggplot2) -->

<!-- lambda <- 1 -->
<!-- eps    <- 0.5  # intervalo (-eps, eps) ao redor de 0 -->

<!-- # pontos apenas onde a MGF está bem definida: t < lambda -->
<!-- t  <- seq(-3, lambda - 0.01, length.out = 400) -->
<!-- mgf <- lambda / (lambda - t) -->

<!-- df <- data.frame(t = t, M = mgf) -->

<!-- ggplot(df, aes(x = t, y = M)) + -->
<!--   # faixa sombreada (-eps, eps) -->
<!--   geom_rect(aes(xmin = -eps, xmax = eps, ymin = -Inf, ymax = Inf), -->
<!--             fill = "grey80", alpha = 0.5, inherit.aes = FALSE) + -->
<!--   # curva da MGF -->
<!--   geom_line(size = 1) + -->
<!--   # assíntota em t = lambda -->
<!--   geom_vline(xintercept = lambda, linetype = "dashed") + -->
<!--   # linha vertical em t = 0 -->
<!--   geom_vline(xintercept = 0, linetype = "dotted") + -->
<!--   labs( -->
<!--     x = "t", -->
<!--     y = "M_X(t)", -->
<!--     title = "MGF da Exponencial com λ = 1", -->
<!--     subtitle = "Domínio: t < 1. A região sombreada é um intervalo (-ε, ε) em torno de 0." -->
<!--   ) + -->
<!--   coord_cartesian(ylim = c(0, 10)) + -->
<!--   theme_minimal(base_size = 14) -->
<!-- ``` -->





## Função Geradora de Momentos

Note que a **definição de função geradora de momentos** é feita independente do tipo de variável, mas a forma de encontrá-la depende se a variável for **discreta** ou **contínua**, isto é, 


- Se $X$ é discreta, 

$$M_X(t) = E(e^{tX}) = \sum_{\forall x \in S_X} \, e^{tx} p_X(x)$$



- Se $X$ é contínua, 

$$M_X(t) = E(e^{tX}) = \int_{-\infty}^{\infty} \, e^{tx} f_X(x) \, dx$$



## Função Geradora de Momentos

::: {.callout-note title="Teorema 01"}
Suponha que a função geradora de momentos de $X$ exista para $|t| < \varepsilon$, $\varepsilon > 0$. Então, $E(X^k)$ existe para $k = 1, 2, \cdots$ e temos:

$$E(X^k) = \dfrac{d^k}{dt^k} M_X(t) \Bigg|_{t=0}$$

ou seja, o $k$-ésimo momento de $X$ é igual à derivada de ordem $k$ de $M_X(t)$ avaliada em $t = 0$.
:::

**Demonstração:** Suponha que a função geradora de momentos de $X$ exista para todo $t$ tal que $|t|<\varepsilon$, com $\varepsilon>0$, isto é,

$$
M_X(t)=E(e^{tX})<\infty,\qquad |t|<\varepsilon.
$$

## Função Geradora de Momentos

Pela série de Maclaurin da função exponencial, para qualquer número real $y$ temos
$$
e^{y} = \sum_{n=0}^{\infty} \frac{y^n}{n!}
$$

Aplicando isso a $y=tX$, obtemos, para cada $t$ com $|t|<\varepsilon$,
$$
e^{tX} = \sum_{n=0}^{\infty} \frac{(tX)^n}{n!} = 1 + tX +\frac{(tX)^2}{2!} + \frac{(tX)^3}{3!} + \cdots
$$


Temos que $M_X(t)=E(e^{tX})$. Logo, admitindo ser válido permutar soma infinita e esperança, temos


## Função Geradora de Momentos

$$
M_X(t)
= E(e^{tX})
= E\left(\sum_{n=0}^{\infty} \frac{(tX)^n}{n!}\right)
= \sum_{n=0}^{\infty} \frac{t^n}{n!} E(X^n),
\qquad |t|<\varepsilon
$$


Portanto, $M_X(t)$ é dada, em uma vizinhança de $0$, por uma série de potência da forma
$$
M_X(t) = \sum_{n=0}^{\infty} a_n t^n,
\qquad \text{com } a_n = \frac{E(X^n)}{n!}
$$




## Função Geradora de Momentos


Da teoria de séries de potência, sabemos que, se
$$
M_X(t) = \sum_{n=0}^{\infty} a_n t^n,
$$
então a $k$-ésima derivada é
$$
M_X^{(k)}(t) = \sum_{n=k}^{\infty} a_n\, n(n-1)\cdots (n-k+1)\, t^{\,n-k}
$$


## Função Geradora de Momentos

Agora substituímos $t=0$:

Observe:

- Se $n > k$, aparece o fator $t^{n-k} = 0^{n-k} = 0$;  
- Então **todos** os termos com $n>k$ desaparecem;
- Só o termo com $n=k$ permanece.

O único termo sobrevivente é:

$$
a_k \, k(k-1)(k-2)\cdots 1 \, t^{\,0}
= a_k \, k!
$$

## Função Geradora de Momentos

Assim,

$$
M_X^{(k)}(0) = a_k\, k!
= \frac{E(X^k)}{k!}\,k!
= E(X^k)
$$


Logo,
$$
E(X^k) = \left.\frac{d^k}{dt^k} M_X(t)\right|_{t=0},
\qquad k=1,2,\dots
$$

o que mostra que o $k$-ésimo momento de $X$ é igual à derivada de ordem $k$ da função geradora de momentos avaliada em $t=0$.



## Função Geradora de Momentos



::: {#tip-FGM .callout-tip}
## Dica Importante!

Para qualquer variável aleatória $X$:

$$
M_X(0) = E(e^{0X}) = 1.
$$

Isso sempre deve ocorrer. Use esse fato para verificar se sua FGM está correta.
:::


## Função Geradora de Momentos

::: {.callout-note title="Exemplo 03: Distribuição de Bernoulli"}
Seja $X \sim Bernoulli(p)$. Encontre sua função geradora de momentos e a partir dela, encontre $E(X)$ e $\operatorname{Var}(X)$.
:::

. . . 

**Solução:** Por definição,

$$
M_X(t) = E(e^{tX}) = \sum_{x=0}^1 e^{tx} p^x(1-p)^{1-x}
$$

Como $X$ só assume os valores $0$ e $1$:

$$
M_X(t)
= e^{t\cdot 0} p^0(1-p)^{1-0} + e^{t\cdot 1} p^1(1-p)^{1-1}
= (1-p) + e^{t}p
= 1 - p +  e^{t} p
$$


## Função Geradora de Momentos

Portanto,

$$
\boxed{M_X(t) = 1 - p + p e^{t}, \quad t \in \mathbb{R}}
$$

Veja que pela @tip-FGM $M_X(0) = 1 - p + p e^{0} = 1 - p + p \times 1 = 1$.  Assim, 


- Primeira derivada de $M_X(t)$:

$$
M_X'(t) = \frac{d}{dt}\big(1 - p + p e^{t}\big)
= p e^{t}
$$

Avaliada em $t = 0$, temos $E(X) = M_X'(0) = p e^{0} = p$


## Função Geradora de Momentos


- Segunda derivada de $M_X(t)$:

$$
M_X''(t) = \frac{d}{dt}\big(M_X'(t)\big)
= \frac{d}{dt}(p e^{t}) = p e^{t}
$$

Avaliada em $t = 0$, temos $E(X) = M_X''(0) = p e^{0} = p$. 


Assim,


$$
\operatorname{Var}(X)
= M_X''(0) - [M_X'(0)]^2
= p - p^2
= p(1-p)
$$



## Função Geradora de Momentos

::: {.callout-note title="Exemplo 03: Distribuição Binomial"}
Seja $X \sim Binomial(n,p)$. Encontre sua função geradora de momentos e a partir dela, encontre $E(X)$ e $\operatorname{Var}(X)$.
:::

. . . 

**Solução:** Se $X \sim Binomial(n,p)$ então sua f.p. é dada por 

$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}, \qquad k=0,1,\dots,n
$$

Por definição,

$$
M_X(t) = E(e^{tX}) = \sum_{k=0}^{n} e^{tk} P(X = k)
= \sum_{k=0}^{n} e^{tk} \binom{n}{k} p^k (1-p)^{n-k}
$$


## Função Geradora de Momentos


Escrevendo $e^{tk} = (e^{t})^k$:

$$
M_X(t)
= \sum_{k=0}^{n} \binom{n}{k} (p e^t)^k (1-p)^{n-k}
$$

Temos que o binômio de Newton é dado por:

$$
(a+b)^n = \sum_{k=0}^{n} \binom{n}{k} a^k b^{n-k}
$$





## Função Geradora de Momentos


Assim, tomando $a = p e^{t}$ e $b = 1-p$:

$$
M_X(t) = (1-p + p e^{t})^n
$$

Portanto,

$$
\boxed{M_X(t) = (1-p + p e^{t})^n,\quad t\in\mathbb{R}}
$$


Veja que pela @tip-FGM $M_X(0) = (1-p + p e^{0})^n = (1 - p + p \times 1)^n = 1^n = 1$.   

## Função Geradora de Momentos

Sabemos que

$$
E(X) = M_X'(0)
$$

Derivada primeira em relação a $t$,

$$
M_X'(t) = \frac{d}{dt} (1-p + p e^{t})^n
= n(1-p + p e^{t})^{n-1} \cdot p e^{t}
$$

Logo,

$$
M_X'(0)
= n(1-p + p e^{0})^{n-1} \cdot p e^{0}
= n(1-p + p)^{n-1} p
= n p
$$



## Função Geradora de Momentos



Vamos agora encontrar a segunda derivada. Temos

$$
M_X'(t) = n p e^{t} (1-p + p e^{t})^{n-1}
$$

Aplicando a regra do produto:

$$
\begin{aligned}
M_X''(t)
&= \frac{d}{dt}\Big[ n p e^{t} (1-p + p e^{t})^{n-1} \Big] \\
&= n p e^{t} (n-1)(1-p + p e^{t})^{n-2} \cdot p e^{t}
 \;+\; n p e^{t} (1-p + p e^{t})^{n-1}
\end{aligned}
$$


## Função Geradora de Momentos

Avaliando em $t=0$:

- $e^{0}=1$  
- $1-p + p e^{0} = 1-p + p = 1$


Assim,

$$
\begin{aligned}
M_X''(0)
&= n p \cdot 1 \cdot (n-1) \cdot 1^{\,n-2} \cdot p \cdot 1
   \;+\; n p \cdot 1 \cdot 1^{\,n-1} \\[6pt]
&= n p (n-1)p + n p \\[6pt]
&= n p \big[(n-1)p + 1\big]
\end{aligned}
$$

## Função Geradora de Momentos

De forma que,

$$
\begin{aligned}
\operatorname{Var}(X)
&= M_X''(0) - [M_X'(0)]^2\\[6pt] 
&= n p \big[(n-1)p + 1\big] - (np)^2 \\[6pt]
&= n p \big[(n-1)p + 1 - n p\big] \\[6pt]
&= n p (1 - p)
\end{aligned}
$$





## Função Geradora de Momentos

::: {.callout-note title="Exemplo 04: Distribuição Geométrica"}
Seja $X \sim Geo(p)$. Encontre sua função geradora de momentos e a partir dela, encontre $E(X)$ e $\operatorname{Var}(X)$.
:::

. . . 

**Solução:**