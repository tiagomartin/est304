[
  {
    "objectID": "revisao.html",
    "href": "revisao.html",
    "title": "Revisão Probabilidade I",
    "section": "",
    "text": "Definição. Uma variável aleatória é uma função que associa a cada resultado do experimento um número real.\n\nDiscretas: suporte finito/enumerável (ex.: 0,1,2,…). Caracterizam-se por função de probabilidade \\(P(X=x_i) =p(x_i) =p_i\\). Uma função de probabilidade satisfaz \\(0 \\le p_i \\le 1\\) e \\(\\sum_{i=1} p_i = 1\\)\nContínuas: suporte intervalar. Caracterizam-se por densidade \\(f(x)\\) tal que \\(P(a&lt;X&lt; b)=\\int_a^b f(x)\\,dx\\). Uma função densidade satisfaz \\(f(x) \\ge 0\\) e \\(\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1\\).\n\nA função de distribuição é \\(F(x)=P(X\\le x)\\). Em ambos os casos, \\(F(x)\\) é não-decrescente e \\(\\lim_{x\\to-\\infty}F(x)=0\\), \\(\\lim_{x\\to\\infty}F(x)=1\\).",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#bernoulli-p",
    "href": "revisao.html#bernoulli-p",
    "title": "Revisão Probabilidade I",
    "section": "3.1 Bernoulli \\((p)\\)",
    "text": "3.1 Bernoulli \\((p)\\)\nInterpretação: 1 sucesso/fracasso em único ensaio.\n\n\n\n\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(x\\in\\{0,1\\}\\)\n\n\nParâmetro\n\\(0&lt;p&lt;1\\)\n\n\nFunção de probabilidade \\(p(x)\\)\n\\(p^x(1-p)^{1-x}\\)\n\n\nDistribuição \\(F(x)\\)\n\\(0\\) se \\(x&lt;0\\); \\(1-p\\) se \\(0\\le x&lt;1\\); \\(1\\) se \\(x\\ge1\\)\n\n\nEsperança \\(E[X]\\)\n\\(p\\)\n\n\nVariância \\(Var(X)\\)\n\\(p(1-p)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nA variável Bernoulli assume valores \\(0\\) e \\(1\\), com \\(P(X=1)=p\\) e \\(P(X=0)=1-p\\).\nEsperança\n\\[\nE(X)=0(1-p)+1\\cdot p = p.\n\\]\nSegundo momento\n\\[\nE(X^2)=0^2(1-p)+1^2\\cdot p = p.\n\\]\nVariância\n\\[\n\\mathrm{Var}(X)=E(X^2)-[E(X)]^2\n= p - p^2 = p(1-p).\n\\]\n\n\n\nExemplo: Um alarme dispara corretamente com probabilidade \\(p = 0{,}92\\). Seja \\(X\\) = 1 se o alarme dispara corretamente, 0 caso contrário.\n\nCalcule \\(P(X=1)\\) e \\(P(X=0)\\).\n\nCalcule \\(E[X]\\) e interprete.\n\nSolução:\n\n\\(P(X=1)=0{,}92\\)\n\n\\(P(X=0)=0{,}08\\)\n\n\\[\nE[X]=p=0{,}92\n\\]\nInterpretação: o alarme funciona corretamente em 92% dos acionamentos.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#binomial-np",
    "href": "revisao.html#binomial-np",
    "title": "Revisão Probabilidade I",
    "section": "3.2 Binomial \\((n,p)\\)",
    "text": "3.2 Binomial \\((n,p)\\)\nInterpretação: número de sucessos em \\(n\\) ensaios independentes, prob. \\(p\\).\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(k=0,1,\\dots,n\\)\n\n\nParâmetros\n\\(n\\in\\mathbb{N}\\), \\(0&lt;p&lt;1\\)\n\n\n\\(p(k)\\)\n\\(\\binom{n}{k}p^k(1-p)^{n-k}\\)\n\n\n\\(F(k)\\)\n\\(\\sum_{j=0}^{k}\\binom{n}{j}p^j(1-p)^{n-j}\\)\n\n\n\\(E[X]\\)\n\\(np\\)\n\n\n\\(Var(X)\\)\n\\(np(1-p)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere \\(X \\sim \\text{Binomial}(n,p)\\), isto é, \\[\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\quad k = 0,1,\\dots,n.\n\\]\nVamos demonstrar:\n\n\\(E(X) = np\\)\n\\(\\mathrm{Var}(X) = np(1-p)\\)\n\nusando\n\\[\nE(X) = \\sum_{k=0}^n k\\,P(X=k),\n\\qquad\n\\mathrm{Var}(X) = E(X^2) - [E(X)]^2.\n\\]\n\nCálculo de E(X)\nPela definição: \\[\nE(X) = \\sum_{k=0}^n k\\,P(X=k)\n     = \\sum_{k=0}^n k \\binom{n}{k} p^k (1-p)^{n-k}.\n\\]\nNote que o termo com \\(k=0\\) é zero (pois tem um fator \\(k\\)), então podemos começar em \\(k=1\\): \\[\nE(X) = \\sum_{k=1}^n k \\binom{n}{k} p^k (1-p)^{n-k}.\n\\]\nUsamos agora a identidade combinatória \\[\nk \\binom{n}{k} = n \\binom{n-1}{k-1}.\n\\]\nSubstituindo: \\[\nE(X)= \\sum_{k=1}^n n \\binom{n-1}{k-1} p^k (1-p)^{n-k}.\n\\]\nColocamos \\(n\\) em evidência: \\[\nE(X)= n \\sum_{k=1}^n \\binom{n-1}{k-1} p^k (1-p)^{n-k}.\n\\]\nAgora fazemos a mudança de índice \\(j = k-1\\):\n\nquando \\(k = 1\\), \\(j = 0\\);\n\nquando \\(k = n\\), \\(j = n-1\\);\n\n\\(k = j + 1\\).\n\nEntão: \\[\nE(X)= n \\sum_{j=0}^{n-1} \\binom{n-1}{j} p^{j+1} (1-p)^{n-(j+1)}.\n\\]\nReorganizando as potências: \\[\np^{j+1} = p \\cdot p^j,\\qquad n-(j+1) = (n-1)-j,\n\\] obtemos: \\[\nE(X)= n p \\sum_{j=0}^{n-1} \\binom{n-1}{j} p^{j} (1-p)^{(n-1)-j}.\n\\]\nRepare que a soma \\[\n\\sum_{j=0}^{n-1} \\binom{n-1}{j} p^{j} (1-p)^{(n-1)-j}\n\\] é exatamente o desenvolvimento binomial de \\[\n(p + (1-p))^{n-1} = 1^{n-1} = 1.\n\\]\nPortanto: \\[\nE(X) = n p \\cdot 1 = np.\n\\]\n\nCálculo de \\(E(X^2)\\)\nPela definição: \\[\nE(X^2) = \\sum_{k=0}^n k^2\\,P(X=k)\n       = \\sum_{k=0}^n k^2 \\binom{n}{k} p^k (1-p)^{n-k}.\n\\]\nTruque clássico: escrever \\[\nk^2 = k(k-1) + k.\n\\]\nEntão: \\[\n\\begin{aligned}\nE(X^2)\n&= \\sum_{k=0}^n \\big[ k(k-1) + k \\big]\\binom{n}{k} p^k (1-p)^{\\,n-k} \\\\[6pt]\n&= \\sum_{k=0}^n k(k-1)\\binom{n}{k} p^k (1-p)^{\\,n-k}\n\\;+\\; \\sum_{k=0}^n k\\binom{n}{k} p^k (1-p)^{\\,n-k}.\n\\end{aligned}\n\\]\nChamemos:\n\n\\(A = \\sum_{k=0}^n k(k-1)\\binom{n}{k} p^k (1-p)^{n-k}\\)\n\n\\(B = \\sum_{k=0}^n k\\binom{n}{k} p^k (1-p)^{n-k}\\)\n\nLogo, \\(E(X^2) = A + B\\).\nMas repare que \\(B = E(X)\\), que já calculamos: \\[\nB = E(X) = np.\n\\]\nFalta calcular \\(A\\).\n\nCálculo de \\(A\\)\nUsamos agora a identidade: \\[\nk(k-1)\\binom{n}{k} = n(n-1)\\binom{n-2}{k-2}.\n\\]\nEntão: \\[\nA = \\sum_{k=0}^n k(k-1)\\binom{n}{k} p^k (1-p)^{n-k}\n  = \\sum_{k=2}^n n(n-1)\\binom{n-2}{k-2} p^k (1-p)^{n-k}.\n\\]\nPodemos tirar \\(n(n-1)\\) em evidência: \\[\nA = n(n-1)\\sum_{k=2}^n \\binom{n-2}{k-2} p^k (1-p)^{n-k}.\n\\]\nAgora faça a mudança de índice \\(j = k-2\\):\n\nquando \\(k = 2\\), \\(j = 0\\);\n\nquando \\(k = n\\), \\(j = n-2\\);\n\n\\(k = j + 2\\).\n\nSubstituindo: \\[\nA = n(n-1)\\sum_{j=0}^{n-2} \\binom{n-2}{j} p^{j+2} (1-p)^{n-(j+2)}.\n\\]\nReorganizando as potências: \\[\np^{j+2} = p^2 p^j,\n\\qquad\nn-(j+2) = (n-2)-j,\n\\] temos: \\[\nA = n(n-1)p^2 \\sum_{j=0}^{n-2} \\binom{n-2}{j} p^{j} (1-p)^{(n-2)-j}.\n\\]\nA soma é novamente um binômio: \\[\n\\sum_{j=0}^{n-2} \\binom{n-2}{j} p^{j} (1-p)^{(n-2)-j}\n= (p + (1-p))^{n-2} = 1^{n-2} = 1.\n\\]\nPortanto: \\[\nA = n(n-1)p^2.\n\\]\n\nConclusão para \\(E(X^2)\\)\nLembrando que:\n\n\\(A = n(n-1)p^2\\)\n\n\\(B = np\\)\n\ntemos: \\[\nE(X^2) = A + B = n(n-1)p^2 + np.\n\\]\n\nCálculo de \\(\\mathrm{Var}(X)\\)\nAgora usamos: \\[\n\\mathrm{Var}(X) = E(X^2) - [E(X)]^2.\n\\]\nJá temos:\n\n\\(E(X^2) = n(n-1)p^2 + np\\)\n\\(E(X) = np\\)\n\nLogo: \\[\n\\mathrm{Var}(X)\n= \\big(n(n-1)p^2 + np\\big) - (np)^2.\n\\]\nAgora expandimos: \\[\n(np)^2 = n^2 p^2,\n\\] então: \\[\n\\mathrm{Var}(X)\n= n(n-1)p^2 + np - n^2 p^2.\n\\]\nNote que \\[\nn(n-1)p^2 = (n^2 - n)p^2,\n\\] então: \\[\n\\mathrm{Var}(X)\n= (n^2 - n)p^2 + np - n^2 p^2\n= -n p^2 + np\n= n p (1-p).\n\\]\n\nLogo,\nPara \\(X \\sim \\text{Binomial}(n,p)\\), \\[\nE(X) = np,\n\\qquad\n\\mathrm{Var}(X) = np(1-p).\n\\]\n\n\n\nExemplo: A probabilidade de um cliente comprar um produto é \\(p=0{,}3\\). Em um dia, 20 clientes entram na loja. Seja \\(X\\) = número de compras.\n\nCalcule \\(P(X=8)\\).\n\nCalcule \\(E[X]\\).\n\nSolução:\n\n\\[\nP(X=8)=\\binom{20}{8}(0{,}3)^8(0{,}7)^{12}\\approx 0{,}053\n\\]\n\\[\nE[X]=np=20\\cdot 0{,}3 = 6\n\\]",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#geométrica-p",
    "href": "revisao.html#geométrica-p",
    "title": "Revisão Probabilidade I",
    "section": "3.3 Geométrica \\((p)\\)",
    "text": "3.3 Geométrica \\((p)\\)\nConvenção usada: \\(X\\) = número de ensaios até o 1º sucesso (apoio \\(1,2,\\dots\\)).\n\n\n\nItem\nExpressão\n\n\n\n\n\\(p(k)\\)\n\\(p(1-p)^{k-1}\\)\n\n\n\\(F(k)\\)\n\\(1-(1-p)^k\\)\n\n\n\\(E[X]\\)\n\\(1/p\\)\n\n\n\\(Var(X)\\)\n\\((1-p)/p^2\\)\n\n\nPropriedade\nSem memória: \\(P(X&gt;s+t\\mid X&gt;t)=P(X&gt;s)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere \\(X \\sim \\text{Geom}(p)\\) com suporte \\(k=1,2,\\dots\\), isto é, \\[\nP(X = k) = p(1-p)^{k-1}, \\quad k = 1,2,\\dots,\\quad 0&lt;p&lt;1.\n\\]\nVamos demonstrar que \\[\nE(X) = \\frac{1}{p}\n\\qquad \\text{e} \\qquad\n\\mathrm{Var}(X) = \\frac{1-p}{p^2},\n\\] usando as definições \\[\nE(X) = \\sum_{k=1}^{\\infty} k\\,P(X=k),\n\\qquad\n\\mathrm{Var}(X) = E(X^2) - [E(X)]^2.\n\\]\n\nCálculo de \\(E(X)\\)\nPela definição de esperança: \\[\nE(X) = \\sum_{k=1}^{\\infty} k\\,P(X=k)\n     = \\sum_{k=1}^{\\infty} k\\,p(1-p)^{k-1}.\n\\]\nColocamos o fator \\(p\\) em evidência: \\[\nE(X) = p \\sum_{k=1}^{\\infty} k (1-p)^{k-1}.\n\\]\nPara simplificar, definimos \\[\nr = 1-p.\n\\]\nNote que \\(0&lt;r&lt;1\\). Então a soma fica \\[\nE(X) = p \\sum_{k=1}^{\\infty} k r^{k-1}.\n\\]\nAgora usamos uma identidade clássica de séries: - Sabemos que, para \\(|r|&lt;1\\), \\[\n  \\sum_{k=0}^{\\infty} r^k = \\frac{1}{1-r}.\n  \\]\nDerivando em relação a \\(r\\): \\[\n\\frac{d}{dr}\\left(\\sum_{k=0}^{\\infty} r^k\\right)\n= \\sum_{k=0}^{\\infty} k r^{k-1}\n= \\frac{d}{dr}\\left(\\frac{1}{1-r}\\right)\n= \\frac{1}{(1-r)^2}.\n\\]\nNote que o termo \\(k=0\\) é zero, então \\[\n\\sum_{k=1}^{\\infty} k r^{k-1} = \\frac{1}{(1-r)^2}.\n\\]\nVoltando à expressão de \\(E(X)\\): \\[\nE(X) = p \\cdot \\frac{1}{(1-r)^2}.\n\\]\nLembrando que \\(r = 1-p\\), então \\[\n1-r = 1 - (1-p) = p.\n\\]\nLogo: \\[\nE(X) = p \\cdot \\frac{1}{p^2} = \\frac{1}{p}.\n\\]\n\nCálculo de \\(E(X^2)\\)\nPela definição: \\[\nE(X^2) = \\sum_{k=1}^{\\infty} k^2 P(X=k)\n       = \\sum_{k=1}^{\\infty} k^2 p(1-p)^{k-1}\n       = p \\sum_{k=1}^{\\infty} k^2 r^{k-1},\n\\] com \\(r = 1-p\\).\nEntão precisamos do valor de \\[\n\\sum_{k=1}^{\\infty} k^2 r^{k-1}.\n\\]\nUsaremos de novo a série geométrica e suas derivadas.\nJá sabemos: \\[\n\\sum_{k=0}^{\\infty} r^k = \\frac{1}{1-r}.\n\\]\n\nPrimeira derivada: \\[\n\\sum_{k=1}^{\\infty} k r^{k-1} = \\frac{1}{(1-r)^2}.\n\\]\nMultiplicando por \\(r\\): \\[\nr \\sum_{k=1}^{\\infty} k r^{k-1}\n= \\sum_{k=1}^{\\infty} k r^{k}\n= \\frac{r}{(1-r)^2}.\n\\]\nDerivando novamente: Vamos derivar a expressão \\[\n\\sum_{k=1}^{\\infty} k r^{k}\n\\] em relação a \\(r\\): \\[\n\\frac{d}{dr}\\left(\\sum_{k=1}^{\\infty} k r^{k}\\right)\n= \\sum_{k=1}^{\\infty} k^2 r^{k-1}.\n\\]\nAgora derivamos o outro lado: \\[\n\\frac{d}{dr}\\left(\\frac{r}{(1-r)^2}\\right)\n= \\frac{(1-r)^2 - r\\cdot 2(1-r)(-1)}{(1-r)^4}.\n\\]\nSimplificando o numerador: \\[\n(1-r)^2 + 2r(1-r)\n= (1 - 2r + r^2) + (2r - 2r^2)\n= 1 - r^2\n= (1-r)(1+r).\n\\]\nAssim, \\[\n\\frac{d}{dr}\\left(\\frac{r}{(1-r)^2}\\right)\n= \\frac{(1-r)(1+r)}{(1-r)^4}\n= \\frac{1+r}{(1-r)^3}.\n\\]\n\nPortanto, \\[\n\\sum_{k=1}^{\\infty} k^2 r^{k-1}\n= \\frac{1+r}{(1-r)^3}.\n\\]\nVoltando para \\(E(X^2)\\): \\[\nE(X^2) = p \\cdot \\frac{1+r}{(1-r)^3}.\n\\]\nSubstituímos \\(r=1-p\\) e \\(1-r=p\\):\n\n\\(1+r = 1 + (1-p) = 2-p\\)\n\n\\((1-r)^3 = p^3\\)\n\nEntão: \\[\nE(X^2)= p \\cdot \\frac{2-p}{p^3}\n      = \\frac{2-p}{p^2}.\n\\]\n\nCálculo de \\(\\mathrm{Var}(X)\\)\nAgora usamos \\[\n\\mathrm{Var}(X) = E(X^2) - [E(X)]^2.\n\\]\nJá encontramos:\n\n\\(E(X) = \\dfrac{1}{p}\\)\n\\(E(X^2) = \\dfrac{2-p}{p^2}\\)\n\nLogo: \\[\n\\mathrm{Var}(X)\n= \\frac{2-p}{p^2} - \\left(\\frac{1}{p}\\right)^2\n= \\frac{2-p}{p^2} - \\frac{1}{p^2}\n= \\frac{1-p}{p^2}.\n\\]\n\nLogo,\nPara \\(X \\sim \\text{Geom}(p)\\), com \\(P(X=k)=p(1-p)^{k-1}\\), \\(k=1,2,\\dots\\), temos:\n\\[\nE(X) = \\frac{1}{p},\n\\qquad\n\\mathrm{Var}(X) = \\frac{1-p}{p^2}.\n\\]\n\n\n\nExemplo: Uma chamada telefônica é atendida com probabilidade \\(p = 0{,}15\\). Seja \\(X\\) = número de tentativas até o primeiro atendimento.\n\nCalcule \\(P(X=4)\\).\n\nCalcule \\(P(X&gt;4)\\).\n\nDetermine \\(E[X]\\).\n\nSolução:\n\n\\[\nP(X=4)=0{,}15(0{,}85)^3 \\approx 0{,}092\n\\]\n\\[\nP(X&gt;4)=0{,}85^4 \\approx 0{,}522\n\\]\n\\[\nE[X]=\\frac{1}{0{,}15}\\approx 6{,}67\n\\]",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#pascal-binomial-negativa-rp",
    "href": "revisao.html#pascal-binomial-negativa-rp",
    "title": "Revisão Probabilidade I",
    "section": "3.4 Pascal / Binomial Negativa \\((r,p)\\)",
    "text": "3.4 Pascal / Binomial Negativa \\((r,p)\\)\nConvenção usada: \\(Y\\) = número de falhas antes do \\(r\\)-ésimo sucesso (apoio \\(0,1,\\dots\\)).\n\n\n\nItem\nExpressão\n\n\n\n\n\\(p(k)\\)\n\\(\\binom{k+r-1}{k}(1-p)^k p^r\\)\n\n\n\\(F(k)\\)\n\\(\\sum_{j=0}^{k}\\binom{j+r-1}{j}(1-p)^j p^r\\)\n\n\n\\(E[Y]\\)\n\\(r(1-p)/p\\)\n\n\n\\(Var(Y)\\)\n\\(r(1-p)/p^2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nVamos usar a seguinte definição:\n\nEm cada tentativa, ocorre sucesso com probabilidade \\(p\\) e falha com probabilidade \\(1-p\\), independentemente.\n\\(X\\) é o número de falhas até o \\(r\\)-ésimo sucesso.\nDizemos então que \\(X \\sim \\text{Binomial Negativa}(r,p)\\), com \\(r \\in \\mathbb{N}\\).\n\nA função de probabilidade é \\[\nP(X = k)\n= \\binom{k + r - 1}{k} (1-p)^k p^r,\n\\quad k = 0,1,2,\\dots\n\\]\nNosso objetivo é demonstrar que \\[\nE(X) = \\frac{r(1-p)}{p}\n\\qquad \\text{e} \\qquad\n\\mathrm{Var}(X) = \\frac{r(1-p)}{p^2}.\n\\]\nEm vez de somar diretamente a série da f.p., vamos usar uma interpretação construída a partir da Geométrica, que já sabemos tratar.\n\nLigação com a distribuição geométrica\nConsidere o processo de Bernoulli (tentativas independentes com probabilidade de sucesso \\(p\\)).\nEntre sucessos consecutivos, o número de falhas que ocorre é sempre do mesmo tipo:\n\nAntes do 1º sucesso, temos um certo número de falhas \\(Y_1\\).\nEntre o 1º e o 2º sucesso, temos um número de falhas \\(Y_2\\).\n…\nEntre o (r-1)º e o r-ésimo sucesso, temos um número de falhas \\(Y_r\\).\n\nEssas quantidades \\(Y_1, Y_2, \\dots, Y_r\\) são independentes e têm mesma distribuição.\nAlém disso, o número total de falhas até o \\(r\\)-ésimo sucesso é \\[\nX = Y_1 + Y_2 + \\cdots + Y_r.\n\\]\nVamos então:\n\nDeterminar a distribuição de cada \\(Y_i\\).\nCalcular \\(E(Y_i)\\) e \\(\\mathrm{Var}(Y_i)\\).\nSomar para obter \\(E(X)\\) e \\(\\mathrm{Var}(X)\\).\n\n\nDistribuição de \\(Y_i\\) (número de falhas entre dois sucessos)\nEntre dois sucessos consecutivos, o experimento funciona assim:\n\nObservamos uma sequência de falhas, todas com probabilidade \\((1-p)\\),\n\nseguida de um sucesso, com probabilidade \\(p\\).\n\nSe \\(Y_i = k\\), isso significa: falha, falha, …, falha (\\(k\\) vezes), depois um sucesso.\nLogo \\[\nP(Y_i = k) = (1-p)^k p, \\quad k = 0,1,2,\\dots\n\\]\nEssa é uma Geométrica com suporte em \\(\\{0,1,2,\\dots\\}\\), às vezes chamada de geométrica “deslocada” ou “número de falhas antes do sucesso”.\nSabemos que:\n\nSe \\(G\\) tem \\(P(G=k)=p(1-p)^{k-1}\\), \\(k=1,2,\\dots\\), então \\(E(G)=\\frac{1}{p}\\) e \\(\\mathrm{Var}(G)=\\frac{1-p}{p^2}\\).\nSe definimos \\(Y = G - 1\\), então \\(Y\\) tem suporte \\(\\{0,1,2,\\dots\\}\\), e \\[\nE(Y) = E(G-1) = E(G) - 1 = \\frac{1}{p} - 1 = \\frac{1-p}{p},\n\\] \\[\n\\mathrm{Var}(Y) = \\mathrm{Var}(G-1) = \\mathrm{Var}(G) = \\frac{1-p}{p^2}.\n\\]\n\nPortanto, cada \\(Y_i\\) tem:\n\\[\nE(Y_i)=\\frac{1-p}{p}, \\qquad\n\\mathrm{Var}(Y_i)=\\frac{1-p}{p^2}.\n\\]\nE os \\(Y_i\\) são i.i.d. (independentes e identicamente distribuídos).\n\nExpressão de \\(X\\) como soma de geométricas\nRelembrando: \\[\nX = Y_1 + Y_2 + \\cdots + Y_r,\n\\] com \\(Y_i\\) independentes e com a mesma distribuição.\nVamos usar:\n\nLinearidade da esperança: \\[\nE(X) = E(Y_1) + \\cdots + E(Y_r),\n\\]\nVariância da soma de independentes: \\[\n\\mathrm{Var}(X)\n= \\mathrm{Var}(Y_1) + \\cdots + \\mathrm{Var}(Y_r),\n\\] pois não há termos de covariância (independência \\(\\Rightarrow\\) covariância zero).\n\n\nCálculo de \\(E(X)\\)\nPela linearidade da esperança: \\[\nE(X)\n= E(Y_1 + \\cdots + Y_r)\n= E(Y_1) + \\cdots + E(Y_r).\n\\]\nComo todos têm a mesma esperança: \\[\nE(X)\n= r \\cdot E(Y_1).\n\\]\nUsando o valor encontrado para a geométrica: \\[\nE(Y_1) = \\frac{1-p}{p},\n\\] então: \\[\nE(X)\n= r \\cdot \\frac{1-p}{p}\n= \\frac{r(1-p)}{p}.\n\\]\nEste é o valor esperado da Binomial Negativa (número de falhas até o \\(r\\)-ésimo sucesso).\n\nCálculo de \\(\\mathrm{Var}(X)\\)\nDa variância da soma de variáveis independentes: \\[\n\\mathrm{Var}(X)\n= \\mathrm{Var}(Y_1 + \\cdots + Y_r)\n= \\mathrm{Var}(Y_1) + \\cdots + \\mathrm{Var}(Y_r),\n\\] pois \\(\\mathrm{Cov}(Y_i, Y_j)=0\\) para \\(i\\ne j\\).\nComo todas têm a mesma variância: \\[\n\\mathrm{Var}(X)\n= r \\cdot \\mathrm{Var}(Y_1).\n\\]\nUsando o valor da geométrica: \\[\n\\mathrm{Var}(Y_1) = \\frac{1-p}{p^2},\n\\] obtemos: \\[\n\\mathrm{Var}(X)\n= r \\cdot \\frac{1-p}{p^2}\n= \\frac{r(1-p)}{p^2}.\n\\]\n\nPortanto, para \\(X \\sim \\text{Binomial Negativa}(r,p)\\) (número de falhas até o \\(r\\)-ésimo sucesso), temos:\n\\[\nE(X) = \\frac{r(1-p)}{p},\n\\qquad\n\\mathrm{Var}(X) = \\frac{r(1-p)}{p^2}.\n\\]\n\n\n\nExemplo: Um pesquisador precisa de 4 pessoas que aceitem responder um questionário. Cada tentativa tem probabilidade \\(p=0{,}25\\) de sucesso. Seja \\(Y\\) = número de recusas até o 4º sucesso.\n\nCalcule \\(P(Y=6)\\).\n\nCalcule \\(E[Y]\\).\n\nSolução:\n\n\\[\nP(Y=6)=\\binom{9}{6}(0{,}75)^6 (0{,}25)^4 \\approx 0{,}050\n\\]\n\\[\nE[Y]=\\frac{4(1-0{,}25)}{0{,}25}=12\n\\]",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#hipergeométrica-nkn",
    "href": "revisao.html#hipergeométrica-nkn",
    "title": "Revisão Probabilidade I",
    "section": "3.5 Hipergeométrica \\((N,K,n)\\)",
    "text": "3.5 Hipergeométrica \\((N,K,n)\\)\nAmostragem sem reposição. \\(N\\) total, \\(K\\) sucessos na população, amostra \\(n\\).\n\n\n\n\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(k=\\max(0,n-(N-K)),\\dots,\\min(n,K)\\)\n\n\n\\(p(k)\\)\n\\(\\dfrac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\n\n\n\\(E[X]\\)\n\\(n\\,\\dfrac{K}{N}\\)\n\n\n\\(Var(X)\\)\n\\(n\\,\\dfrac{K}{N}\\!\\left(1-\\dfrac{K}{N}\\right)\\!\\dfrac{N-n}{N-1}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere:\n\nUma população finita com \\(N\\) elementos.\n\\(K\\) desses \\(N\\) elementos são “sucessos” (por exemplo, peças defeituosas).\nOs demais \\(N-K\\) são “fracassos”.\nRetiramos uma amostra sem reposição de tamanho \\(n\\).\n\nSeja \\(X\\) o número de sucessos na amostra. Dizemos que \\[\nX \\sim \\text{Hipergeométrica}(N, K, n).\n\\]\nA função de probabilidade é \\[\nP(X = k)\n= \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}},\n\\quad k = 0,1,\\dots,\\min(K,n).\n\\]\nQueremos demonstrar que: \\[\nE(X) = n \\frac{K}{N},\n\\qquad\n\\mathrm{Var}(X) = n\\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\\frac{N-n}{N-1}.\n\\]\nEm vez de somar diretamente a f.p., vamos usar uma abordagem com variáveis indicadoras.\n\nRepresentando \\(X\\) como soma de indicadores\nImagine que a amostra de tamanho \\(n\\) é extraída em ordem: 1ª retirada, 2ª retirada, …, \\(n\\)-ésima retirada.\nDefina, para cada \\(i=1,\\dots,n\\): \\[\nY_i =\n\\begin{cases}\n1, & \\text{se o $i$-ésimo elemento sorteado é sucesso;}\\\\[4pt]\n0, & \\text{caso contrário.}\n\\end{cases}\n\\]\nEntão o número total de sucessos na amostra é \\[\nX = Y_1 + Y_2 + \\cdots + Y_n.\n\\]\nIsso é intuitivo: cada \\(Y_i\\) indica se houve sucesso naquela retirada, e a soma conta quantos sucessos houve ao todo.\n\nEsperança de \\(X\\) via linearidade\nUsando linearidade da esperança: \\[\nE(X) = E(Y_1 + Y_2 + \\cdots + Y_n)\n     = E(Y_1) + E(Y_2) + \\cdots + E(Y_n).\n\\]\nComo a população é homogênea e a amostragem é simétrica, todas as retiradas têm a mesma probabilidade de ser sucesso. Ou seja: \\[\nE(Y_1)=E(Y_2)=\\cdots=E(Y_n).\n\\]\nBasta, então, calcular \\(E(Y_1)\\).\n\nCálculo de \\(E(Y_i)\\)\nPor definição, \\[\nE(Y_i) = P(Y_i=1).\n\\]\nMas \\(Y_i=1\\) significa que, na \\(i\\)-ésima retirada, escolhemos um elemento “sucesso”.\nComo as retiradas são todas igualmente prováveis (sem viés) e a população tem \\(K\\) sucessos em \\(N\\) elementos, temos: \\[\nP(Y_i=1) = \\frac{K}{N},\n\\quad \\text{para qualquer } i.\n\\]\nLogo, \\[\nE(Y_i) = \\frac{K}{N}.\n\\]\nPortanto, \\[\nE(X)\n= \\sum_{i=1}^n E(Y_i)\n= n \\cdot \\frac{K}{N}.\n\\]\nIsso demonstra: \\[\nE(X) = n \\frac{K}{N}.\n\\]\n\nVariância de \\(X\\):\nQueremos agora \\[\n\\mathrm{Var}(X) = \\mathrm{Var}(Y_1+\\cdots+Y_n).\n\\]\nLembre que, em geral, para variáveis quaisquer: \\[\n\\mathrm{Var}\\left(\\sum_{i=1}^n Y_i\\right)\n= \\sum_{i=1}^n \\mathrm{Var}(Y_i) + 2\\sum_{1\\le i&lt;j\\le n} \\mathrm{Cov}(Y_i, Y_j).\n\\]\nAs \\(Y_i\\) não são independentes (pois a amostragem é sem reposição), então precisamos levar em conta as covariâncias.\nPela simetria do problema:\n\nTodas as variâncias \\(\\mathrm{Var}(Y_i)\\) são iguais.\nTodas as covariâncias \\(\\mathrm{Cov}(Y_i,Y_j)\\) com \\(i \\ne j\\) são iguais.\n\nEntão podemos escrever: \\[\n\\mathrm{Var}(X)\n= n\\,\\mathrm{Var}(Y_1) + 2\\binom{n}{2}\\mathrm{Cov}(Y_1,Y_2)\n= n\\,\\mathrm{Var}(Y_1) + n(n-1)\\,\\mathrm{Cov}(Y_1,Y_2).\n\\]\nAssim, precisamos calcular:\n\n\\(\\mathrm{Var}(Y_1)\\)\n\n\\(\\mathrm{Cov}(Y_1,Y_2)\\)\n\n\nCálculo de \\(\\mathrm{Var}(Y_1)\\)\nComo \\(Y_1\\) é uma variável indicadora (0 ou 1) com \\[\nP(Y_1=1) = \\frac{K}{N},\n\\quad\nP(Y_1=0) = 1 - \\frac{K}{N},\n\\] temos: \\[\nE(Y_1) = \\frac{K}{N},\\qquad\nE(Y_1^2) = E(Y_1) = \\frac{K}{N}\n\\] (pois \\(Y_1^2 = Y_1\\) quando \\(Y_1 \\in \\{0,1\\}\\)).\nLogo: \\[\n\\mathrm{Var}(Y_1) = E(Y_1^2) - [E(Y_1)]^2\n= \\frac{K}{N} - \\left(\\frac{K}{N}\\right)^2\n= \\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\n= \\frac{K}{N}\\cdot\\frac{N-K}{N}\n= \\frac{K(N-K)}{N^2}.\n\\]\n\nCálculo de \\(\\mathrm{Cov}(Y_1,Y_2)\\)\nPor definição: \\[\n\\mathrm{Cov}(Y_1,Y_2)\n= E(Y_1Y_2) - E(Y_1)E(Y_2).\n\\]\nJá sabemos que \\[\nE(Y_1) = E(Y_2) = \\frac{K}{N}.\n\\]\nEntão precisamos de \\(E(Y_1Y_2)\\), que é \\[\nE(Y_1Y_2) = P(Y_1=1 \\text{ e } Y_2=1),\n\\] pois \\(Y_1Y_2=1\\) somente quando ambos são 1.\n\nCálculo de \\(P(Y_1=1, Y_2=1)\\)\nInterprete o sorteio em duas etapas, sem reposição:\n\nPrimeira retirada é sucesso: probabilidade \\(K/N\\).\nDada uma primeira retirada de sucesso, restam:\n\n\\(K-1\\) sucessos\nem um total de \\(N-1\\) elementos.\n\nEntão a probabilidade de a segunda retirada também ser sucesso é: \\[\n\\frac{K-1}{N-1}.\n\\]\n\nLogo: \\[\nP(Y_1=1, Y_2=1)\n= \\frac{K}{N} \\cdot \\frac{K-1}{N-1}\n= \\frac{K(K-1)}{N(N-1)}.\n\\]\nPortanto: \\[\nE(Y_1Y_2) = \\frac{K(K-1)}{N(N-1)}.\n\\]\n\nCovariância\nAgora: \\[\n\\mathrm{Cov}(Y_1,Y_2)\n= E(Y_1Y_2) - E(Y_1)E(Y_2)\n= \\frac{K(K-1)}{N(N-1)} - \\left(\\frac{K}{N}\\right)^2.\n\\]\nVamos colocar os termos no mesmo denominador. Note que \\[\n\\left(\\frac{K}{N}\\right)^2 = \\frac{K^2}{N^2}\n= \\frac{K^2(N-1)}{N^2(N-1)}.\n\\]\nE \\[\n\\frac{K(K-1)}{N(N-1)}\n= \\frac{K(K-1)N}{N^2(N-1)}.\n\\]\nEntão: \\[\n\\mathrm{Cov}(Y_1,Y_2)\n= \\frac{K(K-1)N - K^2(N-1)}{N^2(N-1)}.\n\\]\nSimplificando o numerador: \\[\nK(K-1)N - K^2(N-1)\n= K[ N(K-1) - K(N-1) ].\n\\]\nDentro dos colchetes: \\[\nN(K-1) - K(N-1)\n= (NK - N) - (KN - K)\n= NK - N - KN + K\n= -N + K\n= K - N.\n\\]\nLogo o numerador é: \\[\nK(K-N) = -K(N-K).\n\\]\nPortanto: \\[\n\\mathrm{Cov}(Y_1,Y_2)\n= \\frac{-K(N-K)}{N^2(N-1)}.\n\\]\nIsso mostra que a covariância é negativa: faz sentido, pois sem reposição, ao observar um sucesso na primeira retirada, fica ligeiramente menos provável ver outro sucesso na segunda.\n\nVariância de \\(X\\)\nRelembrando: \\[\n\\mathrm{Var}(X)=n\\,\\mathrm{Var}(Y_1) + n(n-1)\\,\\mathrm{Cov}(Y_1,Y_2).\n\\]\nSubstituímos os valores encontrados:\n\n\\(\\mathrm{Var}(Y_1) = \\dfrac{K(N-K)}{N^2}\\)\n\\(\\mathrm{Cov}(Y_1,Y_2) = -\\dfrac{K(N-K)}{N^2(N-1)}\\)\n\nEntão: \\[\n\\mathrm{Var}(X)\n= n \\cdot \\frac{K(N-K)}{N^2}\n+ n(n-1)\\cdot\\left(-\\frac{K(N-K)}{N^2(N-1)}\\right).\n\\]\nColocamos o fator comum \\(\\dfrac{K(N-K)}{N^2}\\) em evidência: \\[\n\\mathrm{Var}(X)\n= \\frac{K(N-K)}{N^2}\n\\left[\nn - \\frac{n(n-1)}{N-1}\n\\right].\n\\]\nAgora vamos simplificar o colchete: \\[\nn - \\frac{n(n-1)}{N-1}\n= n\\left[1 - \\frac{n-1}{N-1}\\right]\n= n\\left[\\frac{N-1 - (n-1)}{N-1}\\right]\n= n\\left[\\frac{N-n}{N-1}\\right].\n\\]\nPortanto: \\[\n\\mathrm{Var}(X)\n= \\frac{K(N-K)}{N^2}\\cdot n\\frac{N-n}{N-1}.\n\\]\nPodemos reescrever \\(K(N-K)/N^2\\) como \\[\n\\frac{K}{N}\\left(1-\\frac{K}{N}\\right).\n\\]\nAssim: \\[\n\\mathrm{Var}(X)\n= n \\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\\frac{N-n}{N-1}.\n\\]\n\nAssim, para \\(X \\sim \\text{Hipergeométrica}(N,K,n)\\):\n\nEsperança: \\[\nE(X) = n \\frac{K}{N}.\n\\]\nVariância: \\[\n\\mathrm{Var}(X) = n \\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\\frac{N-n}{N-1}.\n\\]\n\n\n\n\nExemplo: Um lote tem \\(N=80\\) peças, sendo \\(K=10\\) defeituosas. Retira-se uma amostra de \\(n=12\\) peças. Seja \\(X\\) = número de defeituosas na amostra.\n\nCalcule \\(P(X=2)\\).\n\nCalcule \\(E[X]\\).\n\nSolução:\n\n\\[\nP(X=2)=\\frac{\\binom{10}{2}\\binom{70}{10}}{\\binom{80}{12}}\n\\]\n\nResultado aproximado: 0,283\n\n\\[\nE[X]=12 \\cdot \\frac{10}{80} = 1{,}5\n\\]",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#poisson-lambda",
    "href": "revisao.html#poisson-lambda",
    "title": "Revisão Probabilidade I",
    "section": "3.6 Poisson \\((\\lambda)\\)",
    "text": "3.6 Poisson \\((\\lambda)\\)\nContagem de eventos raros em intervalo fixo.\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(k=0,1,2,\\dots\\)\n\n\n\\(p(k)\\)\n\\(e^{-\\lambda}\\lambda^k/k!\\)\n\n\n\\(F(k)\\)\n\\(\\sum_{j=0}^{k}e^{-\\lambda}\\lambda^j/j!\\)\n\n\n\\(E[X]\\)\n\\(\\lambda\\)\n\n\n\\(Var(X)\\)\n\\(\\lambda\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere \\(X \\sim \\text{Poisson}(\\lambda)\\), com \\(\\lambda &gt; 0\\). A função de probabilidade é: \\[\nP(X=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!},\\qquad k=0,1,2,\\dots\n\\]\nNosso objetivo é demonstrar: \\[\nE(X)=\\lambda,\n\\qquad\n\\mathrm{Var}(X)=\\lambda.\n\\]\nUsaremos somente as definições: \\[\nE(X)=\\sum_{k=0}^{\\infty} k\\,P(X=k), \\qquad\n\\mathrm{Var}(X)=E(X^2)-[E(X)]^2.\n\\]\n\nCálculo de \\(E(X)\\)\nPela definição de esperança: \\[\nE(X)=\\sum_{k=0}^{\\infty} k\\,P(X=k)\n    =\\sum_{k=0}^{\\infty} k\\,e^{-\\lambda}\\frac{\\lambda^k}{k!}.\n\\]\nO termo \\(k=0\\) é nulo, então: \\[\nE(X)=e^{-\\lambda}\\sum_{k=1}^{\\infty} k\\frac{\\lambda^k}{k!}.\n\\]\nUsamos a identidade: \\[\nk\\frac{\\lambda^k}{k!}=\\frac{\\lambda^k}{(k-1)!}.\n\\]\nLogo: \\[\nE(X)=e^{-\\lambda}\\sum_{k=1}^{\\infty} \\frac{\\lambda^k}{(k-1)!}.\n\\]\nAgora fazemos a mudança de variável \\(j=k-1\\):\n\nquando \\(k=1\\), \\(j=0\\)\n\nquando \\(k\\to\\infty\\), \\(j\\to\\infty\\)\n\nEntão: \\[\nE(X)=e^{-\\lambda}\\sum_{j=0}^{\\infty} \\frac{\\lambda^{j+1}}{j!}\n= e^{-\\lambda}\\lambda \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j}}{j!}.\n\\]\nMas: \\[\n\\sum_{j=0}^{\\infty} \\frac{\\lambda^{j}}{j!} = e^{\\lambda}.\n\\]\nPortanto: \\[\nE(X)=e^{-\\lambda}\\lambda e^{\\lambda} = \\lambda.\n\\]\nAssim demonstramos: \\[\nE(X)=\\lambda.\n\\]\n\nCálculo de \\(E(X^2)\\)\nAgora usamos a definição: \\[\nE(X^2)=\\sum_{k=0}^{\\infty} k^2 P(X=k)\n      =e^{-\\lambda}\\sum_{k=0}^{\\infty} k^2 \\frac{\\lambda^k}{k!}.\n\\]\nTruque clássico: escrever \\[\nk^2 = k(k-1) + k.\n\\]\nEntão: \\[\nE(X^2)\n= e^{-\\lambda}\\sum_{k=0}^{\\infty} k(k-1)\\frac{\\lambda^k}{k!}\n+ e^{-\\lambda}\\sum_{k=0}^{\\infty} k\\frac{\\lambda^k}{k!}.\n\\]\nChamemos:\n\nPrimeiro somatório:\n\\[A = e^{-\\lambda}\\sum_{k=0}^{\\infty} k(k-1)\\frac{\\lambda^k}{k!}\\]\nSegundo somatório:\n\\[B = e^{-\\lambda}\\sum_{k=0}^{\\infty} k\\frac{\\lambda^k}{k!}\\]\n\nMas já vimos antes que \\(B = E(X) = \\lambda\\).\nVamos calcular \\(A\\).\n\nCálculo do termo \\(A\\)\nNote que: \\[\nk(k-1)\\frac{\\lambda^k}{k!}\n= \\frac{\\lambda^k}{(k-2)!}.\n\\]\nPortanto: \\[\nA = e^{-\\lambda}\\sum_{k=2}^{\\infty}\\frac{\\lambda^k}{(k-2)!}.\n\\]\nFazemos a mudança de variável \\(j=k-2\\):\n\nquando \\(k=2\\), \\(j=0\\)\nquando \\(k\\to\\infty\\), \\(j\\to\\infty\\)\n\nEntão: \\[\nA = e^{-\\lambda}\\sum_{j=0}^{\\infty}\\frac{\\lambda^{j+2}}{j!}\n= e^{-\\lambda}\\lambda^2 \\sum_{j=0}^{\\infty}\\frac{\\lambda^{j}}{j!}.\n\\]\nA soma é novamente \\(e^\\lambda\\), logo: \\[\nA = e^{-\\lambda}\\lambda^2 e^\\lambda = \\lambda^2.\n\\]\nAgora juntamos:\n\n\\(A = \\lambda^2\\)\n\\(B = \\lambda\\)\n\nPortanto: \\[\nE(X^2) = A + B = \\lambda^2 + \\lambda.\n\\]\n\nVariância\nUsamos: \\[\n\\mathrm{Var}(X)=E(X^2)-[E(X)]^2.\n\\]\nSubstituindo:\n\n\\(E(X)=\\lambda\\)\n\\(E(X^2)=\\lambda^2 + \\lambda\\)\n\nTemos: \\[\n\\mathrm{Var}(X)\n= (\\lambda^2+\\lambda) - \\lambda^2\n= \\lambda.\n\\]\n\nLogo, para \\(X \\sim \\text{Poisson}(\\lambda)\\):\n\\[\nE(X)=\\lambda,\n\\qquad\n\\mathrm{Var}(X)=\\lambda.\n\\]\n\n\n\nExemplo: A taxa média de chamadas em um call center é \\(\\lambda=12\\) chamadas por hora. Seja \\(N\\) = número de chamadas.\n\nCalcule \\(P(N=10)\\).\n\nCalcule \\(P(N\\ge 15)\\).\n\nCalcule \\(E[N]\\) e \\(Var(N)\\).\n\nSolução:\n\n\\[\nP(N=10)=e^{-12}\\frac{12^{10}}{10!}\\approx 0{,}104\n\\]\n\\[\nP(N\\ge 15)=1-P(N\\le 14)\\approx 0{,}263\n\\]\n\\[\nE[N]=12,\\qquad Var(N)=12\n\\]",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#uniforme-ab",
    "href": "revisao.html#uniforme-ab",
    "title": "Revisão Probabilidade I",
    "section": "4.1 Uniforme \\((a,b)\\)",
    "text": "4.1 Uniforme \\((a,b)\\)\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(a\\le x\\le b\\)\n\n\n\\(f(x)\\)\n\\(1/(b-a)\\)\n\n\n\\(F(x)\\)\n\\((x-a)/(b-a)\\) para \\(a\\le x\\le b\\)\n\n\n\\(E[X]\\)\n\\((a+b)/2\\)\n\n\n\\(Var(X)\\)\n\\((b-a)^2/12\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere \\(X \\sim \\text{Uniforme}(a,b)\\), com \\(a &lt; b\\).\nA função densidade é: \\[\nf(x) =\n\\begin{cases}\n\\dfrac{1}{b-a}, & a \\le x \\le b,\\\\[6pt]\n0, & \\text{caso contrário.}\n\\end{cases}\n\\]\nNosso objetivo é demonstrar que \\[\nE(X) = \\frac{a+b}{2},\n\\qquad\n\\mathrm{Var}(X) = \\frac{(b-a)^2}{12},\n\\] usando apenas as definições: \\[\nE(X)=\\int_{-\\infty}^{\\infty} x f(x)\\,dx,\n\\qquad\nE(X^2)=\\int_{-\\infty}^{\\infty} x^2 f(x)\\,dx,\n\\qquad\n\\mathrm{Var}(X)=E(X^2)-[E(X)]^2.\n\\]\n\nCálculo de \\(E(X)\\)\nPela definição: \\[\nE(X) = \\int_{-\\infty}^{\\infty} x f(x)\\,dx.\n\\]\nComo \\(f(x)=0\\) fora do intervalo \\([a,b]\\), temos: \\[\nE(X) = \\int_a^b x \\cdot \\frac{1}{b-a}\\,dx\n     = \\frac{1}{b-a} \\int_a^b x\\,dx.\n\\]\nCalculamos a integral: \\[\n\\int_a^b x\\,dx = \\left[\\frac{x^2}{2}\\right]_a^b\n= \\frac{b^2}{2} - \\frac{a^2}{2}\n= \\frac{b^2 - a^2}{2}.\n\\]\nLogo: \\[\nE(X) = \\frac{1}{b-a} \\cdot \\frac{b^2 - a^2}{2}.\n\\]\nFatoramos \\(b^2 - a^2\\): \\[\nb^2 - a^2 = (b-a)(b+a).\n\\]\nSubstituindo: \\[\nE(X) = \\frac{1}{b-a} \\cdot \\frac{(b-a)(b+a)}{2}\n     = \\frac{b+a}{2}.\n\\]\nPortanto: \\[\nE(X) = \\frac{a+b}{2}.\n\\]\n\nCálculo de \\(E(X^2)\\)\nPela definição: \\[\nE(X^2) = \\int_{-\\infty}^{\\infty} x^2 f(x)\\,dx\n       = \\int_a^b x^2 \\cdot \\frac{1}{b-a}\\,dx\n       = \\frac{1}{b-a}\\int_a^b x^2\\,dx.\n\\]\nCalculamos a integral: \\[\n\\int_a^b x^2\\,dx = \\left[\\frac{x^3}{3}\\right]_a^b\n= \\frac{b^3}{3} - \\frac{a^3}{3}\n= \\frac{b^3 - a^3}{3}.\n\\]\nEntão: \\[\nE(X^2) = \\frac{1}{b-a} \\cdot \\frac{b^3 - a^3}{3}\n       = \\frac{b^3 - a^3}{3(b-a)}.\n\\]\nAgora usamos a fatoração: \\[\nb^3 - a^3 = (b-a)(b^2 + ab + a^2).\n\\]\nSubstituindo: \\[\nE(X^2) = \\frac{(b-a)(b^2 + ab + a^2)}{3(b-a)}\n       = \\frac{b^2 + ab + a^2}{3}.\n\\]\nPortanto: \\[\nE(X^2) = \\frac{a^2 + ab + b^2}{3}.\n\\]\n\nCálculo de \\(\\mathrm{Var}(X)\\)\nUsamos: \\[\n\\mathrm{Var}(X) = E(X^2) - [E(X)]^2.\n\\]\nJá obtivemos:\n\n\\(E(X) = \\dfrac{a+b}{2}\\)\n\n\\(E(X^2) = \\dfrac{a^2 + ab + b^2}{3}\\)\n\nEntão: \\[\n\\mathrm{Var}(X)\n= \\frac{a^2 + ab + b^2}{3} - \\left(\\frac{a+b}{2}\\right)^2.\n\\]\nPrimeiro, calculemos o quadrado: \\[\n\\left(\\frac{a+b}{2}\\right)^2\n= \\frac{(a+b)^2}{4}\n= \\frac{a^2 + 2ab + b^2}{4}.\n\\]\nAgora escrevemos a variância com denominador comum. O denominador comum entre 3 e 4 é 12:\n\nPrimeiro termo: \\[\n\\frac{a^2 + ab + b^2}{3}\n= \\frac{4(a^2 + ab + b^2)}{12}.\n\\]\nSegundo termo: \\[\n\\frac{a^2 + 2ab + b^2}{4}\n= \\frac{3(a^2 + 2ab + b^2)}{12}.\n\\]\n\nEntão: \\[\n\\mathrm{Var}(X)\n= \\frac{4(a^2 + ab + b^2)}{12} - \\frac{3(a^2 + 2ab + b^2)}{12}.\n\\]\nSubtraindo os numeradores: \\[\n4(a^2 + ab + b^2) - 3(a^2 + 2ab + b^2)\n= 4a^2 + 4ab + 4b^2 - 3a^2 - 6ab - 3b^2\n= (4a^2 - 3a^2) + (4ab - 6ab) + (4b^2 - 3b^2)\n= a^2 - 2ab + b^2.\n\\]\nLogo: \\[\n\\mathrm{Var}(X)\n= \\frac{a^2 - 2ab + b^2}{12}\n= \\frac{(b-a)^2}{12},\n\\] pois \\[\na^2 - 2ab + b^2 = (b-a)^2.\n\\]\n\nAssim, para \\(X \\sim \\text{Uniforme}(a,b)\\), demonstramos que: \\[\nE(X) = \\frac{a+b}{2},\n\\qquad\n\\mathrm{Var}(X) = \\frac{(b-a)^2}{12}.\n\\]\n\n\n\nExemplo: O tempo de resposta de um servidor web varia uniformemente entre 50 ms e 90 ms, ou seja \\(T \\sim U(50, 90)\\).\n\nCalcule \\(P(60 &lt; T &lt; 80)\\).\n\nCalcule \\(E[T]\\) e \\(Var(T)\\).\n\nInterprete o valor esperado no contexto.\n\nSolução:\n\n\\[\nP(60&lt;T&lt;80)=\\frac{80-60}{90-50}=\\frac{20}{40}=0{,}5\n\\]\n\\[\nE[T]=\\frac{50+90}{2}=70\n\\]\n\n\\[\nVar(T)=\\frac{(90-50)^2}{12}=\\frac{1600}{12}\\approx 133{,}33\n\\]\n\nO tempo médio de resposta é 70 ms.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#exponencial-lambda",
    "href": "revisao.html#exponencial-lambda",
    "title": "Revisão Probabilidade I",
    "section": "4.2 Exponencial \\((\\lambda)\\)",
    "text": "4.2 Exponencial \\((\\lambda)\\)\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(x\\ge 0\\)\n\n\n\\(f(x)\\)\n\\(\\lambda e^{-\\lambda x}\\)\n\n\n\\(F(x)\\)\n\\(1-e^{-\\lambda x}\\)\n\n\n\\(E[X]\\)\n\\(1/\\lambda\\)\n\n\n\\(Var(X)\\)\n\\(1/\\lambda^2\\)\n\n\nPropriedade\nSem memória: \\(P(X&gt;s+t\\mid X&gt;t)=P(X&gt;s)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nConsidere \\(X \\sim \\text{Exponencial}(\\lambda)\\), com \\(\\lambda &gt; 0\\).\nA função densidade é \\[\nf(x) =\n\\begin{cases}\n\\lambda e^{-\\lambda x}, & x \\ge 0, \\\\[4pt]\n0, & x &lt; 0.\n\\end{cases}\n\\]\nNosso objetivo é demonstrar: \\[\nE(X) = \\frac{1}{\\lambda},\n\\qquad\n\\mathrm{Var}(X) = \\frac{1}{\\lambda^2},\n\\] usando apenas as definições: \\[\nE(X) = \\int_0^\\infty x\\,\\lambda e^{-\\lambda x}\\,dx,\n\\qquad\nE(X^2) = \\int_0^\\infty x^2\\,\\lambda e^{-\\lambda x}\\,dx.\n\\]\n\nCálculo de \\(E(X)\\)\nPela definição: \\[\nE(X) = \\int_0^\\infty x\\lambda e^{-\\lambda x}\\,dx.\n\\]\nPara resolver a integral, usamos integração por partes.\nEscolhemos: - \\(u = x\\) → \\(du = dx\\) - \\(dv = \\lambda e^{-\\lambda x}dx\\) → \\(v = -e^{-\\lambda x}\\)\nAplicando integração por partes: \\[\n\\int_0^\\infty x\\lambda e^{-\\lambda x}\\,dx\n= \\left[-x e^{-\\lambda x}\\right]_{0}^{\\infty}\n+ \\int_0^\\infty e^{-\\lambda x}\\,dx.\n\\]\nAgora avaliamos cada termo:\n\nPrimeira parte:\n\nQuando \\(x\\to\\infty\\): \\(x e^{-\\lambda x} \\to 0\\).\nQuando \\(x=0\\): \\(0 \\cdot e^{0} = 0\\).\n\nLogo: \\[\n\\left[-x e^{-\\lambda x}\\right]_{0}^{\\infty} = 0.\n\\]\nIntegral restante: \\[\n\\int_0^\\infty e^{-\\lambda x}\\,dx\n= \\left[-\\frac{1}{\\lambda}e^{-\\lambda x}\\right]_{0}^{\\infty}\n= \\frac{1}{\\lambda}.\n\\]\n\nPortanto: \\[\nE(X)=\\frac{1}{\\lambda}.\n\\]\n\nCálculo de \\(E(X^2)\\)\nPela definição: \\[\nE(X^2)=\\int_0^\\infty x^2 \\lambda e^{-\\lambda x}\\,dx.\n\\]\nVamos aplicar integração por partes duas vezes.\n\nPrimeira integração por partes\nEscolha: - \\(u = x^2\\) → \\(du = 2x\\,dx\\) - \\(dv = \\lambda e^{-\\lambda x}dx\\) → \\(v = -e^{-\\lambda x}\\)\nEntão: \\[\nE(X^2)\n= \\left[-x^2 e^{-\\lambda x}\\right]_0^\\infty\n+ \\int_0^\\infty 2x e^{-\\lambda x} \\, dx.\n\\]\nO primeiro termo é zero, pelo mesmo argumento anterior.\nAssim: \\[\nE(X^2)= 2\\int_0^\\infty x e^{-\\lambda x}\\,dx.\n\\]\n\nSegunda integração por partes\nAgora resolvemos: \\[\n\\int_0^\\infty x e^{-\\lambda x}\\,dx.\n\\]\nEscolha: - \\(u = x\\) → \\(du = dx\\) - \\(dv = e^{-\\lambda x}dx\\) → \\(v = -\\frac{1}{\\lambda}e^{-\\lambda x}\\)\nEntão: \\[\n\\int_0^\\infty x e^{-\\lambda x}\\,dx\n= \\left[-\\frac{x}{\\lambda} e^{-\\lambda x}\\right]_0^\\infty\n+ \\int_0^\\infty \\frac{1}{\\lambda} e^{-\\lambda x}\\,dx.\n\\]\nO primeiro termo novamente é zero.\nResta: \\[\n\\int_0^\\infty x e^{-\\lambda x}\\,dx\n= \\frac{1}{\\lambda} \\int_0^\\infty e^{-\\lambda x}\\,dx\n= \\frac{1}{\\lambda}\\cdot\\frac{1}{\\lambda}\n= \\frac{1}{\\lambda^2}.\n\\]\nVoltando ao ponto onde paramos: \\[\nE(X^2)= 2\\left(\\frac{1}{\\lambda^2}\\right)\n= \\frac{2}{\\lambda^2}.\n\\]\n\nCálculo da variância\nUsamos: \\[\n\\mathrm{Var}(X)=E(X^2)-[E(X)]^2.\n\\]\nSubstituindo:\n\n\\(E(X^2)=\\frac{2}{\\lambda^2}\\)\n\\(E(X)=\\frac{1}{\\lambda}\\)\n\nEntão: \\[\n\\mathrm{Var}(X)\n= \\frac{2}{\\lambda^2} - \\left(\\frac{1}{\\lambda}\\right)^2\n= \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2}\n= \\frac{1}{\\lambda^2}.\n\\]\nLoggo, para \\(X \\sim \\text{Exponencial}(\\lambda)\\):\n\\[\nE(X)=\\frac{1}{\\lambda},\n\\qquad\n\\mathrm{Var}(X)=\\frac{1}{\\lambda^2}.\n\\]\n\n\n\nExemplo: O tempo entre chegadas ao caixa segue \\(X \\sim Exp(0{,}2)\\).\n\nCalcule \\(P(X&gt;8)\\).\n\nDetermine a mediana.\n\nInterprete a propriedade “sem memória”.\n\nSolução:\n\n\\[\nP(X&gt;8)=e^{-0{,}2\\cdot 8}=e^{-1{,}6}\\approx 0{,}2019\n\\]\n\\[\nm=\\frac{\\ln 2}{0{,}2}=5\\ln 2 \\approx 3{,}47\n\\]\nO tempo adicional não depende do tempo já passado.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#normal-musigma2",
    "href": "revisao.html#normal-musigma2",
    "title": "Revisão Probabilidade I",
    "section": "4.3 Normal \\((\\mu,\\sigma^2)\\)",
    "text": "4.3 Normal \\((\\mu,\\sigma^2)\\)\n\n\n\n\n\n\n\nItem\nExpressão\n\n\n\n\nSuporte\n\\(x\\in\\mathbb{R}\\)\n\n\n\\(f(x)\\)\n\\(\\dfrac{1}{\\sigma\\sqrt{2\\pi}}\\,\\exp\\left(-\\dfrac{(x-\\mu)^2}{2\\sigma^2}\\right)\\)\n\n\n\\(F(x)\\)\n\\(\\Phi\\!\\left(\\dfrac{x-\\mu}{\\sigma}\\right)\\) (não possui forma fechada)\n\n\n\\(E[X]\\)\n\\(\\mu\\)\n\n\n\\(Var(X)\\)\n\\(\\sigma^2\\)\n\n\n\nUso de Tabelas: padronize \\(Z=(X-\\mu)/\\sigma\\) e leia \\(P(Z\\le z)\\) na tabela da Normal padrão \\(\\Phi(z)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostrar demonstração\n\n\n\n\n\nVamos considerar uma variável aleatória normal geral \\[\nX \\sim N(\\mu,\\sigma^2), \\quad \\sigma &gt; 0.\n\\]\nA densidade é \\[\nf_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\\quad x\\in\\mathbb{R}.\n\\]\nNosso objetivo é demonstrar, a partir das definições, que \\[\nE(X)=\\mu,\n\\qquad\n\\mathrm{Var}(X)=\\sigma^2.\n\\]\nA estratégia será:\n\nCalcular \\(E(Z)\\) e \\(\\mathrm{Var}(Z)\\) para a normal padrão \\(Z\\sim N(0,1)\\).\nUsar a relação \\(X = \\mu + \\sigma Z\\).\n\n\nNormal padrão \\(Z \\sim N(0,1)\\)\nPara a normal padrão, a densidade é \\[\nf_Z(z)=\\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2},\\quad z\\in\\mathbb{R}.\n\\]\nQueremos mostrar que: \\[\nE(Z)=0, \\qquad E(Z^2)=1 \\quad\\Rightarrow\\quad \\mathrm{Var}(Z)=1.\n\\]\n\nCálculo de \\(E(Z)\\)\nPela definição: \\[\nE(Z)=\\int_{-\\infty}^{\\infty} z f_Z(z)\\,dz\n= \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} z e^{-z^2/2}\\,dz.\n\\]\nObserve que:\n\nA função \\(e^{-z^2/2}\\) é par (simétrica): \\(e^{-(-z)^2/2}=e^{-z^2/2}\\).\nA função \\(z\\) é ímpar: \\((-z) = -z\\).\nLogo, o produto \\(z e^{-z^2/2}\\) é ímpar.\n\nA integral de uma função ímpar em intervalo simétrico é zero: \\[\n\\int_{-\\infty}^{\\infty} z e^{-z^2/2}\\,dz = 0.\n\\]\nPortanto: \\[\nE(Z)=0.\n\\]\n\nCálculo de \\(E(Z^2)\\)\nPela definição: \\[\nE(Z^2)=\\int_{-\\infty}^{\\infty} z^2 f_Z(z)\\,dz\n= \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} z^2 e^{-z^2/2}\\,dz.\n\\]\nPara calcular \\[\n\\int_{-\\infty}^{\\infty} z^2 e^{-z^2/2}\\,dz,\n\\] vamos usar um truque padrão com um parâmetro auxiliar.\nConsidere, para \\(a&gt;0\\): \\[\nI(a) = \\int_{-\\infty}^{\\infty} e^{-a z^2/2}\\,dz.\n\\]\nEste é um integral gaussiano. Sabe-se (ou demonstra-se via coordenadas polares) que \\[\nI(a) = \\sqrt{\\frac{2\\pi}{a}}.\n\\]\nAgora vamos derivar \\(I(a)\\) em relação a \\(a\\) para obter uma integral com \\(z^2\\).\n\nDerivando \\(I(a)\\)\nPor um lado, derivando “dentro” da integral (legítimo sob condições usuais):\n\\[\nI'(a) = \\frac{d}{da}\\int_{-\\infty}^{\\infty} e^{-a z^2/2}\\,dz\n      = \\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial a}\n        \\big(e^{-a z^2/2}\\big)\\,dz.\n\\]\nMas \\[\n\\frac{\\partial}{\\partial a} e^{-a z^2/2}\n= -\\frac{z^2}{2} e^{-a z^2/2}.\n\\]\nLogo: \\[\nI'(a) = \\int_{-\\infty}^{\\infty} -\\frac{z^2}{2} e^{-a z^2/2}\\,dz\n      = -\\frac{1}{2}\\int_{-\\infty}^{\\infty} z^2 e^{-a z^2/2}\\,dz.\n\\]\nPor outro lado, derivando a expressão fechada \\[\nI(a) = \\sqrt{\\frac{2\\pi}{a}}\n= (2\\pi)^{1/2} a^{-1/2},\n\\]\ntemos \\[\nI'(a) = (2\\pi)^{1/2}\\left(-\\frac{1}{2}\\right)a^{-3/2}\n      = -\\frac{\\sqrt{2\\pi}}{2}\\,a^{-3/2}.\n\\]\nIgualando as duas expressões para \\(I'(a)\\): \\[\n-\\frac{1}{2}\\int_{-\\infty}^{\\infty} z^2 e^{-a z^2/2}\\,dz\n= -\\frac{\\sqrt{2\\pi}}{2}\\,a^{-3/2}.\n\\]\nMultiplicando por \\(-2\\) ambos os lados: \\[\n\\int_{-\\infty}^{\\infty} z^2 e^{-a z^2/2}\\,dz\n= \\sqrt{2\\pi}\\,a^{-3/2}.\n\\]\n\nAplicando o resultado em \\(a=1\\)\nQueremos o caso com \\(a=1\\), isto é, \\[\n\\int_{-\\infty}^{\\infty} z^2 e^{-z^2/2}\\,dz.\n\\]\nPela fórmula: \\[\n\\int_{-\\infty}^{\\infty} z^2 e^{-z^2/2}\\,dz\n= \\sqrt{2\\pi}\\cdot 1^{-3/2}\n= \\sqrt{2\\pi}.\n\\]\nAgora voltamos para \\(E(Z^2)\\): \\[\nE(Z^2)\n= \\frac{1}{\\sqrt{2\\pi}}\n\\int_{-\\infty}^{\\infty} z^2 e^{-z^2/2}\\,dz\n= \\frac{1}{\\sqrt{2\\pi}}\\cdot \\sqrt{2\\pi} = 1.\n\\]\nLogo: \\[\nE(Z^2)=1.\n\\]\n\nVariância da normal padrão\nA variância é \\[\n\\mathrm{Var}(Z)=E(Z^2)-[E(Z)]^2=1-0^2=1.\n\\]\nConcluímos: \\[\nE(Z)=0,\\qquad \\mathrm{Var}(Z)=1\n\\quad\\text{para } Z\\sim N(0,1).\n\\]\n\nNormal geral \\(X \\sim N(\\mu,\\sigma^2)\\)\nUma variável normal geral pode ser escrita como \\[\nX = \\mu + \\sigma Z,\n\\] onde \\(Z \\sim N(0,1)\\).\nVamos usar essa relação para encontrar \\(E(X)\\) e \\(\\mathrm{Var}(X)\\).\n\nCálculo de \\(E(X)\\)\nUsando a linearidade da esperança: \\[\nE(X) = E(\\mu + \\sigma Z)\n     = E(\\mu) + E(\\sigma Z)\n     = \\mu + \\sigma E(Z).\n\\]\nComo já mostramos que \\(E(Z)=0\\), obtemos: \\[\nE(X) = \\mu + \\sigma \\cdot 0 = \\mu.\n\\]\n\nCálculo de \\(\\mathrm{Var}(X)\\)\nUsamos a propriedade de variância para transformações lineares: \\[\n\\mathrm{Var}(a + bZ) = b^2\\,\\mathrm{Var}(Z).\n\\]\nAqui, \\(a=\\mu\\) e \\(b=\\sigma\\), então: \\[\n\\mathrm{Var}(X) = \\mathrm{Var}(\\mu + \\sigma Z)\n                = \\sigma^2\\,\\mathrm{Var}(Z).\n\\]\nSabemos que \\(\\mathrm{Var}(Z)=1\\), logo: \\[\n\\mathrm{Var}(X) = \\sigma^2 \\cdot 1 = \\sigma^2.\n\\]\n\nAssim, para uma variável aleatória normal geral \\(X \\sim N(\\mu,\\sigma^2)\\), demonstramos que:\n\\[\nE(X) = \\mu,\n\\qquad\n\\mathrm{Var}(X) = \\sigma^2.\n\\]\n\n\n\nExemplo: Pesos de pacotes seguem \\(W \\sim N(25, 1{,}5^2)\\).\n\nCalcule \\(P(24 &lt; W &lt; 27)\\).\n\nDetermine o percentil 95%.\n\nInterprete o percentil no controle de qualidade.\n\nSolução:\n\n\\[\nP(24&lt;W&lt;27)=P(-0{,}67&lt;Z&lt;1{,}33)=\\Phi(1{,}33)-\\Phi(-0{,}67)\n\\]\n\n\\[\n\\approx 0{,}9082 - 0{,}2514 = 0{,}6568\n\\]\n\n\\[\nx_{0{,}95}=25 + 1{,}645\\cdot 1{,}5 = 27{,}4675\n\\]\n95% dos pacotes pesam até 27,47 kg.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#hipergeométrica-approx-binomial",
    "href": "revisao.html#hipergeométrica-approx-binomial",
    "title": "Revisão Probabilidade I",
    "section": "5.1 Hipergeométrica \\(\\approx\\) Binomial",
    "text": "5.1 Hipergeométrica \\(\\approx\\) Binomial\nCondição: população grande vs. amostra pequena (fração amostral \\(n/N\\) pequena).\nUse \\(X\\sim Bin(n, p=K/N)\\) como aproximação.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#binomial-approx-poisson",
    "href": "revisao.html#binomial-approx-poisson",
    "title": "Revisão Probabilidade I",
    "section": "5.2 Binomial \\(\\approx\\) Poisson",
    "text": "5.2 Binomial \\(\\approx\\) Poisson\nCondição: \\(n\\) grande, \\(p\\) pequeno, \\(\\lambda=np\\) moderado.\nAproximação: \\(P_{Bin}(X=k)\\approx e^{-\\lambda}\\lambda^k/k!\\).",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#binomial-approx-normal",
    "href": "revisao.html#binomial-approx-normal",
    "title": "Revisão Probabilidade I",
    "section": "5.3 Binomial \\(\\approx\\) Normal",
    "text": "5.3 Binomial \\(\\approx\\) Normal\nCondição: \\(np(1-p)\\gtrsim 10\\).\nAproximação: \\(X\\approx N(\\mu=np,\\sigma^2=np(1-p))\\) com correção de continuidade.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "revisao.html#poisson-approx-normal",
    "href": "revisao.html#poisson-approx-normal",
    "title": "Revisão Probabilidade I",
    "section": "5.4 Poisson \\(\\approx\\) Normal",
    "text": "5.4 Poisson \\(\\approx\\) Normal\nCondição: \\(\\lambda\\gtrsim 10\\).\nAproximação: \\(X\\approx N(\\mu=\\lambda,\\sigma^2=\\lambda)\\) com correção de continuidade.",
    "crumbs": [
      "Revisão Probabilidade I"
    ]
  },
  {
    "objectID": "programacao/semana-7.html",
    "href": "programacao/semana-7.html",
    "title": "Semana 07",
    "section": "",
    "text": "Não haverá aula!"
  },
  {
    "objectID": "programacao/semana-7.html#entrega-lista-de-exercícios-01",
    "href": "programacao/semana-7.html#entrega-lista-de-exercícios-01",
    "title": "Semana 07",
    "section": "Entrega lista de exercícios 01",
    "text": "Entrega lista de exercícios 01\n\n\n\n\n\n\nFique Atento!\n\n\n\n Lista de exercícios 01\nEntrega na sala de aula!\n\nData de entrega:\n\n25 de novembro de 2025"
  },
  {
    "objectID": "plano.html",
    "href": "plano.html",
    "title": "Plano de Ensino",
    "section": "",
    "text": "Leia com atenção o plano de ensino da disciplina que será oferecida neste período. Nele estão as regras do jogo.\n\n\n\nPlano de ensino\n\n\n Ver plano",
    "crumbs": [
      "Plano de Ensino"
    ]
  },
  {
    "objectID": "exercicios.html",
    "href": "exercicios.html",
    "title": "Listas de Exercícios",
    "section": "",
    "text": "Esta página contém as listas de exercícios que serão apresentadas ao longo do semestre. Você pode baixar as listas em versão PDF.\n\n\n\n1. Revisão de Probabilidade I\n\n\n Ver lista PDF \n Entrega: 25/11/2025 \n\n\n\n\n2. Distribuições Contínuas\n\n\n Ver lista PDF \n Entrega: 18/12/2025",
    "crumbs": [
      "Listas de Exercícios"
    ]
  },
  {
    "objectID": "exercicios/lista01.html",
    "href": "exercicios/lista01.html",
    "title": "Revisão de Probabilidade I",
    "section": "",
    "text": "Data de entrega: 25 de novembro de 2025\n\n\n\nA demanda diária de arroz em um supermercado (em centenas de quilos) é uma variável aleatória contínua \\(X\\) com função densidade de probabilidade\n\n\\[\nf_X(x)=\n\\begin{cases}\n\\dfrac{2x}{3}, & 0&lt;x&lt;1,\\\\\\\\\n1-\\dfrac{x}{3}, & 1&lt;x&lt;3,\\\\\\\\\n0, & \\text{caso contrário.}\n\\end{cases}\n\\]\nConsidere as questões a seguir.\n\nMostre que \\(f_x(x)\\) é uma função densidade de probabilidade para a demanda de arroz.\nQual a probabilidade de, em um dia escolhido ao acaso, se vender mais que 150 kg de arroz?\nEm 30 dias, quanto o gerente do supermercado espera vender?\nDetermine a função de distribuição acumulada de \\(X\\).\nQual é a quantidade de arroz que deve ser deixada à disposição do público diariamente para que não falte arroz com \\(95\\%\\) de probabilidade?\nQual é a demanda mediana de arroz?\nE a demanda modal?\n\n\n\nA temperatura \\(T\\) de destilação do petróleo é crucial na determinação da qualidade final do produto. Suponha que \\(T\\) seja considerada uma v.a. com distribuição uniforme no intervalo de 150 a 300. Suponha que o custo para produzir um galão de petróleo seja \\(C_1 u.m.\\). Se o óleo é destilado a uma temperatura inferior a 200, o produto obtido é vendido a \\(C_2 u.m.\\); se a temperatura for superior a 200, o produto é vendido a \\(C_3 u.m.\\).\n\n\nFazer o gráfico da f.d.p de \\(T\\).\nQual o lucro esperado por galão?\n\n\n\nO diâmetro \\(X\\) de rolamentos de esferas fabricados por certa fábrica tem distribuição \\(N(0,6140;\\ (0,0025)^2)\\). O lucro \\(T\\) de cada esfera depende de seu diâmetro e\n\n\n\\(T=0,10\\) se a esfera é boa \\((0,6100 &lt; X &lt; 0,6180)\\)\n\\(T=0,05\\) se a esfera é recuperável \\((0,6080 &lt; X &lt; 0,6100)\\) ou \\((0,6180 &lt; X &lt; 0,6200)\\)\n\\(T=-0,10\\) se a esfera é defeituosa \\((X &lt; 0,6080 \\text{ ou } X &gt; 0,6200)\\).\n\nDetermine \\(E[T]\\).\n\n\nEm uma determinada localidade, a renda em 1000 u.m. é uma v.a. \\(X\\) com função densidade de probabilidade: \\[\nf_X(x)=\n\\begin{cases}\n\\dfrac{x+1}{10}, & 0&lt;x&lt;2,\\\\[6pt]\n\\dfrac{18-3x}{40}, & 2&lt;x&lt;6,\\\\[6pt]\n0, & \\text{c.c.}\n\\end{cases}\n\\]\n\n\nMostre que \\(f_X(x)\\) é uma função densidade de probabilidade para \\(X\\).\nDetermine a função de distribuição acumulada de \\(X\\).\nEscolhida uma pessoa ao acaso, qual é a probabilidade de sua renda exceder 3.000 u.m.?\nDetermine a renda média nessa localidade.\nDetermine a renda mediana nessa localidade.\nDetermine o 1º e o 3º quartis da variável renda.\n\n\n\nAs notas de Probabilidade dos alunos de determinada universidade seguem a distribuição normal, com média \\(6{,}4\\) e desvio-padrão \\(0{,}8\\). O professor atribui graus A, B e C, da seguinte forma:\n\n\nC, para notas inferiores a \\(5\\)\nB, para notas entre \\(5\\) e \\(7{,}5\\)\nA, para notas superiores a \\(7{,}5\\)\n\n\nQual a probabilidade de um aluno receber conceito A?\n\nQual a probabilidade de um aluno receber conceito B?\n\nQual a probabilidade de um aluno receber conceito C?\n\nSe a turma tem 80 alunos, quantos devem receber cada conceito, em média?\n\n\n\nSuponha que o número de milhas que um carro percorre antes que sua bateria sofra desgaste tenha distribuição Exponencial com média de 10.000 milhas. Se uma pessoa deseja fazer uma viagem de 5.000 milhas com uma bateria já usada por 8.000 milhas, qual é a probabilidade de terminar a viagem sem ter que trocar a bateria?\n\n\n\nO tempo de vida dos pneus de certo fabricante tem distribuição Exponencial, com duração média de 50.000 km.\n\n\nDetermine a probabilidade de que um pneu deste fabricante dure mais que 50.000 km.\nQual é o tempo de vida que o fabricante deve garantir de forma que, no máximo, 1% dos compradores utilizem a garantia?\nVocê acha que a distribuição exponencial é adequada a esta situação? Justifique.\n\n\n\nO número de clientes chegando a um certo estabelecimento comercial segue a distribuição de Poisson. Em média, chegam 10 clientes a cada hora.\n\n\nDetermine a probabilidade de que o tempo até a chegada do primeiro cliente exceda 5 minutos.\nDetermine a probabilidade de que o tempo entre chegadas sucessivas de dois clientes quaisquer exceda 5 minutos.\nDetermine a probabilidade de que o tempo até a chegada do quinto cliente exceda 30 minutos.\nDetermine a probabilidade de que chegue algum cliente nos próximos 30 minutos, uma vez que nenhum cliente chegou na última hora.\nDetermine o tempo médio entre chegadas sucessivas. Este é um bom valor preditivo?\nDetermine o tempo mediano entre chegadas sucessivas.\nDetermine o tempo médio até a chegada do quinto cliente. Este é um bom valor preditivo?\n\n\n\nSuponha-se que um fusível tenha uma duração de vida \\(X\\), a qual pode ser considerada uma variável aleatória contínua com distribuição Exponencial. Existem dois processos pelos quais o fusível pode ser fabricado. O processo I apresenta uma duração de vida esperada de 100 horas, enquanto o processo II apresenta uma duração de vida esperada de 150 horas. Suponha-se que o processo II seja duas vezes mais custoso que o processo I, que custa 3,00 u.m. por fusível. Admita-se, além disso, que se um fusível durar menos que 200 horas, uma multa de 20 u.m. seja lançada sobre o fabricante. Qual processo deve ser empregado de forma a se minimizar o custo esperado?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.Mostre que se \\(X\\) é uma variável aleatória contínua, com distribuição \\(Uniforme(a,b)\\), então:\n\\[E[X] = \\frac{a+b}{2} \\quad \\text{e} \\quad V[X] = \\frac{(b-a)^2}{12}.\\]\n\n11.Mostre que se \\(X \\sim Exponencial(\\lambda)\\), então:\n\\[E[X] = \\frac{1}{\\lambda} \\quad \\text{e} \\quad V[X] = \\frac{1}{\\lambda^2}.\\]\n\n12.Mostre que se \\(X \\sim Exponencial(\\lambda)\\), então \\(P(X &gt; t + s \\mid X &gt; t) = P(X &gt; s)\\), ou seja, a distribuição Exponencial goza da propriedade de “Falta de Memória”.\n\n\n\n\n\n\n\n\n\nUma fábrica produz 10 recipientes de vidro por dia. Deve-se supor que exista uma probabilidade constante \\(p = 0,1\\) de produzir um recipiente defeituoso. Antes que esses recipientes sejam estocados, eles são inspecionados e os defeituosos são separados. Admita que exista uma probabilidade constante \\(r = 0,1\\) de que um recipiente defeituoso seja mal classificado. Faça \\(X\\) igual ao número de recipientes classificados como defeituosos ao fim de um dia de produção. (Admita que todos os recipientes fabricados em um dia sejam inspecionados naquele dia.)\n\n\nCalcule \\(P(X = 3)\\) e \\(P(X &gt; 3)\\).\nObtenha a expressão de \\(P(X = k)\\).\n\n\n\nO número de navios petroleiros, digamos \\(N\\), que chegam a determinada refinaria, cada dia, tem distribuição de Poisson, com parâmetro \\(\\lambda = 2\\). As atuais instalações do porto podem atender a três petroleiros por dia. Se mais de três petroleiros aportarem por dia, os excedentes a três deverão seguir para outro porto.\n\na)Em um dia, qual é a probabilidade de se ter de mandar petroleiros para outro porto?\nb)De quanto deverão as atuais instalações ser aumentadas para permitir manobrar todos os petroleiros, em aproximadamente \\(90\\%\\) dos dias?\nc)Qual é o número esperado de petroleiros a chegarem por dia?\nd)Qual é o número mais provável de petroleiros a chegarem por dia?\ne)Qual é o número esperado de petroleiros a serem atendidos diariamente?\nf)Qual é o número esperado de petroleiros que voltarão a outros portos diariamente?\n\n\nA probabilidade de um bem-sucedido lançamento de foguete é igual a 0,8. Suponha que tentativas de lançamento sejam feitas até que tenham ocorrido 3 lançamentos bem-sucedidos. Qual é a probabilidade de que exatamente 6 tentativas sejam necessárias? Qual é a probabilidade de que menos de 6 tentativas sejam necessárias?\n\n\n\nNa situação descrita no Probl. 15, suponha que as tentativas de lançamento sejam feitas até que três lançamentos bem-sucedidos, consecutivos, ocorram. Responda às questões que surgiram no problema anterior, neste caso.\n\n\n17.Considere novamente a situação descrita no Probl. 15. Suponha que cada tentativa de lançamento custe \\(R\\$ 25.000,00\\). Além disso, um lançamento falho acarrete um custo adicional de \\(R\\$ 5.000,00\\). Calcule o custo esperado, para a situação apresentada."
  },
  {
    "objectID": "aulas.html",
    "href": "aulas.html",
    "title": "Aulas",
    "section": "",
    "text": "Esta página contém aulas que serão apresentadas ao longo do semestre. Você pode baixar as aulas em uma versão PDF.\n\n\n Outras Distribuições Contínuas \n Ver slides PDF \n\n\n Transformação de Variáveis Unidimensionais \n Ver slides PDF \n\n\n Função Geradora de Momentos \n\n\n\n\n Integral Dupla e Tripla \n\n\n\n\n Vetores Aleatórios",
    "crumbs": [
      "Aulas"
    ]
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nA função Gamma é uma das funções especiais mais importantes em probabilidade e estatística. Ela aparece naturalmente em várias distribuições contínuas fundamentais:\n\nDistribuição Gamma\n\n\\[f(x |\\alpha, \\lambda) = \\dfrac{\\lambda e^{-\\lambda x}(\\lambda x)^{\\alpha-1}}{\\Gamma(\\alpha)}\\]\n\nDistribuição Qui-quadrado\n\n\\[f(x | n) = \\frac{1}{2^{n/2} \\Gamma(n/2)} x^{\\frac{n}{2} -1} e^{- \\frac{x}{2}}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\n\nDistribuição Beta\n\n\\[f(x |\\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1} (1-x)^{\\beta-1} \\]\n\nDistribuição t de Student\n\n\\[ f(x |\\nu) = \\frac{\\Gamma [(\\nu+1)/2]}{\\Gamma (\\nu/2)} \\frac{1}{\\sqrt{\\nu\\pi}} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-(\\nu+1)/2} \\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\n\nDistribuição F de Snedecor\n\n\\[ f(x |\\nu_1, \\nu_2) = \\frac{\\Gamma [(\\nu_1+\\nu_2)/2] }{\\Gamma \\left( \\frac{\\nu_1}{2} \\right) \\Gamma \\left( \\frac{\\nu_2}{2} \\right) } \\left( \\frac{\\nu_1}{\\nu_2} \\right)^{\\nu_1/2} \\frac{x^{(\\nu_1-2)/2}}{[1+(\\nu_1/\\nu_2)x]^{(\\nu_1+\\nu_2)/2}} \\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nDefinimos a função gamma como\n\\[\\Gamma(\\alpha) = \\int_{0}^{\\infty} e^{-y} \\, y^{\\alpha-1} \\, dy, \\,\\,\\,\\,\\,\\,\\,\\ \\alpha &gt; 0\\]\nVale destacar os seguintes resultados:\n\n\\(\\Gamma(\\alpha) = (\\alpha - 1)\\Gamma(\\alpha - 1)\\);\n\\(\\Gamma(n) = (n-1)!\\), \\(n\\) inteiro positivo;\n\\(\\Gamma(1/2) = \\sqrt{(\\pi)}\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nDemonstração\n\nResolvendo a integral por partes, fazendo \\(u = y^{\\alpha - 1}\\) e \\(dv = e^{-y} dy\\), temos\n\n\\[\n\\begin{aligned}\n\\Gamma(\\alpha)\n&= -\\, e^{-y}\\,y^{\\alpha-1}\\Big|_{0}^{\\infty}\n    + \\int_{0}^{\\infty} e^{-y}(\\alpha-1)\\,y^{\\alpha-2}\\,dy \\\\[6pt]\n&= (\\alpha - 1)\\int_{0}^{\\infty} e^{-y} y^{\\alpha-2}\\,dy \\\\[6pt]\n&= (\\alpha - 1)\\,\\Gamma(\\alpha - 1).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\n\nPara valores inteiros positivos de \\(\\alpha\\), por exemplo \\(\\alpha = n\\), temos\n\n\\[\n\\begin{aligned}\n\\Gamma(n)\n&= (n-1)\\,\\Gamma(n-1) \\\\[6pt]\n&= (n-1)(n-2)\\,\\Gamma(n-2) \\\\[6pt]\n&= \\cdots \\\\[6pt]\n&= (n-1)(n-2)\\cdots 3\\cdot 2\\cdot \\Gamma(1).\n\\end{aligned}\n\\]\nComo\n\\[\n\\Gamma(1) = \\int_{0}^{\\infty} e^{-y} \\, y^{1-1} \\, dy = \\int_{0}^{\\infty} e^{-y} dy = \\lim_{t \\to +\\infty} \\int_{0}^{t} e^{-t} dt = \\lim_{t \\to +\\infty} (-e^{-t} + e^0) = 1\n\\]\ntemos que \\(\\Gamma(n) = (n-1)!\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\n\nUma forma alternativa de definir a função gamma, às vezes útil, é dada por:\n\n\\[ \\Gamma(\\alpha) = 2\\int_0^\\infty e^{-y^2} y^{2\\alpha-1} dy\\] Temos que \\(\\Gamma(\\alpha) = \\int_{0}^{\\infty} e^{-y} \\, y^{\\alpha-1} \\, dy\\). Fazendo \\(y = u^2\\), temos que \\(dy = 2udu\\). Assim,\n\\[\n\\Gamma(\\alpha) = \\int_{0}^{\\infty} e^{-y} \\, y^{\\alpha-1} \\, dy = \\int_{0}^{\\infty} e^{-u^2} \\, u^{2\\alpha-2} \\, 2u\\,du = 2\\int_{0}^{\\infty} e^{-u^2}u^{2\\alpha-1}du\n\\]\nSe provarmos que \\(\\left[ \\Gamma\\left( \\frac{1}{2}\\right) \\right]^2 = \\pi\\), então segue que \\(\\Gamma\\left( \\frac{1}{2}\\right) = \\sqrt{\\pi}\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nPartindo de:\n\\[ \\left[ \\Gamma(\\alpha) \\right]^2 = 2\\int_0^\\infty x^{2\\alpha-1}e^{-x^2} dx\\quad 2\\int_0^\\infty y^{2\\alpha-1}e^{-y^2} dy\\]\no que resulta,\n\\[ \\left[ \\Gamma(\\alpha) \\right]^2 = 4\\int_0^\\infty\\int_0^\\infty x^{2\\alpha-1}  y^{2\\alpha-1} e^{-(x^2+y^2)} dx dy\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nTomando \\(\\alpha = \\dfrac{1}{2}\\), temos \\(2 \\alpha - 1 = 0\\) e assim,\n\\[\n\\displaystyle \\left[ \\Gamma \\left({\\frac {1}{2}}\\right) \\right]^2 = 4\\int_0^\\infty\\int_0^\\infty  e^{-(x^2+y^2)} dx dy\n\\]\n\nPara resolvermos esta integral dupla, podemos recorrer à técnica de coordenadas polares, na qual pontos \\((x,y)\\) são referenciados no sitema de coordenadas \\((r,\\theta)\\), sendo não negativo e \\(\\theta\\) variando de 0 a \\(2\\pi\\).\n\n\nAssim, tomamos \\(x=r \\cos\\theta\\) e \\(y=r \\text{ sen}\\,\\,\\theta\\), de forma que,\n\\[x^2+y^2 = r^2 \\cos^2\\theta +r^2 \\text{ sen}^2\\theta = r^2\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nA unidade infinitesimal de área \\(dx\\text{ }dy\\) corresponde à unidade infinitesimal de área \\(r\\text{ }dr\\text{ }d\\theta\\) no sistema de coordenadas polares.\n\nAlém disso, integrar com tanto como variando de zero a infinito corresponde a integrar no primeiro quadrante, que, no sistema de coordenadas polares, consiste em integrar com \\(\\theta\\) variando de 0 a \\(\\pi /2\\) e variando de 0 a infinito."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma\nAssim,\n\\[\n\\begin{aligned}\n\\left[\\Gamma\\!\\left(\\frac12\\right)\\right]^2\n&= 4 \\int_{0}^{\\pi/2} \\int_{0}^{\\infty} e^{-r^{2}}\\, r\\, dr\\, d\\theta = 4 \\int_{0}^{\\pi/2} d\\theta \\int_{0}^{\\infty} e^{-r^{2}}\\, r\\, dr \\\\[6pt]\n&= 4 \\int_{0}^{\\pi/2} d\\theta\n    \\left[ -\\frac{e^{-r^{2}}}{2} \\right]_{0}^{\\infty} = 4 \\int_{0}^{\\pi/2} \\left(\\frac12\\right)\\, d\\theta \\\\[6pt]\n&= 2 \\int_{0}^{\\pi/2} 1\\, d\\theta = 2\\,\\theta\\Big|_{0}^{\\pi/2} = \\pi\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#função-gamma-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Função Gamma",
    "text": "Função Gamma"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nDizemos que \\(X\\) segue uma distribuição Gamma com parâmetros \\(\\alpha &gt; 0\\) e \\(\\lambda &gt; 0\\) se sua função densidade é dada por\n\\[\nf(x | \\alpha, \\lambda)=\n\\begin{cases}\n\\dfrac{\\lambda e^{-\\lambda x}(\\lambda x)^{\\alpha-1}}{\\Gamma(\\alpha)}, & x\\ge0\\\\[6pt]\n0, & x&lt;0\n\\end{cases}\n\\]\nNotação: \\(X \\sim Gamma(\\alpha, \\lambda)\\). Nessa parametrização:\n\n\\(\\alpha\\) = parâmetro de forma\n\\(\\dfrac{1}{\\lambda}\\) = parâmetro de escala"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nSe \\(X \\sim Gamma(\\alpha, \\lambda)\\), então\n\\[\n\\begin{aligned}\nE[X]\n&= \\frac{1}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} x\\,\\lambda\\,e^{-\\lambda x}(\\lambda x)^{\\alpha-1}\\,dx \\\\[6pt]\n&= \\frac{1}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-\\lambda x}(\\lambda x)^{\\alpha}\\,dx \\\\[6pt]\n&= \\frac{1}{\\lambda\\,\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-u}\\,u^{\\alpha}\\,du \\\\[6pt]\n&= \\frac{\\Gamma(\\alpha+1)}{\\lambda\\,\\Gamma(\\alpha)}\n  = \\frac{\\alpha\\,\\Gamma(\\alpha)}{\\lambda\\,\\Gamma(\\alpha)}\n  = \\frac{\\alpha}{\\lambda}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\n\\[\n\\begin{aligned}\nE[X^{2}]\n&= \\frac{1}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} x^{2}\\,\\lambda\\,e^{-\\lambda x}(\\lambda x)^{\\alpha-1}\\,dx = \\frac{1}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-\\lambda x}\\,\\lambda^{\\alpha}\\,x^{\\alpha+1}\\,dx \\\\[6pt]\n&= \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-\\lambda x}\\,x^{\\alpha+1}\\,dx = \\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-u}\\left(\\frac{u}{\\lambda}\\right)^{\\alpha+1}\n    \\left(\\frac{1}{\\lambda}\\right)\\,du \\\\[6pt]\n&= \\frac{\\lambda^{\\alpha}}{\\lambda^{\\alpha+2}\\,\\Gamma(\\alpha)}\n    \\int_{0}^{\\infty} e^{-u}\\,u^{\\alpha+1}\\,du = \\frac{\\lambda^{\\alpha}\\,\\Gamma(\\alpha+2)}\n        {\\lambda^{\\alpha+2}\\,\\Gamma(\\alpha)} \\\\[6pt]\n&= \\frac{(\\alpha+1)\\Gamma(\\alpha+1)}\n        {\\lambda^{2}\\,\\Gamma(\\alpha)} = \\frac{(\\alpha+1)\\alpha\\,\\Gamma(\\alpha)}{\\lambda^{2}\\,\\Gamma(\\alpha)}= \\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nDe forma que,\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X)\n&= E(X^{2}) - [E(X)]^{2} \\\\[6pt]\n&= \\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}\n    - \\left(\\frac{\\alpha}{\\lambda}\\right)^{2} \\\\[6pt]\n&= \\frac{\\alpha^{2}+\\alpha}{\\lambda^{2}}\n    - \\frac{\\alpha^{2}}{\\lambda^{2}} \\\\[6pt]\n&= \\frac{\\alpha^{2}+\\alpha-\\alpha^{2}}{\\lambda^{2}} \\\\[6pt]\n&= \\frac{\\alpha}{\\lambda^{2}}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nLogo, se \\(X \\sim Gamma(\\alpha, \\lambda)\\), então\n\\[\nf(x | \\alpha, \\lambda)=\n\\begin{cases}\n\\dfrac{\\lambda e^{-\\lambda x}(\\lambda x)^{\\alpha-1}}{\\Gamma(\\alpha)}, & x\\ge0\\\\[6pt]\n0, & x&lt;0\n\\end{cases}\n\\]\ncom\n\\[E(X) =  \\dfrac{\\alpha}{\\lambda} \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\dfrac{\\alpha}{\\lambda^2}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nA Função de Distribuição Acumulada da distribuição gamma é intratável analiticamente.\n\\[\nF(x\\mid\\alpha,\\lambda)\n= \\int_{0}^{x} \\frac{\\lambda e^{-\\lambda u}(\\lambda u)^{\\alpha-1}}{\\Gamma(\\alpha)}\\,du,\n\\qquad x\\ge 0.\n\\]\n\n\n\n\n\n\n\n\n\nPara \\(\\alpha\\) inteiro positivo, a equação acima pode ser integrada por partes, resultando em\n\\[\nF(x\\mid\\alpha,\\lambda) =\n\\begin{cases}\n1 - \\sum_{k=0}^{\\alpha-1}\\frac{\\lambda^k}{k!} x^k e^{-\\lambda x}, & x &gt; 0\\\\[6pt]\n0, & x \\leq 0\n\\end{cases}\n\\]\nA expressão acima é a soma de termos da Poisson com média \\(\\lambda x\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribução-gamma",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribução-gamma",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribução Gamma",
    "text": "Distribução Gamma\n\n\nFigure 1: Distribuição Gama — variação do shape (α) com λ fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribução-gamma-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribução-gamma-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribução Gamma",
    "text": "Distribução Gamma\n\n\nFigure 2: Distribuição Gama — variação da taxa (λ) com α fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nA distribuição Gamma tem muitas aplicações reais, especialmente quando estudamos tempos até ocorrência de eventos.\n\n\nTempo até falha / confiabilidade de sistemas: modelagem do tempo de vida de componentes mecânicos, eletrônicos, etc.\n\n\n\n\nTempo até ocorrência de eventos em Poisson: Se eventos acontecem segundo um processo de Poisson com taxa \\(\\lambda\\):\n\no tempo até o primeiro evento é Exponencial (Gamma(1, \\(\\lambda\\)))\no tempo até o \\(k\\)-ésimo evento é Gamma(k,\\(\\lambda\\))\n\n\n\n\n\nModelagem de tempos de espera em filas: em teoria de filas (M/M/1, G/G/1 etc.), tempos de serviço ou tempos de atendimento podem ser modelados como Gamma."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\n\nPriori conjugada em Bayesiana: é priori conjugada para o parâmetro de taxa de uma Exponencial ou Poisson. Então em inferência Bayesiana, a Gamma aparece o tempo todo como priori para \\(\\lambda\\)\n\n\n\nHidrologia / clima: modelagem de chuvas acumuladas (precipitação) ao longo de certo intervalo: o total acumulado de chuva frequentemente é bem modelado por Gamma.\n\n\n\n\nBiologia / Epidemiologia: tempo até infecção, tempo até recuperação, duração de hospitalização, tempos de permanência podem ser modelados por Gamma (ou Weibull, que é próxima).\n\n\n\n\nAnálise de risco / Seguros: valores positivos e assimétricos (como sinistros) podem ser modelados com Gamma."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nExemplo 01: Suponha que o tempo gasto por um estagiário selecionado aleatoriamente para realizar uma tarefa em uma empresa tem uma distribuição gamma com média \\(20\\,\\, \\text{minutos}\\) e variância de \\(80\\,\\, \\text{minutos}^2\\)\n\nQuais são os parâmetros da distribuição gamma utilizada? R: \\(\\lambda = 0,25\\) e \\(\\alpha = 5\\)\nQual é a probabilidade de um estagiário realizar a tarefa em no máximo 24 minutos? R: \\(0,7149\\)\nQual é a probabilidade de um estagiário passar entre 20 e 40 minutos realizando a tarefa? R: \\(0,5595\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-gamma-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Gamma",
    "text": "Distribuição Gamma\nExemplo 02: A duração do atendimento de cada cliente no caixa de um supermercado tem distribuição Gamma com parâmetro de forma \\(\\alpha = 12\\) e parâmetro de taxa \\(\\lambda = 2\\)\n\nQual a média e variância da duração dos atendimentos? R: \\(E(x) = 6\\) e \\(Var(X) = 3\\)\nQual a probabilidade de um atendimento durar menos de 5 minutos? R: \\(0,3032\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Qui-Quadrado",
    "text": "Distribuição Qui-Quadrado\nUm caso particular da distribuição Gamma, quando tomamos \\(\\alpha = \\dfrac{n}{2}\\) e \\(\\lambda = \\dfrac{1}{2}\\), onde \\(n\\) é um inteiro positivo.\n\nAssim, para \\(\\alpha = \\dfrac{n}{2}\\) e \\(\\lambda = \\dfrac{1}{2}\\),\n\\[\nf(x) = \\dfrac{\\frac{1}{2} e^{-\\frac{x}{2}}\\left(\\frac{x}{2}\\right)^{\\frac{n}{2}-1}}{\\Gamma \\left(\\frac{n}{2}\\right)} =  \\dfrac{\\frac{e^{-\\frac{x}{2}}}{2} \\left(\\frac{x ^{\\frac{n}{2}-1}}{2^{\\frac{n}{2}-1}}\\right)}{\\Gamma \\left(\\frac{n}{2}\\right)} = \\dfrac{\\frac{e^{-\\frac{x}{2}} x ^{\\frac{n}{2}-1}}{2^{\\frac{n}{2}}}}{\\Gamma \\left(\\frac{n}{2}\\right)} = \\dfrac{1}{2^{\\frac{n}{2}} \\Gamma \\left(\\frac{n}{2}\\right)} e^{-\\frac{x}{2}} x ^{\\frac{n}{2}-1}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Qui-Quadrado",
    "text": "Distribuição Qui-Quadrado\nLogo, se \\(X \\sim \\chi^2_n\\), então\n\\[\nf(x | \\alpha, \\lambda)=\n\\begin{cases}\n\\dfrac{1}{2^{\\frac{n}{2}} \\Gamma \\left(\\frac{n}{2}\\right)} e^{-\\frac{x}{2}} x ^{\\frac{n}{2}-1}, & x\\ge0\\\\[6pt]\n0, & x&lt;0\n\\end{cases}\n\\]\ncom\n\\[E(X) =  n \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = 2n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Qui-Quadrado",
    "text": "Distribuição Qui-Quadrado\nA Função de Distribuição Acumulada da distribuição qui-quadrado é intratável analiticamente.\n\\[\nF(x\\mid n)\n= \\int_{0}^{x} \\dfrac{1}{2^{\\frac{n}{2}} \\Gamma \\left(\\frac{n}{2}\\right)} e^{-\\frac{x}{2}} x ^{\\frac{n}{2}-1} \\,dx,\n\\qquad x\\ge 0.\n\\]\n\n\n\n\n\n\n\n\n\nPara \\(n\\) inteiro positivo par, então existe forma como série finita:\n\\[\nF(x\\mid n) = 1 - e^{-x/2}\\sum_{k=0}^{\\frac{n}{2}-1}\\frac{\\left(\\frac{x}{2}\\right)^k}{k!}\n\\]\nou seja, quando \\(n\\) é par, ela pode ser escrita como uma soma finita de termos tipo Poisson."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Qui-Quadrado",
    "text": "Distribuição Qui-Quadrado\n\n\nFigure 3: Densidades qui-quadrado para vários graus de liberdade n."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-qui-quadrado-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Qui-Quadrado",
    "text": "Distribuição Qui-Quadrado\nA distribuição qui-quadrado é central em inferência estatística porque ela surge naturalmente quando somamos quadrados de variáveis Normais padrão:\n\\[\\chi^2_n = \\displaystyle{\\sum_{i=1}^n} Z_i^2, \\,\\,\\,\\,\\, Z_i \\sim N(0,1)\\]\n\nLogo, ela está por trás dos testes mais usados com dados categóricos, ANOVA, variâncias e na estruturação das distribuições t e F."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nDiz-se que uma variável aleatória tem distribução Beta, se sua função densidade é dada por\n\\[\nf(x \\mid a,b)=\n\\begin{cases}\n\\dfrac{1}{B(a,b)} x^{\\,a-1} (1-x)^{\\,b-1}, & 0&lt;x&lt;1\\\\[6pt]\n0, & \\text{caso contrário}\n\\end{cases}\n\\]\nem que a função Beta é dada por\n\\[B(a,b)=\\int_0^1 x^{\\,a-1} (1-x)^{\\,b-1}\\,dx\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nAlém disso, a função Beta tem uma conexão muito importante com a função Gamma\n\\[B(a,b) = \\dfrac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a+b)}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nSe \\(X \\sim Beta(a, b)\\), então\n\\[\nE[X] = \\int_0^1 x \\dfrac{1}{B(a,b)} x^{\\,a-1} (1-x)^{\\,b-1} \\, dx = \\dfrac{1}{B(a,b)}  \\int_0^1 x^a(1-x)^{b-1} \\, dx = \\dfrac{B(a+1,b)}{B(a,b)}\n\\]\nUsando a relação \\(B(a,b) = \\dfrac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a+b)}\\), temos\n\\[\n\\dfrac{B(a+1,b)}{B(a,b)} = \\dfrac{\\dfrac{\\Gamma(a+1)\\Gamma(b)}{\\Gamma(a+b + 1)}}{\\dfrac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}} = \\dfrac{\\Gamma(a+1)\\Gamma(b)}{\\Gamma(a+b + 1)} \\times \\dfrac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} = \\dfrac{\\Gamma(a+1)\\Gamma(a+b)}{\\Gamma(a+b + 1)\\Gamma(a)}=\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\n\\(= \\dfrac{a\\Gamma(a)\\Gamma(a+b)}{(a+b)\\Gamma(a+b)\\Gamma(a)} = \\dfrac{a}{a+b}\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\n\\[\n\\begin{aligned}\nE[X^{2}]\n&= \\int_{0}^{1} x^{2}\\,\n    \\frac{1}{B(a,b)}\\,x^{a-1}(1-x)^{b-1}\\,dx = \\frac{1}{B(a,b)}\n    \\int_{0}^{1} x^{a+1}(1-x)^{\\,b-1}\\,dx \\\\[6pt]\n&= \\frac{B(a+2,b)}{B(a,b)} = \\frac{\n      \\dfrac{\\Gamma(a+2)\\Gamma(b)}{\\Gamma(a+b+2)}\n    }{\n      \\dfrac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\n    } = \\frac{\\Gamma(a+2)\\Gamma(b)\\Gamma(a+b)}\n        {\\Gamma(a+b+2)\\Gamma(a)\\Gamma(b)} \\\\[6pt]\n&= \\frac{\n      (a+1)\\Gamma(a+1)\\,\\Gamma(a+b)\n    }{\n      (a+b+1)\\Gamma(a+b+1)\\,\\Gamma(a)\n    } = \\frac{\n      (a+1)a\\,\\Gamma(a)\\,\\Gamma(a+b)\n    }{\n      (a+b+1)(a+b)\\,\\Gamma(a+b)\\,\\Gamma(a)\n    } \\\\[6pt]\n&= \\frac{a(a+1)}{(a+b)(a+b+1)}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nDe forma que,\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X)\n&= E(X^{2}) - [E(X)]^{2} = \\frac{a(a+1)}{(a+b)(a+b+1)}\n    - \\left(\\frac{a}{a+b}\\right)^{2} \\\\[6pt]\n&= \\frac{a^{2}+a}{(a+b)(a+b+1)}\n    - \\frac{a^{2}}{(a+b)^{2}} = \\frac{(a^{2}+a)(a+b) - a^{2}(a+b+1)}\n        {(a+b+1)(a+b)^{2}} \\\\[6pt]\n&= \\frac{a^{3} + a^{2}b + a^{2} + ab - a^{3} - a^{2}b - a^{2}}\n        {(a+b+1)(a+b)^{2}} = \\frac{ab}{(a+b+1)(a+b)^{2}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nLogo, se \\(X \\sim Beta(a,b)\\), então\n\\[\nf(x \\mid a,b)=\n\\begin{cases}\n\\dfrac{1}{B(a,b)}x^{a-1} (1-x)^{b-1}, & 0&lt;x&lt;1\\\\[6pt]\n0, & \\text{caso contrário}\n\\end{cases}\n\\]\ncom\n\\[E(X) =  \\dfrac{a}{a+b} \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\dfrac{ab}{(a+b+1)(a+b)^2}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nA Função de Distribuição Acumulada da distribuição Beta é intratável analiticamente.\n\\[\nF(x| a,b)=\\dfrac{1}{B(a,b)}\\int_0^x t^{a-1}(1-t)^{b-1}dt.\n\\qquad 0&lt; x &lt; 1.\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\n\n\nFigure 4: Distribuição Beta — variação de a (shape1) com b fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\n\n\nFigure 5: Distribuição Beta — variação de b (shape2) com a fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\n\n\nFigure 6: Distribuição Beta — simetria quando α = β."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nA distribuição Beta é usada para modelar proporções (variáveis contínuas entre 0 e 1). É uma das distribuições mais importantes em estatística aplicada.\n\n\nModelagem de proporções: proporção de sucesso, taxa de clique (CTR) em marketing digital, fração de tempo ativo de um equipamento, percentual de umidade, pureza, concentração, etc.\n\n\n\n\nInferência Bayesiana: é a prior conjugada da Bernoulli e da Binomial → se o parâmetro de interesse é uma probabilidade \\(p\\), a priori Beta é natural.\n\n\n\n\nModelo para incerteza em probabilidades: incerteza sobre \\(p\\) em “probabilidade de sucesso” antes de observar dados, nossa crença sobre \\(p\\) é Beta"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-12",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-12",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nExemplo 03: A porcentagem de impurezas por lote, em determinado produto químico, é uma variável aleatória com distribuição Beta com parâmetros \\(a = 3\\) e \\(b = 2\\). Um lote com mais de \\(40\\%\\) de impurezas não pode ser vendido.\n\nQual é a probabilidade de que um lote, selecionado ao acaso, não possa ser vendido por causa do excesso de impurezas? R: \\(0,8208\\)\nQuantos lotes, em média, são selecionados, ao acaso, até que se encontre um que não pode ser vendido por causa do excesso de impurezas? R: \\(1,2183\\)\nQual é a porcentagem média de impurezas nos lotes desse produto químico? R: \\(0,60\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-13",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-beta-13",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Beta",
    "text": "Distribuição Beta\nExemplo 04: O teor de gordura no leite de um rebanho bovino é uma variável com distribuição Beta com parâmetros \\(a = 2\\) e \\(b = 5\\).\n\nQual o teor médio de gordura no leite? R: \\(0,2857\\)\nQual o percentual de amostras que terá teor de gordura menor que \\(10\\%\\)? R: \\(0,1143\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nUma variável aleatória tem distribuição de Weibull com parâmetros \\(\\beta &gt; 0\\) e \\(\\alpha &gt; 0\\) se sua função densidade para \\(x \\geq 0\\) é dada por\n\\[\nf(x|\\alpha, \\beta) =\n\\begin{cases}\n\\dfrac{\\beta}{\\alpha}\n\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta - 1}\n\\exp\\!\\left[-\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta}\\right],\n& x\\geq0\\\\[10pt]\n0, & x&lt;0\n\\end{cases}\n\\]\nNesta parametrização,\n\n\\(\\beta\\) - parâmetro de forma\n\\(\\alpha\\) - parâmetro de escala"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nSe \\(X \\sim Weibull(\\alpha, \\beta)\\), então\n\\[ \\small\n\\begin{aligned}\nE[X]\n&= \\int_{0}^{\\infty}\n    x \\,\\frac{\\beta}{\\alpha}\n    \\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}\n    \\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right] dx = \\int_{0}^{\\infty}\n    (\\alpha u)\\,\\frac{\\beta}{\\alpha}\n    \\left(\\frac{\\alpha u}{\\alpha}\\right)^{\\beta-1}\n    \\exp\\!\\left[-\\left(\\frac{\\alpha u}{\\alpha}\\right)^{\\beta}\\right]\n    \\alpha\\,du \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    u\\,\\beta\\,u^{\\beta-1}\\exp[-u^{\\beta}]\\,\\alpha\\,du = \\alpha\\int_{0}^{\\infty}\n    \\beta\\,u^{\\beta}\\exp[-u^{\\beta}]\\,du \\\\[6pt]\n&= \\alpha\\int_{0}^{\\infty}\n    \\beta\\,v\\,e^{-v}\\,\\frac{1}{\\beta}\\,v^{\\frac{1}{\\beta}-1} dv\n    \\qquad (v = u^{\\beta}) \\\\ &= \\alpha\\int_{0}^{\\infty}\n    e^{-v}\\,v^{\\frac{1}{\\beta}}\\,dv = \\alpha\\,\\Gamma\\!\\left(\\frac{1}{\\beta}+1\\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\n\\[ \\small\n\\begin{aligned}\nE[X^{2}]\n&= \\int_{0}^{\\infty}\n    x^{2}\\,\\frac{\\beta}{\\alpha}\n    \\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}\n    \\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right] dx \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    (\\alpha u)^{2}\\,\\frac{\\beta}{\\alpha}\n    \\left(\\frac{\\alpha u}{\\alpha}\\right)^{\\beta-1}\n    \\exp[-u^{\\beta}]\\,\\alpha\\,du \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    \\alpha^{2}u^{2}\\,\\frac{\\beta}{\\alpha}\\,u^{\\beta-1}\n    e^{-u^{\\beta}}\\,\\alpha\\,du = \\int_{0}^{\\infty}\n    \\alpha^{2}\\beta\\,u^{\\beta+1}\\,e^{-u^{\\beta}}\\,du \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    \\alpha^{2}\\beta\\,u^{\\beta}\\,u\\,e^{-u^{\\beta}}\\,du = \\int_{0}^{\\infty}\n    \\alpha^{2}\\beta\\,v\\,v^{1/\\beta}\\,e^{-v}\\,\n    \\frac{1}{\\beta}\\,v^{1/\\beta-1}\\,dv\n    \\quad (v = u^{\\beta}) \\\\[6pt]&= \\alpha^{2}\n    \\int_{0}^{\\infty}\n    v^{\\,1/\\beta + 1 + 1/\\beta -1}\\,e^{-v}\\,dv = \\alpha^{2}\n    \\int_{0}^{\\infty}\n    v^{\\,2/\\beta}\\,e^{-v}\\,dv = \\alpha^{2}\\,\n    \\Gamma\\!\\left(\\frac{2}{\\beta}+1\\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nDe forma que,\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X)\n&= E(X^{2}) - [E(X)]^{2} \\\\[6pt]\n&= \\alpha^{2}\\,\\Gamma\\!\\left(\\frac{2}{\\beta}+1\\right)\n    - \\left[\\alpha\\,\\Gamma\\!\\left(\\frac{1}{\\beta}+1\\right)\\right]^{2} \\\\[6pt]\n&= \\alpha^{2}\\,\\Gamma\\!\\left(\\frac{2}{\\beta}+1\\right)\n    - \\alpha^{2}\\left[\\Gamma\\!\\left(\\frac{1}{\\beta}+1\\right)\\right]^{2} \\\\[6pt]\n&= \\alpha^{2}\n    \\left\\{\n      \\Gamma\\!\\left(\\frac{2}{\\beta}+1\\right)\n      - \\left[\\Gamma\\!\\left(\\frac{1}{\\beta}+1\\right)\\right]^{2}\n    \\right\\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nSe \\(X \\sim Weibull(\\alpha, \\beta)\\), então\n\\[\nf(x|\\alpha, \\beta) =\n\\begin{cases}\n\\dfrac{\\beta}{\\alpha}\n\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta - 1}\n\\exp\\!\\left[-\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta}\\right],\n& x\\geq0\\\\[10pt]\n0, & x&lt;0\n\\end{cases}\n\\]\ncom\n\\[E(X) = \\alpha \\Gamma\\left( \\dfrac{1}{\\beta} + 1\\right) \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\alpha^2\\left\\{\\Gamma\\left( \\dfrac{2}{\\beta} + 1\\right) - \\left[\\Gamma\\left( \\dfrac{1}{\\beta} + 1\\right)\\right]^2\\right\\}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nObservação: Se \\(X \\sim Weibull(\\alpha, 1)\\), ou seja, fazendo \\(\\beta = 1\\), temos\n\\[f(x) = \\dfrac{1}{\\alpha} \\left(\\dfrac{x}{\\alpha}\\right)^{1 - 1} \\exp\\!\\left[-\\left(\\dfrac{x}{\\alpha}\\right)^{1}\\right] = \\dfrac{1}{\\alpha}  \\exp\\!\\left(-\\dfrac{x}{\\alpha}\\right), \\,\\,\\,\\,\\,\\, x\\geq 0\\]\nFazendo \\(\\lambda = \\dfrac{1}{\\alpha}\\), temos \\(f(x) = \\lambda e^{-\\lambda x}\\). Logo \\(X \\sim Exp(\\lambda)\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nUma das vantagens da distribuição Weibull é a possibilidade de encontrar a sua função de distribuição parametrizada por \\(\\alpha\\) e \\(\\beta\\). Dessa forma fica fácil fazer cálculos de probabilidades.\n\nPor definição, \\(F(x) = P(X ≤ x)\\). Para \\(x \\leq 0\\) claramente \\(F(x) = 0\\). Para \\(x &gt; 0\\), temos:\n\\[F(x) = \\int_0^x \\dfrac{\\beta}{\\alpha}\\left(\\dfrac{t}{\\alpha}\\right)^{\\beta - 1} \\exp\\!\\left[-\\left(\\dfrac{t}{\\alpha}\\right)^{\\beta}\\right] \\,\\,dt\\]\nMudança de variável: \\(u=\\left(\\frac{t}{\\alpha}\\right)^{\\beta} \\;\\;\\Rightarrow\\;\\; du=\\frac{\\beta}{\\alpha}\\left(\\frac{t}{\\alpha}\\right)^{\\beta-1}dt.\\) Quando \\(t=0\\), \\(u=0\\); quando \\(t=x\\), \\(u=(x/\\alpha)^{\\beta}\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nLogo,\n\\[\nF(x)=\\int_{0}^{(x/\\alpha)^{\\beta}} e^{-u}\\,du = \\Big[-e^{-u}\\Big]_{0}^{(x/\\alpha)^{\\beta}} = 1-\\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right]\n\\]\nPortanto,\n\\[\nF(x|\\alpha, \\beta)=\n\\begin{cases}\n1-\\exp\\!\\left[-\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta}\\right], & x&gt; 0,\\\\[8pt]\n0, & x\\le0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\n\n\nFigure 7: Distribuição Weibull — variação de β (forma) com α fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\n\n\nFigure 8: Distribuição Weibull — variação de α (escala) com β fixo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nA Weibull é uma das distribuições mais usadas em engenharia para modelar tempo até falha/tempo de vida. Ela é extremamente flexível porque o parâmetro de forma \\(\\beta\\) permite que o risco aumente, diminua ou seja constante ao longo do tempo.\n\n\nEngenharia de Confiabilidade:\n\nvida útil de componentes mecânicos e eletrônicos\nfadiga de materiais\ntempo até quebra de peças, motores, rolamentos, cabos, soldas\n\n\n\n\n\nAnálise de Risco/Manutenção:\n\nplanejamento de manutenção preventiva\nprever quando um equipamento deve ser substituído"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\n\nAnálise de sobrevivência/biomedicina:\n\ntempo até ocorrência de um evento (recorrência de doença, óbito, falha de tratamento)\nalternativa mais flexível que exponencial\n\n\n\n\nMeteorologia e Clima:\n\ndistribuição de vento (velocidade do vento normalmente é modelada por Weibull)\n\n\n\n\n\nPesquisa operacional:\n\ntempo até falha em sistemas complexos\nmodelagem em teoria de filas com tempos de serviço não-exponenciais"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-12",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-12",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nExemplo 05: Uma empresa realiza treinamentos periódicos com seus funcionários. Em cada grupo de treinamento é passado uma tarefa desafio individual e os funcionários do grupo podem fazê-la durante o tempo que precisarem. O tempo que dura a tarefa desafio, em horas, pode ser considerada uma variável aleatória de Weibull com \\(\\alpha = 2\\) e \\(\\beta = 0,4\\).\n\nEm média, quanto tempo dura a tarefa desafio em um treinamento? R: \\(6,6467\\) \\((\\approx 6h38min)\\)\nQual a probabilidade da tarefa desafio durar menos de 8 horas? R: \\(0,8247\\)\nA tarefa desafio já está sendo realizada há 2 horas. Qual a probabilidade dela acabar nas próximas 2 horas? R: \\(0,2735\\)\nQual o menor tempo \\(t\\), em horas, para o qual podemos dizer que \\(95\\%\\) das tarefas desafio duram menos que \\(t\\)? R: \\(31,06615\\) \\((\\approx 31h04min)\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-13",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-weibull-13",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Weibull",
    "text": "Distribuição Weibull\nExemplo 06: Uma loja quer saber quanto tempo suas lâmpadas LED duram, para decidir garantia. Ela testa várias lâmpadas funcionando 24 horas por dia e anota o tempo até queimarem. Os dados mostram que quanto mais antiga a lâmpada, mais chance ela tem de queimar a qualquer momento, ou seja, os dados seguem uma distribuição de Weibull com parâmetros \\(\\alpha = 200\\) e \\(\\beta = 1,4\\).\n\nQual a probabilidade de uma lâmpada queimar antes de 150 dias? R: \\(0,4875\\)\nQual a probabilidade de uma lâmpada queimar entre 100 e 250 dias? R: \\(0,4296\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nUma variável \\(X\\) tem distribuição Log-Normal quando\n\\[\\ln(X) \\sim N(\\mu, \\sigma^2)\\]\nAssim, \\(X \\sim Log-Normal(\\mu, \\sigma^2)\\) se sua função densidade é dada por\n\\[\nf(x|\\mu, \\sigma) =\n\\begin{cases}\n\\dfrac{1}{x\\, \\sigma\\, \\sqrt{2\\pi}} \\,\\exp\\!\\left[-\\dfrac{1}{2}\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right)^2\\right],\n& x&gt;0\\\\[10pt]\n0, & x\\leq 0\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\\[\n\\begin{aligned}\nE(X)\n&= \\int_{0}^{\\infty}\n    x \\,\\frac{1}{x\\,\\sigma\\sqrt{2\\pi}}\\,\n    \\exp\\!\\left[\n      -\\frac{1}{2}\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right)^{2}\n    \\right] dx \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,\n    \\exp\\!\\left[\n      -\\frac{1}{2}\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right)^{2}\n    \\right] dx\n\\end{aligned}\n\\]\nMudança de variável: \\(z = \\ln(x) \\Rightarrow x = e^z, dx = e^z \\, dz\\). Quando \\(x \\in (0, \\infty) \\Rightarrow z \\in (-\\infty,\\infty)\\)\n\\[\n\\begin{aligned}\n&= \\int_{-\\infty}^{\\infty}\n   \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,\n   \\exp\\!\\left[\n     -\\frac12\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n   \\right]\\, e^{z}\\,dz \\\\[6pt]\n&= \\int_{-\\infty}^{\\infty}\n   \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,\n   \\exp\\!\\left[\n     -\\frac12\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n     + z\n   \\right]\\,dz\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nCompletando o quadrado do expoente:\n\\[\n\\begin{aligned}\nz - \\frac{(z-\\mu)^2}{2\\sigma^{2}}\n&= -\\frac{1}{2\\sigma^{2}}\\Big[(z-\\mu)^2 - 2\\sigma^{2}z\\Big] \\\\[6pt]\n&= -\\frac{1}{2\\sigma^{2}}\\Big[z^{2} - 2(\\mu+\\sigma^{2})z + \\mu^{2}\\Big] \\\\[6pt]\n&= -\\frac{1}{2\\sigma^{2}}\n    \\left[\n      (\\,z-(\\mu+\\sigma^{2})\\,)^2\n      -(\\mu+\\sigma^{2})^{2}\n      + \\mu^{2}\n    \\right] \\\\[6pt]\n&= -\\frac{(z-(\\mu+\\sigma^{2}))^{2}}{2\\sigma^{2}}\n    + \\frac{(\\mu+\\sigma^{2})^{2} - \\mu^{2}}{2\\sigma^{2}} \\\\[6pt]\n&= -\\frac{(z-(\\mu+\\sigma^{2}))^{2}}{2\\sigma^{2}}\n    + \\mu + \\frac{\\sigma^{2}}{2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nAssim,\n\\[ \\small\n\\begin{aligned}\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{1}{2}\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n   + z\n\\right] dz\n&=\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{\\big(z-(\\mu+\\sigma^{2})\\big)^{2}}{2\\sigma^{2}}\n   + \\mu + \\frac{\\sigma^{2}}{2}\n\\right] dz \\\\[6pt]\n&=\ne^{\\mu+\\sigma^{2}/2}\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{\\big(z-(\\mu+\\sigma^{2})\\big)^{2}}{2\\sigma^{2}}\n\\right] dz\n\\end{aligned}\n\\]\nA integral é 1 (é uma densidade Normal). Logo,\n\\[\n\\boxed{E(X)=\\exp\\!\\left(\\mu+\\frac{\\sigma^2}{2}\\right)}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nDa mesma forma,\n\\[\n\\begin{aligned}\nE(X^{2})\n&= \\int_{0}^{\\infty}\n    x^{2}\\,\n    \\frac{1}{x\\,\\sigma\\sqrt{2\\pi}}\\,\n    \\exp\\!\\left[\n      -\\frac12\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right)^{2}\n    \\right] dx \\\\[6pt]\n&= \\int_{0}^{\\infty}\n    \\frac{x}{\\sigma\\sqrt{2\\pi}}\\,\n    \\exp\\!\\left[\n      -\\frac12\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right)^{2}\n    \\right] dx\n\\end{aligned}\n\\]\nMudança de variável: \\(z = \\ln(x) \\Rightarrow x = e^z, dx = e^z \\, dz\\). Quando \\(x \\in (0, \\infty) \\Rightarrow z \\in (-\\infty,\\infty)\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\\[\n\\begin{aligned}\n&= \\int_{-\\infty}^{\\infty}\n   \\frac{e^{z}}{\\sigma\\sqrt{2\\pi}}\\,\n   \\exp\\!\\left[\n     -\\frac12\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n   \\right] e^{z}\\,dz \\\\[6pt]\n&= \\int_{-\\infty}^{\\infty}\n   \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,\n   \\exp\\!\\left[\n     -\\frac12\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n   \\right] e^{2z}\\,dz \\\\[6pt]\n&= \\int_{-\\infty}^{\\infty}\n   \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,\n   \\exp\\!\\left[\n     -\\frac12\\left(\\frac{z-\\mu}{\\sigma}\\right)^{2}\n     + 2z\n   \\right] dz\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nCompletando o quadrado do expoente:\n\\[\n\\begin{aligned}\n2z - \\frac{(z-\\mu)^2}{2\\sigma^{2}}\n&= -\\frac{1}{2\\sigma^{2}}\n    \\Big[(z-\\mu)^2 - 4\\sigma^{2}z\\Big] \\\\[6pt]\n&= -\\frac{1}{2\\sigma^{2}}\n    \\Big[z^{2} - 2(\\mu+2\\sigma^{2})z + \\mu^{2}\\Big] \\\\[6pt]\n&= -\\frac{1}{2\\sigma^{2}}\n    \\left[\n      (\\,z-(\\mu+2\\sigma^{2})\\,)^{2}\n      - (\\mu+2\\sigma^{2})^{2} + \\mu^{2}\n    \\right] \\\\[6pt]\n&= -\\frac{(z-(\\mu+2\\sigma^{2}))^{2}}{2\\sigma^{2}}\n    + \\frac{(\\mu+2\\sigma^{2})^{2} - \\mu^{2}}{2\\sigma^{2}} \\\\[6pt]\n&= -\\frac{(z-(\\mu+2\\sigma^{2}))^{2}}{2\\sigma^{2}}\n    + 2\\mu + 2\\sigma^{2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nAssim,\n\\[\\small\n\\begin{aligned}\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{1}{2}\\left(\\frac{z-\\mu}{\\sigma}\\right)^2 + 2z\n\\right] dz\n&=\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{(z-(\\mu+2\\sigma^{2}))^{2}}{2\\sigma^{2}}\n   + 2\\mu + 2\\sigma^{2}\n\\right] dz\n\\\\[6pt]\n&=\ne^{2\\mu + 2\\sigma^{2}}\n\\int_{-\\infty}^{\\infty}\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\n\\exp\\!\\left[\n   -\\frac{(z-(\\mu+2\\sigma^{2}))^{2}}{2\\sigma^{2}}\n\\right] dz\n\\end{aligned}\n\\]\nA integral é 1 (é uma densidade Normal). Logo,\n\\[\n\\boxed{E(X^2)=\\exp\\!\\left(2\\mu+2\\sigma^2\\right)}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nDe forma que,\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X)\n&= E(X^2) - [E(X)]^2 \\\\[4pt]\n&= \\exp\\!\\left(2\\mu + 2\\sigma^2\\right)\n    - \\left[\\exp\\!\\left(\\mu + \\frac{\\sigma^2}{2}\\right)\\right]^2 \\\\[4pt]\n&= \\exp\\!\\left(2\\mu + 2\\sigma^2\\right)\n    - \\exp\\!\\left(2\\mu + \\sigma^2\\right) \\\\[4pt]\n&= \\exp\\!\\left(2\\mu + \\sigma^2\\right)\\big(e^{\\sigma^2} - 1\\big)\n\\end{aligned}\n\\]\nAssim,\n\\[\n\\boxed{Var(X)=\\exp\\!\\left(\\,2\\mu+\\sigma^2\\right)\\big(e^{\\sigma^2}-1\\big)}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nSe \\(X \\sim Log-Normal(\\mu, \\sigma^2)\\), então\n\\[\nf(x|\\mu, \\sigma) =\n\\begin{cases}\n\\dfrac{1}{x\\, \\sigma\\, \\sqrt{2\\pi}} \\,\\exp\\!\\left[-\\dfrac{1}{2}\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right)^2\\right],\n& x&gt;0\\\\[10pt]\n0, & x\\leq 0\n\\end{cases}\n\\]\ncom\n\\[E(X) = \\exp\\!\\left(\\mu+\\frac{\\sigma^2}{2}\\right) \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\exp\\!\\left(\\,2\\mu+\\sigma^2\\right)\\big(e^{\\sigma^2}-1\\big)\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nA distribuição Log-Normal não possui forma fechada para a função de distribuição acumulada. No entanto,\n\\[F_X(x)=P(X\\le x)=\\Phi\\!\\left(\\frac{\\ln x - \\mu}{\\sigma}\\right), \\quad x&gt;0,\\]\nonde \\(\\Phi(\\cdot)\\) é a FDA da Normal padrão."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\n\nFigure 9: Distribuição Lognormal — variação de μ (com σ fixo)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-12",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-12",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\n\nFigure 10: Distribuição Lognormal — variação de σ (com μ fixo)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-13",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-13",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\n\nFigure 11: Distribuição Lognormal — FDC variando μ (σ fixo)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-14",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-14",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\n\nFigure 12: Distribuição Lognormal — FDC variando σ (μ fixo)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-15",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-15",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nA distribuição Lognormal aparece quando um processo multiplicativo gera a variável observada. Como \\(\\ln(X)\\) é Normal, isso quer dizer que \\(X\\) nasce como produto de vários pequenos fatores aleatórios. Por isso, a Lognormal é muito comum em:\n\n\nEconomia e Finanças: distribuição de valores de ações, tempo até certos eventos econômicos, modelos de volatilidade e retornos acumulados\n\n\n\n\nBiologia e Medicina: tempos de incubação de doenças, tempos de sobrevivência em certos contextos, concentração (positiva) de substâncias em fluidos biológicos"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-16",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-16",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\n\nEngenharias/Confiabilidade: vida útil de componentes quando o desgaste é multiplicativo, dureza de materiais, diâmetro de partículas (tamanho de grãos)\n\n\n\nCiências Ambientais: distribuição de poluentes positivos (\\(CO_2\\), etc.), precipitação acumulada em certos modelos"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-17",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-17",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nExemplo 07: A duração do atendimento de cada cliente no caixa de um supermercado tem distribuição Lognormal com parâmetro de locação \\(\\mu = 1,5\\) e parâmetro de dispersão \\(\\sigma = 0,5\\).\n\nQual a média e variância da duração dos atendimentos? R: \\(E(X) = 5,0784\\) e \\(Var(x) = 7,3251\\)\nQual a probabilidade de um atendimento durar menos de 5 minutos? R: \\(0,5871\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-18",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-log-normal-18",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Log-Normal",
    "text": "Distribuição Log-Normal\nExemplo 08: Considere o tempo de reparo \\(X\\) (em horas) de equipamentos. Admita que \\[\n\\ln(X) \\sim N(\\mu,\\sigma^2), \\qquad \\mu=0,2\\,\\,\\,\\,\\text{e}\\,\\,\\,\\, \\sigma=0,6.\n\\]\nResponda:\n\nCalcule \\(P(X \\le 1,5)\\). R: \\(0,6331\\)\n\nCalcule \\(P(1 \\le X \\le 3)\\). R: \\(0,5625\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nTambém conhecida como Distribuição de Laplace, é formada por reflexão da distribuição exponencial em torno da média.\n\nSe \\(X \\sim Laplace(a, b)\\), então sua função densidade é dada por\n\\[\nf(x)= \\frac{1}{2b}\\, \\exp\\!\\left(-\\frac{|x-a|}{b}\\right), \\qquad -\\infty &lt; x &lt; \\infty,\\; -\\infty &lt; a &lt; \\infty,\\; b &gt; 0.\n\\]\nNesta parametrização:\n\n\\(a\\): parâmetro de localização (a média e mediana da distribuição).\n\\(b\\): parâmetro de escala (controla a dispersão; quanto maior \\(b\\), mais “achatada” é a curva)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\nPara \\(x \\ge a\\), exponencial decaindo para a direita\n\n\\[\nf(x)= \\frac{1}{2b}\\, \\exp\\!\\left(-\\frac{x-a}{b}\\right)\n\\]\n\nPara \\(x &lt; a\\), exponencial decaindo para a esquerda\n\n\\[\nf(x)= \\frac{1}{2b}\\, \\exp\\!\\left(\\frac{x-a}{b}\\right)\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#aparte-funções-pares-e-ímpares",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#aparte-funções-pares-e-ímpares",
    "title": "Outras Distribuições Contínuas",
    "section": "Aparte: Funções Pares e Ímpares",
    "text": "Aparte: Funções Pares e Ímpares\nDefinições:\n\nUma função \\(f(x)\\) é par se\n\n\\[  f(-x) = f(x), \\quad \\forall x\\]\n→ Gráfico simétrico em relação ao eixo y. Exemplos: \\(f(x) = x^2, \\cos x, e^{-x^2}\\)\n\nUma função \\(f(x)\\) é ímpar se\n\n\\[f(-x) = -f(x), \\quad \\forall x\\] → Gráfico simétrico em relação à origem. Exemplos: \\(f(x) = x^3, \\sin x, x e^{-x^2}\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#aparte-funções-pares-e-ímpares-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#aparte-funções-pares-e-ímpares-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Aparte: Funções Pares e Ímpares",
    "text": "Aparte: Funções Pares e Ímpares\nPara integrais em intervalos simétricos \\([-a, a]\\):\n\nSe \\(f(x)\\) é par:\n\n\\[\\int_{-a}^{a} f(x)\\,dx = 2\\int_{0}^{a} f(x)\\,dx\\]\n\nSe \\(f(x)\\) é ímpar:\n\n\\[\\int_{-a}^{a} f(x)\\,dx = 0\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nVamos encontrar \\(E(X)\\). Para isso, tomamos \\(Z = X-a\\). Logo, \\(Z \\sim Laplace(0,b)\\) com\n\\[\nf_Z(z)= \\dfrac{1}{2b}\\, \\exp\\!\\left(-\\frac{|z|}{b}\\right)\n\\] e \\(E(X) = E(Z + a) = E(Z) + a\\)\n\\[\n\\begin{aligned}\nE(Z)\n&= \\int_{-\\infty}^{\\infty} z\\,f_Z(z)\\,dz\n  = \\frac{1}{2b} \\int_{-\\infty}^{\\infty} z\\,e^{-|z|/b}\\,dz \\\\[6pt]\n&= \\frac{1}{2b}\n    \\left(\n      \\int_{-\\infty}^{0} z\\,e^{z/b}\\,dz\n      +\n      \\int_{0}^{\\infty} z\\,e^{-z/b}\\,dz\n    \\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nNote que o integrando \\(z\\,e^{-|z|/b}\\) é ímpar, portanto as áreas se cancelam:\n\\[E(Z)=0\\]\nde forma que,\n\\[E(X)= E(Z+a) = E(Z) + a = a\\]\nLogo,\n\\[\\boxed{E(X)=a}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nCálculo de \\(Var(Z)=E(Z^2)\\) (pois \\((E(Z)=0\\)):\n\\[\n\\begin{aligned}\nE(Z^{2})\n&= \\int_{-\\infty}^{\\infty} z^{2}\\,f_Z(z)\\,dz \\\\[6pt]\n&= \\int_{-\\infty}^{\\infty} z^{2}\\,\\frac{1}{2b}\\,e^{-|z|/b}\\,dz\n\\end{aligned}\n\\]\nComo o integrando é par,\n\\[\nE(Z^2)=\\int_{0}^{\\infty} z^{2} \\frac{1}{b} e^{-z/b}\\,dz\n\\]\nFaça a mudança \\(y=z/b\\Rightarrow z=by,\\ dz=b\\,dy\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\\[\n\\begin{aligned}\nE(Z^{2})\n&= \\int_{0}^{\\infty} z^{2}\\,\\frac{1}{b}\\,e^{-z/b}\\,dz \\\\[6pt]\n&= \\int_{0}^{\\infty} (b y)^{2}\\,\\frac{1}{b}\\,e^{-y}\\,b\\,dy \\\\[6pt]\n&= b^{2}\\int_{0}^{\\infty} y^{2} e^{-y}\\,dy\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nPela definição da função Gama,\n\\[\\int_{0}^{\\infty} y^{2} e^{-y}\\,dy=\\Gamma(3)=2!\\]\nPortanto,\n\\[E(Z^2)=b^{2}\\cdot 2 = 2b^{2}\\]\n\nComo \\(Var(X)=Var(Z)=E(Z^2)\\),\n\\[\\boxed{Var(X)=2b^{2}}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nSe \\(X \\sim Laplace(a, b)\\), então\n\\[\nf(x)= \\frac{1}{2b}\\, \\exp\\!\\left(-\\frac{|x-a|}{b}\\right), \\qquad -\\infty &lt; x &lt; \\infty,\\; -\\infty &lt; a &lt; \\infty,\\; b &gt; 0.\n\\]\ncom\n\\[E(X) = a \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = 2b^{2}\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nSe \\(X \\sim Laplace(a,b)\\), então,\n\\[F(x)=P(X\\le x)=\\int_{-\\infty}^{x} f(t)\\,dt = \\int_{-\\infty}^{x} \\frac{1}{2b}e^{-\\frac{|t-a|}{b}}\\,dt\\]\nComo a função é definida por módulos, dividimos o cálculo em dois casos.\n\nCaso 1: \\(x &lt; a\\)\nNeste intervalo, \\(|t-a|=a-t\\). Logo\n\\[F(x)=\\int_{-\\infty}^{x}\\frac{1}{2b}e^{-(a-t)/b}\\,dt\n=\\frac{1}{2b}e^{-a/b}\\int_{-\\infty}^{x}e^{t/b}\\,dt\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nCalculando a integral:\n\\[\\int_{-\\infty}^{x} e^{t/b}\\,dt = \\Big[b\\,e^{t/b}\\Big]_{-\\infty}^{x} = b\\,e^{x/b} - b\\,\\lim_{t\\to -\\infty} e^{t/b} = b\\,e^{x/b}\\]\nUma vez que \\(\\lim_{t\\to -\\infty} e^{t/b}=0\\). Então:\n\\[F(x)=\\frac{1}{2b}e^{-a/b}\\,b\\,e^{x/b} =\\dfrac{1}{2} e^{\\Big({\\dfrac{x-a}{b}}\\Big)}, \\qquad x&lt;a\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nCaso 2: \\(x \\ge a\\)\nAqui \\(|t-a|=t-a\\). Assim:\n\\[F(x)=\\int_{-\\infty}^{a}\\frac{1}{2b}e^{-(a-t)/b}\\,dt + \\int_{a}^{x}\\frac{1}{2b}e^{-(t-a)/b}\\,dt\\]\nA primeira integral resulta em:\n\\[\n\\begin{aligned}\n\\int_{-\\infty}^{a} \\frac{1}{2b}\\, e^{-(a-t)/b}\\,dt\n&= \\frac{e^{-a/b}}{2b}\\int_{-\\infty}^{a} e^{t/b}\\,dt = \\frac{e^{-a/b}}{2b}\\,\\Big[b\\,e^{t/b}\\Big]_{-\\infty}^{a} \\\\[6pt]\n&= \\frac{e^{-a/b}}{2b}\\,\\Big(b\\,e^{a/b}-0\\Big) = \\frac{1}{2}\\,e^{-a/b}e^{a/b} = \\frac{1}{2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nPara a segunda integral, fazemos a substituição \\(u = t - a  \\Rightarrow  du = dt\\). Quando \\(t = a \\Rightarrow u = 0\\) e quando \\(t = x \\Rightarrow u = x - a\\).\n\\[\n\\begin{aligned}\n\\int_{a}^{x}\\frac{1}{2b}\\,e^{-(t-a)/b}\\,dt\n&= \\frac{1}{2b}\\int_{0}^{\\,x-a} e^{-u/b}\\,du = \\frac{1}{2b}\\left[-b\\,e^{-u/b}\\right]_{0}^{\\,x-a} \\\\[6pt]\n&= \\frac{1}{2b}\\left[-b\\,e^{-(x-a)/b} + b\\right] = \\frac{1}{2b}\\cdot b\\,(1 - e^{-(x-a)/b}) \\\\[6pt]\n&= \\frac{1}{2}\\left(1 - e^{-\\frac{x-a}{b}}\\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-12",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-12",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nSomando:\n\\[ F(x)=\\frac{1}{2}+\\frac{1}{2}(1-e^{-(x-a)/b}) =1 - \\dfrac{1}{2} e^{-\\Big(\\dfrac{x-a}{b}\\Big)}, \\qquad x\\ge a\\] Logo, se \\(X \\sim Laplace(a,b)\\), então\n\\[\nF(x)=\n\\begin{cases}\n\\dfrac{1}{2} e^{\\Big({\\dfrac{x-a}{b}}\\Big)}, & x&lt;a, \\\\[8pt]\n1 - \\dfrac{1}{2} e^{-\\Big(\\dfrac{x-a}{b}\\Big)}, & x\\ge a\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-13",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-13",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\n\nFigure 13: Distribuição Laplace — diferentes parâmetros (função densidade)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-14",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-14",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\n\nFigure 14: Distribuição Laplace — diferentes parâmetros (função de distribuição acumulada)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-15",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-15",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nA distribuição Laplace (também chamada de exponencial dupla) aparece em diversas áreas onde há simetria, mas com caudas mais pesadas que a normal.\n\n\nFigure 15: Comparação lado a lado: Laplace(0, 1/√2) vs Normal(0,1)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-16",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-16",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\n\nNo painel esquerdo (escala linear): a Laplace tem pico mais alto e mais pontudo no centro.\nNo painel direito (escala log): as caudas da Laplace decaem mais lentamente que as da Normal — ou seja, a Laplace tem caudas mais pesadas."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-17",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-17",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\n\nFigure 16: CDF: Normal(0,1) vs Laplace(0, 1/√2)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-18",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-18",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\nModelagem de Erros e Ruídos: Em muitos fenômenos, os erros são simétricos, mas com maior probabilidade de valores extremos do que uma normal permitiria.\n\n\n\nEconomia e Finanças: Em séries de retornos de ativos financeiros, é comum observar distribuições simétricas com caudas longas.\n\n\n\n\nEngenharia de Processos e Controle: Modelagem de diferenças entre medições ou resíduos em sistemas físicos. Muito usada em filtros robustos e em controle adaptativo, pois é menos sensível a outliers do que a Normal.\n\n\n\n\nProcessamento de Sinais e Imagens: Em processamento de imagem, a distribuição Laplace descreve coeficientes de transformadas, especialmente onde há bordas ou ruídos bruscos. Também aparece em compressão de imagem e remoção de ruído impulsivo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-19",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-19",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\nCiência de Dados e Estatística Robusta: O modelo Laplace é base para a Regressão de Mínima Soma de Desvios Absolutos (LAD), também chamada regressão mediana. O estimador de máxima verossimilhança sob erro Laplace é o estimador da mediana, o que torna a Laplace uma escolha natural para modelos robustos a outliers.\n\n\n\nPrivacidade Diferencial: Em Ciência de Dados, o Mecanismo Laplace é usado para adicionar ruído calibrado e proteger dados sensíveis. A distribuição Laplace permite controlar a quantidade de ruído adicionada de acordo com o parâmetro de privacidade \\(\\epsilon\\)."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-20",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-20",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nExemplo 09: Considere que o retorno financeiro de dado investimento possa ser modelado de acordo com um distribuição de Laplace, com parâmetros \\(a = \\, R\\$ \\, 1 \\text{milhão}\\) e \\(b = 20 \\, \\text{mil}\\).\n\nCalcule a probabilidade do retorno ser superior a \\(R\\$ \\, 1.020.000,00\\). R: \\(0,1839\\)\nCalcule a probabilidade do retorno ser inferior a \\(R\\$ \\, 940.000,00\\). R: \\(0,0249\\)\nCalcule a probabilidade do retorno ficar entre \\(R\\$ \\, 940.000,00\\) e \\(R\\$ \\, 1.020.000,00\\). R: \\(0,7912\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-21",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-21",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\nExemplo 10: Uma câmera digital utilizada em um ambiente industrial está sujeita a reflexos de luz intensa e interferências elétricas, que produzem ruído impulsivo nas imagens. Esse ruído pode ser modelado pela distribuição de Laplace, cuja função densidade de probabilidade é dada por:\n\\[f(x) = \\frac{1}{2b}\\, e^{-\\frac{|x - a|}{b}}, \\quad -\\infty &lt; x &lt; \\infty,\\]\nonde: - \\(a\\) é o valor médio (esperado) do ruído, - \\(b\\) é o parâmetro de escala que controla a dispersão.\nEm uma determinada medição, assume-se que:\n\\[a = 0, \\quad b = 10\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-22",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-22",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\nCalcule a probabilidade de que a perturbação no brilho de um pixel seja maior que 20 unidades em valor absoluto (ou seja, (|X| &gt; 20)). R: \\(0,1353\\)\nCalcule a probabilidade de que a variação do brilho esteja entre -15 e 15 unidades. R: \\(0,7769\\)\nCompare esse comportamento com o ruído Gaussiano \\(N(0, 10^2)\\). O ruído Laplaciano gera mais ou menos pixels “fora da faixa normal” (\\(|X| &gt; 20\\))? Explique o motivo, relacionando ao formato das caudas."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-23",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-exponencial-dupla-23",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição Exponencial Dupla",
    "text": "Distribuição Exponencial Dupla\n\nRuído Laplaciano (a=0, b=10) e comparação com Normal(0,10)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nEm muitas situações práticas, não estamos interessados na média ou no comportamento típico dos dados, mas sim nos eventos extremos, os maiores ou menores valores observados.\nAssim, temos duas possibilidades:\n\nDistribuição do Menor Valor Extremo\nDistribuição do Maior Valor Extremo"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-1",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-1",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nA Distribuição de Gumbel é um caso particular da teoria dos valores extremos. Ela descreve o comportamento assintótico de máximos ou mínimos em grandes amostras.\n\n\nDistribuição do Maior Valor Extremo (Gumbel Máximo)\n\nUsada para modelar valores máximos observados, por exemplo:\n\na maior temperatura anual,\na maior cheia de um rio,\no maior prejuízo financeiro."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-2",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-2",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nA função de distribuição acumulada (FDC) é:\n\\[F(x) = \\exp\\!\\left[-\\,e^{-\\Big(\\dfrac{x-\\mu}{\\sigma}\\Big)}\\right], \\qquad x \\in \\mathbb{R},\\]\nonde:\n\n\\(\\mu\\) é o parâmetro de localização,\n\\(\\sigma &gt; 0\\) é o parâmetro de escala."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-3",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-3",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nA função densidade é:\n\\[\\small f(x \\mid \\mu, \\sigma)\n= \\frac{1}{\\sigma}\n\\exp\\!\\left[\n-\\left(\n\\frac{x - \\mu}{\\sigma}\n\\right)\n- \\exp\\!\\left(\n-\\frac{x - \\mu}{\\sigma}\n\\right)\n\\right],\nx \\in \\mathbb{R},\\;\n\\mu \\in \\mathbb{R},\\;\n\\sigma &gt; 0\\]\nÉ possível demonstrar que,\n\\[E(X) = \\mu + \\gamma\\sigma,\\]\nonde \\(\\gamma = 0.57721566\\) é conhecida como constante de Euler–Mascheroni.\ne,\n\\[Var(X) = \\dfrac{\\pi^2}{6}\\sigma^2\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-4",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-4",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nSe \\(X \\sim Gumbel_{\\text{max}}(\\mu, \\sigma)\\), então\n\\[\nf(x) = \\frac{1}{\\sigma} \\exp\\!\\left[-\\left(\\frac{x - \\mu}{\\sigma}\\right)- \\exp\\!\\left(-\\frac{x - \\mu}{\\sigma}\\right)\\right]\n\\]\ncom\n\\[E(X) = \\mu + \\gamma\\sigma \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\dfrac{\\pi^2}{6}\\sigma^2\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-5",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-5",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\n\nFigure 17: Gumbel — Maior Valor Extremo: diferentes parâmetros"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-6",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-6",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\nDistribuição do Menor Valor Extremo (Gumbel Mínimo)\n\nUsada para modelar valores mínimos, por exemplo:\n\na menor temperatura do inverno,\na menor resistência de um material antes da falha,\no menor tempo até um evento extremo."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-7",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-7",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nA função de distribuição acumulada é:\n\\[F(x) = 1 - \\exp\\!\\left[-\\,e^{\\Big(\\dfrac{x-\\mu}{\\sigma}\\Big)}\\right], \\qquad x \\in \\mathbb{R}\\] A função densidade correspondente é:\n\\[\n\\small\nf(x|\\mu, \\sigma) = \\dfrac{1}{\\sigma}\\exp\\!\\left[\\Big(\\dfrac{x - \\mu}{\\sigma}\\Big)- \\exp\\!\\left(\\dfrac{x - \\mu}{\\sigma}\\right)\\right],\nx \\in \\mathbb{R},\\;\n\\mu \\in \\mathbb{R},\\;\n\\sigma &gt; 0\n\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-8",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-8",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nÉ possível demonstrar que,\n\\[E(X) = \\mu - \\gamma\\sigma,\\]\nonde \\(\\gamma = 0.57721566\\) é a constante de Euler–Mascheroni.\ne,\n\\[Var(X) = \\dfrac{\\pi^2}{6}\\sigma^2\\]\n\nObserve que a variância é a mesma; apenas o sinal da média muda."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-9",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-9",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nSe \\(X \\sim Gumbel_{\\text{min}}(\\mu, \\sigma)\\), então\n\\[\nf(x) = \\dfrac{1}{\\sigma}\\exp\\!\\left[\\Big(\\dfrac{x - \\mu}{\\sigma}\\Big)- \\exp\\!\\left(\\dfrac{x - \\mu}{\\sigma}\\right)\\right]\n\\]\ncom\n\\[E(X) = \\mu - \\gamma\\sigma \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, \\text{       e       } \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,Var(X) = \\dfrac{\\pi^2}{6}\\sigma^2\\]"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-10",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-10",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\n\nFigure 18: Gumbel — Menor Valor Extremo: diferentes parâmetros"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-11",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-11",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nRelação entre as duas formas\nNote que o Gumbel do mínimo é obtido invertendo o sinal de \\(x\\):\n\\[\nX_{\\text{mínimo}} \\sim \\text{Gumbel Mínimo}(\\mu, \\sigma)\n\\quad \\Leftrightarrow \\quad\n-Y \\sim \\text{Gumbel Máximo}(-\\mu, \\sigma),\n\\]\nou seja, o Gumbel mínimo é simplesmente o reflexo do Gumbel máximo em torno do eixo vertical."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-12",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-12",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\n\nFigure 19: Comparação entre Gumbel Máximo e Gumbel Mínimo"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-13",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-13",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\n\nO Gumbel Máximo tem cauda longa à direita → eventos de máximos (chuvas, enchentes, picos).\nO Gumbel Mínimo tem cauda longa à esquerda → eventos de mínimos (temperaturas mínimas, falhas).\nParâmetro \\(\\mu\\): define o centro.\nParâmetro \\(\\sigma\\): define a dispersão e intensidade dos extremos."
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-14",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-14",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nExemplo 11: Considere que a temperatura de operação para um determinado processo industrial possa ser modelada através de uma distribuição do Menor Valor Extremo, com parâmetros \\(\\mu = 30^o \\,C\\) e \\(\\sigma = 2\\). Valores de temperatura abaixo de \\(20^o\\,C\\) são raros, porém quando acontecem, inviabilizam o processo. Determine a probabilidade disso ocorrer, bem como a temperatura média do processo. R: \\(0,0067\\) \\(E(X) = 28,85\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-15",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-15",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\nExemplo 12: Uma equipe de engenheiros hidrólogos está estudando o nível máximo anual do Rio Paraopeba (em metros acima do leito) para dimensionar obras de contenção. Com base em 30 anos de registros históricos, o nível máximo anual pode ser modelado por uma Distribuição de Gumbel do Máximo com parâmetros:\n\\[\\mu = 6 \\,\\,\\text{m} \\,\\,\\,\\text{       e       } \\,\\,\\,\\sigma = 0,4\\]\nQuer-se saber:\n\nQual é a probabilidade de o nível máximo anual ultrapassar 7 metros? R: \\(0,0789\\)\nQual é o nível esperado (médio) das cheias anuais?R: \\(6,23 \\, \\text{m}\\)"
  },
  {
    "objectID": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-16",
    "href": "aulas/outras_distr_continuas/outras_dist_continuas.html#distribuição-de-valores-extremos-16",
    "title": "Outras Distribuições Contínuas",
    "section": "Distribuição de Valores Extremos",
    "text": "Distribuição de Valores Extremos\n\n\n\n\nFigure 20: Distribuição de Gumbel (Maior Valor Extremo) — Exemplo: nível máximo anual do Rio Paraopeba"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nCalculamos algumas características de uma variável aleatória \\(X\\), tais como \\(E(X)\\) e \\(Var(X)\\), através da distribuição de probabilidade de \\(X\\)\n\nVimos que a variância pode ser expressa como uma função da esperança das duas primeiras potências de \\(X\\), ou seja,\n\\[Var(X) = E(X^2) - \\Big[E(X)\\Big]^2\\]\n\n\nOutras características da distribuição de probabilidade de \\(X\\) podem ser expressas por meio das esperanças das potências de \\(X\\) como por exemplo coeficientes de assimetria e curtose."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-1",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-1",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\n\n\n\n\n\n\n\nDefinição 01: Momentos\n\n\nSeja \\(X\\) uma variável aleatória. Então, o k-ésimo momento de \\(X\\), denotado por \\(\\mu'_k\\) é definido como,\n\\[\\mu'_k = E(X^k)\\]\ndesde que essa quantidade exista. O k-ésimo momento central de uma variável aleatória \\(X\\), denotado por \\(\\mu_k\\) é definido como,\n\\[\\mu^k = E\\Big[X - E(X)\\Big]^k\\]\nsempre que essa quantidade existir."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-2",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-2",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nNote que,\n\n\\(E(X) = \\mu'_1\\)\n\n\n\n\\(Var(X) = \\mu_2 = \\mu'_2 - [\\mu'_1]^2\\)\n\n\n\n\nPara qualquer variável aleatória, \\(\\mu_1 = 0\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-3",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-3",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\n\nSe \\(X\\) é uma variável aleatória discreta,\n\n\\[\\mu'_k = E(X^k) = \\sum_{i=1}^{\\infty} x_i^k p(x_i)\\]\n\n\nSe \\(X\\) é uma variável aleatória contínua,\n\n\\[\\mu'_k = E(X^k) = \\int_{-\\infty}^{\\infty} x_i^k f(x) \\, dx\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-4",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-4",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\n\n\n\n\n\n\n\nExemplo 01: Momentos da distribuição Gamma\n\n\nEncontre o \\(k\\)-ésimo momento de \\(X \\sim Gamma(\\alpha, \\lambda)\\).\n\n\n\n\n\nSolução: Temos que, se \\(X \\sim Gamma(\\alpha, \\lambda)\\), então sua função densidade é dada por,\n\\[\nf(x \\mid \\alpha,\\lambda) =\n\\begin{cases}\n\\dfrac{\\lambda e^{-\\lambda x}(\\lambda x)^{\\alpha-1}}{\\Gamma(\\alpha)}, & x\\ge 0,\\\\[6pt]\n0, & x&lt;0\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-5",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-5",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nAssim,\n\\[\n\\begin{aligned}\nE(X^k) &= \\int_0^\\infty x^k f(x\\mid \\alpha,\\lambda)\\, dx = \\int_0^\\infty x^k\n\\frac{\\lambda e^{-\\lambda x}(\\lambda x)^{\\alpha-1}}\n{\\Gamma(\\alpha)}\\, dx \\\\[6pt]\n&= \\int_0^\\infty x^k\n\\frac{\\lambda e^{-\\lambda x}\\lambda^{\\alpha-1} \\, x^{\\alpha-1}}\n{\\Gamma(\\alpha)}\\, dx = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}\n\\int_0^\\infty x^{\\alpha+k-1} e^{-\\lambda x}\\, dx\n\\end{aligned}\n\\]\nNote que a integral é quase a função gama, a não ser pelo termo \\(e^{-\\lambda x}\\). Seja então a seguinte mudança de variável,\n\\[u = \\lambda  x \\,\\,\\, \\Rightarrow \\,\\,\\, x = \\dfrac{u}{\\lambda}, \\qquad dx = \\dfrac{du}{\\lambda}\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-6",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-6",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nAssim,\n\\[\n\\begin{aligned}\nE(X^k) &=  \\dfrac{\\lambda^\\alpha}{\\Gamma(\\alpha)}\n\\int_0^\\infty x^{\\alpha+k-1} e^{-\\lambda x}\\, dx  = \\dfrac{\\lambda^\\alpha}{\\Gamma(\\alpha)}\n\\int_0^\\infty \\Big(\\dfrac{u}{\\lambda}\\Big)^{\\alpha+k-1} e^{-u}\\, \\dfrac{du}{\\lambda} \\\\[6pt] &= \\dfrac{\\lambda^\\alpha}{\\lambda ^{\\alpha + k}\\,\\Gamma(\\alpha)}\n\\int_0^\\infty u^{\\alpha+k-1} e^{-u}\\, du = \\dfrac{\\lambda^\\alpha \\Gamma(\\alpha + k)}{\\lambda ^{\\alpha + k}\\,\\Gamma(\\alpha)} \\\\[6pt] &= \\dfrac{\\Gamma(\\alpha+k)}{\\Gamma(\\alpha)\\lambda^k}\n\\end{aligned}\n\\]\nMas,\n\\[\n\\Gamma(\\alpha+k) = (\\alpha+k-1)(\\alpha+k-2)\\cdots(\\alpha+1)\\alpha\\Gamma(\\alpha)\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-7",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-7",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nDe forma que, o \\(k\\)-ésimo momento de uma variável aleatória \\(X \\sim Gamma (\\alpha, \\lambda)\\) é dado por\n\\[\nE(X^k)\n=\n\\frac{\\alpha(\\alpha+1)\\cdots(\\alpha+k-1)}{\\lambda^k}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-8",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-8",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\n\n\n\n\n\n\n\nExemplo 02: Momentos da distribuição Weibull\n\n\nEncontre o \\(k\\)-ésimo momento de \\(X \\sim Weibull(\\alpha, \\beta)\\).\n\n\n\n\n\nSolução: Temos que, se \\(X \\sim Weibull(\\alpha, \\beta)\\), então sua função densidade é dada por,\n\\[\nf(x \\mid \\alpha,\\beta)=\n\\begin{cases}\n\\dfrac{\\beta}{\\alpha}\n\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta-1}\n\\exp\\!\\left[-\\left(\\dfrac{x}{\\alpha}\\right)^{\\beta}\\right], & x\\ge 0,\\\\[6pt]\n0, & x&lt;0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-9",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-9",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nAssim,\n\\[\n\\begin{aligned}\nE(X^k) &= \\int_0^\\infty x^k\n\\frac{\\beta}{\\alpha}\n\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}\n\\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right] dx\n\\end{aligned}\n\\]\nMudança de variável:\n\\[\nu = \\left(\\frac{x}{\\alpha}\\right)^{\\beta}\n\\quad\\Rightarrow\\quad\nx = \\alpha u^{1/\\beta},\\qquad\ndx = \\alpha \\frac{1}{\\beta} u^{1/\\beta - 1} du\n\\]\nAlém disso:\n\\[\nx^k = \\alpha^k u^{k/\\beta},\n\\qquad\n\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}=u^{(\\beta-1)/\\beta},\n\\qquad\n\\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right]=e^{-u}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-10",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#momentos-10",
    "title": "Função Geradora de Momentos",
    "section": "Momentos",
    "text": "Momentos\nlogo,\n\\[\n\\begin{aligned}\nE(X^k) &= \\int_0^\\infty x^k\n\\frac{\\beta}{\\alpha}\n\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1}\n\\exp\\!\\left[-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}\\right] dx \\\\[6pt] &= \\int_0^\\infty\n\\alpha^k u^{k/\\beta}\\,\n\\frac{\\beta}{\\alpha}\\,\nu^{(\\beta-1)/\\beta}\\,\ne^{-u}\\,\n\\alpha \\frac{1}{\\beta}u^{1/\\beta -1}\\,du \\\\[6pt] &= \\alpha^k \\int_0^\\infty\nu^{\\frac{k+\\beta}{\\beta}-1}\ne^{-u}\\,du = \\alpha^k\\,\\,\\Gamma\\!\\left(1+\\frac{k}{\\beta}\\right)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nDefinição 02: Função Geradora de Momentos\n\n\nSeja \\(X\\) uma variável aleatória qualquer. A função geradora de momentos (FGM) de \\(X\\), denotada por \\(M_X\\), é definida por\n\\[\nM_X(t)=E(e^{tX}),\n\\]\npara valores de \\(t\\) em um intervalo contendo \\(0\\) onde a experença exista.\n\n\n\n\nImportante: a função geradora de momentos é função de \\(t\\). Para ela existir basta que exista \\(\\varepsilon &gt; 0\\) tal que \\(E(e^{tX})\\) esteja bem definida para qualquer \\(t \\in (-\\varepsilon, \\varepsilon)\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-1",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-1",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nNote que a definição de função geradora de momentos é feita independente do tipo de variável, mas a forma de encontrá-la depende se a variável for discreta ou contínua, isto é,\n\nSe \\(X\\) é discreta,\n\n\\[M_X(t) = E(e^{tX}) = \\sum_{\\forall x \\in S_X} \\, e^{tx} p_X(x)\\]\n\nSe \\(X\\) é contínua,\n\n\\[M_X(t) = E(e^{tX}) = \\int_{-\\infty}^{\\infty} \\, e^{tx} f_X(x) \\, dx\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-2",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-2",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nTeorema 01\n\n\nSuponha que a função geradora de momentos de \\(X\\) exista para \\(|t| &lt; \\varepsilon\\), \\(\\varepsilon &gt; 0\\). Então, \\(E(X^k)\\) existe para \\(k = 1, 2, \\cdots\\) e temos:\n\\[E(X^k) = \\dfrac{d^k}{dt^k} M_X(t) \\Bigg|_{t=0}\\]\nou seja, o \\(k\\)-ésimo momento de \\(X\\) é igual à derivada de ordem \\(k\\) de \\(M_X(t)\\) avaliada em \\(t = 0\\).\n\n\n\n\nDemonstração: Suponha que a função geradora de momentos de \\(X\\) exista para todo \\(t\\) tal que \\(|t|&lt;\\varepsilon\\), com \\(\\varepsilon&gt;0\\), isto é,\n\\[\nM_X(t)=E(e^{tX})&lt;\\infty,\\qquad |t|&lt;\\varepsilon.\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-3",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-3",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nPela série de Maclaurin da função exponencial, para qualquer número real \\(y\\) temos \\[\ne^{y} = \\sum_{n=0}^{\\infty} \\frac{y^n}{n!}\n\\]\nAplicando isso a \\(y=tX\\), obtemos, para cada \\(t\\) com \\(|t|&lt;\\varepsilon\\), \\[\ne^{tX} = \\sum_{n=0}^{\\infty} \\frac{(tX)^n}{n!} = 1 + tX +\\frac{(tX)^2}{2!} + \\frac{(tX)^3}{3!} + \\cdots\n\\]\nTemos que \\(M_X(t)=E(e^{tX})\\). Logo, admitindo ser válido permutar soma infinita e esperança, temos"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-4",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-4",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\\[\nM_X(t)\n= E(e^{tX})\n= E\\left(\\sum_{n=0}^{\\infty} \\frac{(tX)^n}{n!}\\right)\n= \\sum_{n=0}^{\\infty} \\frac{t^n}{n!} E(X^n),\n\\qquad |t|&lt;\\varepsilon\n\\]\nPortanto, \\(M_X(t)\\) é dada, em uma vizinhança de \\(0\\), por uma série de potência da forma \\[\nM_X(t) = \\sum_{n=0}^{\\infty} a_n t^n,\n\\qquad \\text{com } a_n = \\frac{E(X^n)}{n!}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-5",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-5",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nDa teoria de séries de potência, sabemos que, se \\[\nM_X(t) = \\sum_{n=0}^{\\infty} a_n t^n,\n\\] então a \\(k\\)-ésima derivada é \\[\nM_X^{(k)}(t) = \\sum_{n=k}^{\\infty} a_n\\, n(n-1)\\cdots (n-k+1)\\, t^{\\,n-k}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-6",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-6",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAgora substituímos \\(t=0\\):\nObserve:\n\nSe \\(n &gt; k\\), aparece o fator \\(t^{n-k} = 0^{n-k} = 0\\);\n\nEntão todos os termos com \\(n&gt;k\\) desaparecem;\nSó o termo com \\(n=k\\) permanece.\n\nO único termo sobrevivente é:\n\\[\na_k \\, k(k-1)(k-2)\\cdots 1 \\, t^{\\,0}\n= a_k \\, k!\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-7",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-7",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAssim,\n\\[\nM_X^{(k)}(0) = a_k\\, k!\n= \\frac{E(X^k)}{k!}\\,k!\n= E(X^k)\n\\]\nLogo, \\[\nE(X^k) = \\left.\\frac{d^k}{dt^k} M_X(t)\\right|_{t=0},\n\\qquad k=1,2,\\dots\n\\]\no que mostra que o \\(k\\)-ésimo momento de \\(X\\) é igual à derivada de ordem \\(k\\) da função geradora de momentos avaliada em \\(t=0\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-8",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-8",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nTip 1: Dica Importante!\n\n\nPara qualquer variável aleatória \\(X\\):\n\\[\nM_X(0) = E(e^{0X}) = 1.\n\\]\nIsso sempre deve ocorrer. Use esse fato para verificar se sua FGM está correta."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-9",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-9",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 03: Distribuição de Bernoulli\n\n\nSeja \\(X \\sim Bernoulli(p)\\). Encontre sua função geradora de momentos e a partir dela, encontre \\(E(X)\\) e \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\nSolução: Por definição,\n\\[\nM_X(t) = E(e^{tX}) = \\sum_{x=0}^1 e^{tx} p^x(1-p)^{1-x}\n\\]\nComo \\(X\\) só assume os valores \\(0\\) e \\(1\\):\n\\[\nM_X(t)\n= e^{t\\cdot 0} p^0(1-p)^{1-0} + e^{t\\cdot 1} p^1(1-p)^{1-1}\n= (1-p) + e^{t}p\n= 1 - p +  e^{t} p\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-10",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-10",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nPortanto,\n\\[\n\\boxed{M_X(t) = 1 - p + p e^{t}, \\quad t \\in \\mathbb{R}}\n\\]\nVeja que pela Tip 1 \\(M_X(0) = 1 - p + p e^{0} = 1 - p + p \\times 1 = 1\\). Assim,\n\nPrimeira derivada de \\(M_X(t)\\):\n\n\\[\nM_X'(t) = \\frac{d}{dt}\\big(1 - p + p e^{t}\\big)\n= p e^{t}\n\\]\nAvaliada em \\(t = 0\\), temos \\(E(X) = M_X'(0) = p e^{0} = p\\)"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-11",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-11",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\nSegunda derivada de \\(M_X(t)\\):\n\n\\[\nM_X''(t) = \\frac{d}{dt}\\big(M_X'(t)\\big)\n= \\frac{d}{dt}(p e^{t}) = p e^{t}\n\\]\nAvaliada em \\(t = 0\\), temos \\(E(X) = M_X''(0) = p e^{0} = p\\).\nAssim,\n\\[\n\\operatorname{Var}(X)\n= M_X''(0) - [M_X'(0)]^2\n= p - p^2\n= p(1-p)\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-12",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-12",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 03: Distribuição Binomial\n\n\nSeja \\(X \\sim Binomial(n,p)\\). Encontre sua função geradora de momentos e a partir dela, encontre \\(E(X)\\) e \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\nSolução: Se \\(X \\sim Binomial(n,p)\\) então sua f.p. é dada por\n\\[\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\qquad k=0,1,\\dots,n\n\\]\nPor definição,\n\\[\nM_X(t) = E(e^{tX}) = \\sum_{k=0}^{n} e^{tk} P(X = k)\n= \\sum_{k=0}^{n} e^{tk} \\binom{n}{k} p^k (1-p)^{n-k}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-13",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-13",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nEscrevendo \\(e^{tk} = (e^{t})^k\\):\n\\[\nM_X(t)\n= \\sum_{k=0}^{n} \\binom{n}{k} (p e^t)^k (1-p)^{n-k}\n\\]\nTemos que o binômio de Newton é dado por:\n\\[\n(a+b)^n = \\sum_{k=0}^{n} \\binom{n}{k} a^k b^{n-k}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-14",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-14",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAssim, tomando \\(a = p e^{t}\\) e \\(b = 1-p\\):\n\\[\nM_X(t) = (1-p + p e^{t})^n\n\\]\nPortanto,\n\\[\n\\boxed{M_X(t) = (1-p + p e^{t})^n,\\quad t\\in\\mathbb{R}}\n\\]\nVeja que pela Tip 1 \\(M_X(0) = (1-p + p e^{0})^n = (1 - p + p \\times 1)^n = 1^n = 1\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-15",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-15",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nSabemos que\n\\[\nE(X) = M_X'(0)\n\\]\nDerivada primeira em relação a \\(t\\),\n\\[\nM_X'(t) = \\frac{d}{dt} (1-p + p e^{t})^n\n= n(1-p + p e^{t})^{n-1} \\cdot p e^{t}\n\\]\nLogo,\n\\[\nM_X'(0)\n= n(1-p + p e^{0})^{n-1} \\cdot p e^{0}\n= n(1-p + p)^{n-1} p\n= n p\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-16",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-16",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nVamos agora encontrar a segunda derivada. Temos\n\\[\nM_X'(t) = n p e^{t} (1-p + p e^{t})^{n-1}\n\\]\nAplicando a regra do produto:\n\\[\n\\begin{aligned}\nM_X''(t)\n&= \\frac{d}{dt}\\Big[ n p e^{t} (1-p + p e^{t})^{n-1} \\Big] \\\\\n&= n p e^{t} (n-1)(1-p + p e^{t})^{n-2} \\cdot p e^{t}\n\\;+\\; n p e^{t} (1-p + p e^{t})^{n-1}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-17",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-17",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAvaliando em \\(t=0\\):\n\n\\(e^{0}=1\\)\n\n\\(1-p + p e^{0} = 1-p + p = 1\\)\n\nAssim,\n\\[\n\\begin{aligned}\nM_X''(0)\n&= n p \\cdot 1 \\cdot (n-1) \\cdot 1^{\\,n-2} \\cdot p \\cdot 1\n   \\;+\\; n p \\cdot 1 \\cdot 1^{\\,n-1} \\\\[6pt]\n&= n p (n-1)p + n p \\\\[6pt]\n&= n p \\big[(n-1)p + 1\\big]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-18",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-18",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nDe forma que,\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X)\n&= M_X''(0) - [M_X'(0)]^2\\\\[6pt]\n&= n p \\big[(n-1)p + 1\\big] - (np)^2 \\\\[6pt]\n&= n p \\big[(n-1)p + 1 - n p\\big] \\\\[6pt]\n&= n p (1 - p)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-19",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-19",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 04: Distribuição Geométrica\n\n\nSeja \\(X \\sim Geo(p)\\). Encontre sua função geradora de momentos e a partir dela, encontre \\(E(X)\\) e \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\nSolução: Seja \\(X \\sim \\text{Geo}(p)\\), cuja função de probabilidade é\n\\[\nP(X = k) = p(1-p)^{k-1}, \\qquad k = 1,2,3,\\dots\n\\]\nPor definição, temos que,\n\\[\nM_X(t)\n= E(e^{tX})\n= \\sum_{k=1}^{\\infty} e^{tk} p(1-p)^{k-1} = p \\sum_{k=1}^{\\infty} (e^t)^k (1-p)^{k-1}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória",
    "text": "Função de Variável Aleatória\nSe \\(X\\) é uma variável aleatória com função densidade acumulada \\(F_x(x)\\), então qualquer função de \\(X\\), por exemplo, \\(g(X)\\) também é uma variável aleatória.\n\nGeralmente, \\(g(X)\\) é de nosso interesse e denotamos \\(Y = g(X)\\) para indicar a nova variável aleatória \\(g(X)\\).\n\n\nUma vez que \\(Y\\) é uma função de \\(X\\), podemos descrever o comportamento probabilístico de \\(Y\\) em termos de \\(X\\), isto é, para um dado conjunto \\(A\\),\n\\[P(Y \\in A) = P(g(X) \\in A)\\]\nmostrando que a distribuição de \\(Y\\) depende das funções \\(F_X\\) e \\(g\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-1",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-1",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória",
    "text": "Função de Variável Aleatória\nFormalmente, ao escrevermos \\(y = g(x)\\), a função \\(g(x)\\) define uma função no suporte original de \\(X\\), denotado por \\(S_X\\), para um novo espaço amostral, denotado por \\(S_Y\\), o suporte de \\(Y\\).\n\nSeja então a função inversa de \\(g\\), denotada por \\(g^{-1}\\), que é uma função de \\(S_y\\) para \\(S_x\\).\n\\[g^{-1}(y)=\\{x : g(x) = y \\}\\]\n\n\nPortanto, a função inversa consiste no conjunto de valores de \\(X\\), para os quais \\(g(x) = y\\), dado um valor de \\(y\\) fixado do suporte de \\(Y\\), que é a variável aleatória obtida pela transformação de interesse, \\(g(X)\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-2",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-2",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória",
    "text": "Função de Variável Aleatória\nÉ importante observar que cada valor de \\(x\\) pertencente ao suporte de \\(X\\), corresponde a um único valor de \\(y\\) pertencente ao suporte de \\(Y\\). Por outro lado, um valor \\(y \\in S_Y\\) pode corresponder a mais de um valor do suporte de \\(X\\), conforme ilustra a figura abaixo"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-3",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-3",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória",
    "text": "Função de Variável Aleatória\nFinalmente, se a variável aleatória \\(Y\\) for definida por \\(Y= g(X)\\), podemos escrever para qualquer conjunto \\(A \\subset S_Y\\),\n\\[\n\\begin{aligned}\nP(Y \\in A) &= P(g(X) \\in A) \\\\\n           &= P(\\{x \\in S_X : g(x) \\in A\\}) \\\\\n           &= P(X \\in g^{-1}(A))\n\\end{aligned}\n\\]\nIsto define a distribuição de probabilidade de \\(Y\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nSe \\(X\\) for uma variável aleatória discreta e \\(Y= g(X)\\), então \\(Y\\) também será uma variável aleatória discreta. Assim,\n\\[p_Y(y) = P(Y = y) = \\sum_{x \\in g^{-1}(y)} p_X(x), \\qquad \\text{para} \\,\\, y \\in S_Y\\] e \\(p_Y(y) = 0\\) para \\(y \\notin S_Y\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-1",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-1",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nExemplo 01: Suponhamos que a distribuição de probabilidades da variável aleatória \\(X\\) é dada pela tabela abaixo:\n\n\n\n\n\\(x\\)\n-2\n-1\n0\n1\n2\n3\n\n\n\n\n\\(p_X(x)\\)\n0,1\n0,2\n0,2\n0,3\n0,1\n0,1\n\n\n\n\nSeja \\(Y = 3X+1\\). Encontre a distribuição da variável aleatória \\(Y\\).\n\nSolução:\nComo \\(Y = 3X+1\\),\n\n\n\n\n\\(y = 3x + 1\\)\n-5\n-2\n1\n4\n7\n10\n\n\n\n\n\\(p_Y(y)\\)\n0,1\n0,2\n0,2\n0,3\n0,1\n0,1"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-2",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-2",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nExemplo 02: Considere a mesma distribuição de probabilidades da variável aleatória \\(X\\), dada pela tabela abaixo:\n\n\n\n\n\\(x\\)\n-2\n-1\n0\n1\n2\n3\n\n\n\n\n\\(p_X(x)\\)\n0,1\n0,2\n0,2\n0,3\n0,1\n0,1\n\n\n\n\nContudo, vamos agora definir a variável aleatória \\(Y = X^2\\). Qual a distribuição de probabilidades de \\(Y\\)?\n\nSolução:\nTemos que \\(S_X = \\{-2, -1, 0, 1, 2, 3\\}\\). Como \\(Y = X^2\\), temos que o suporte de \\(Y\\) é dado por \\(S_Y = \\{0, 1, 4, 9\\}\\), de forma que a distribuição da variável \\(Y\\) será dada por:"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-3",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-3",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\n\\[\n\\begin{aligned}\nP(Y = 0) &= P(X = 0) = 0{,}2 \\\\[6pt]\nP(Y = 1) &= P(X = -1) + P(X = 1) = 0{,}5 \\\\[6pt]\nP(Y = 4) &= P(X = -2) + P(X = 2) = 0{,}2 \\\\[6pt]\nP(Y = 9) &= P(X = 3) = 0{,}1\n\\end{aligned}\n\\]\nLogo,\n\n\n\n\n\\(y = x^{2}\\)\n0\n1\n4\n9\n\n\n\n\n\\(p_Y(y)\\)\n0,2\n0,5\n0,2\n0,1"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-4",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-4",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nExemplo 03: Suponha que \\(X \\sim Poisson(\\lambda)\\), com função de probabilidade\n\\[\nP(x | \\lambda)=\n  \\begin{cases}\n\\dfrac{e^{-\\lambda} \\lambda^x}{x!}, & x \\in \\{0, 1, 2, 3, \\cdots \\} \\\\[6pt]\n0, & c.c.\n\\end{cases}\n\\]\nConsidere que \\(Y = g(X)\\), tal que \\(g(X) = 0\\), se \\(x\\) é par e \\(g(X) = 1\\), se \\(x\\) é ímpar. Obter a função de probabilidade de \\(Y\\).\n\nSolução:\nTemos que o conjunto suporte de \\(Y\\) é \\(S_Y = \\{0,1\\}\\). Vamos calcular a \\(P(Y = 0)\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-5",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-5",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\n\\[\n\\begin{aligned}\nP(Y = 0)\n&= P(g(X) = 0)\n  = P(X \\text{ ser par}) \\\\[6pt]\n&= \\sum_{x \\in \\{0,2,4,\\ldots\\}}\n    \\frac{e^{-\\lambda}\\lambda^{x}}{x!} \\\\[6pt]\n&= e^{-\\lambda}\n    \\sum_{k = 0}^{\\infty}\n    \\frac{\\lambda^{2k}}{(2k)!}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#aparte-séries-de-taylor-e-maclaurin",
    "href": "aulas/transformacoes/transformacoes.html#aparte-séries-de-taylor-e-maclaurin",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Aparte — Séries de Taylor e Maclaurin",
    "text": "Aparte — Séries de Taylor e Maclaurin\nSérie de Taylor\nExpansão de uma função em torno de um ponto \\(a\\):\nA expansão de Taylor escrita termo a termo é:\n\\[\n{\\small\n\\begin{aligned}\n    f(x) &= f(a)\n    + f'(a)(x-a)\n+ \\frac{f''(a)}{2!}(x-a)^2\n+ \\frac{f^{(3)}(a)}{3!}(x-a)^3 + \\cdots = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^n\n\\end{aligned}\n}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#aparte-séries-de-taylor-e-maclaurin-1",
    "href": "aulas/transformacoes/transformacoes.html#aparte-séries-de-taylor-e-maclaurin-1",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Aparte — Séries de Taylor e Maclaurin",
    "text": "Aparte — Séries de Taylor e Maclaurin\nSérie de Maclaurin\nCaso particular da série de Taylor com \\(a = 0\\):\n\\[ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!}x^n \\]\nExemplos:\n\\[\ne^x\n= 1\n+ x\n+ \\frac{x^2}{2!}\n+ \\frac{x^3}{3!}\n+ \\frac{x^4}{4!}\n+ \\frac{x^5}{5!}\n+ \\cdots\n+ \\frac{x^n}{n!}\n+ \\cdots= \\sum_{n=0}^{\\infty} \\frac{x^n}{n!}\n\\]\n\\[\ne^{-x}\n= 1\n- x\n+ \\frac{x^2}{2!}\n- \\frac{x^3}{3!}\n+ \\frac{x^4}{4!}\n- \\frac{x^5}{5!}\n+ \\cdots\n+ (-1)^n \\frac{x^n}{n!}\n+ \\cdots = \\sum_{n=0}^{\\infty} (-1)^n \\frac{x^n}{n!}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-6",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-6",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nAssim, \\(e^{\\lambda} + e^{-\\lambda} = 2\\sum_{k=0}^{\\infty} \\frac{\\lambda^{2k}}{(2k)!}\\) e,\n\\[\n\\begin{aligned}\nP(Y = 0)\n&= e^{-\\lambda} \\sum_{k = 0}^{\\infty} \\frac{\\lambda^{2k}}{(2k)!} \\\\[6pt]\n&= e^{-\\lambda} \\cdot \\frac{1}{2}\\Big(e^{\\lambda} + e^{-\\lambda}\\Big) \\\\[6pt]\n&= \\frac{1}{2}\\Big(1 + e^{-2\\lambda}\\Big).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-7",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-7",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nComo \\(\\sum_{y=0}^{\\infty} P(Y = y) = 1\\), temos que\n\\[\n\\begin{aligned}\nP(Y = 1)\n&= P(X \\text{ ser ímpar})\n  = 1 - \\frac{1}{2}\\Big(1 + e^{-2\\lambda}\\Big) \\\\[6pt]\n&= \\frac{1}{2}\\Big(1 - e^{-2\\lambda}\\Big).\n\\end{aligned}\n\\]\n\nFinalmente, \\(p_Y(y) = 0\\) para outros valores de \\(y \\notin S_Y\\). Portanto, \\(Y \\sim Bernoulli(p)\\) com\n\\[p = \\dfrac{1}{2}\\Big(1 - e^{-2\\lambda}\\Big), \\qquad \\lambda &gt; 0\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-8",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-8",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\nExemplo 04: Considere que \\(X \\sim Binomial (n,p)\\) com função de probabilidade\n\\[\nP(x | n,p)=\n\\begin{cases}\n\\dbinom{n}{x}\\, p^{x}\\, (1-p)^{\\,n-x}, \\qquad x \\in \\{0, 1, 2, \\dots, n\\}  \\\\[6pt]\n0, & c.c.\n\\end{cases}\n\\]\nConsidere \\(Y = g(X) = n - X\\) e obtenha a distribuição de probabilidade de \\(Y\\).\n\nSolução:\nConsiderando \\(Y = g(X) = n - X\\), temos que \\(S_Y = \\{0, 1, 2, \\dots, n\\}\\). Quando \\(Y =  y\\), temos \\(X = n-y\\), assim,"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-9",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-discreto-9",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Discreto",
    "text": "Função de Variável Aleatória: Caso Discreto\n\\[\n\\begin{aligned}\nP(Y = y) &= P(g(X) = y) = P(X = g^{-1}(y)) = P(X = n - y) \\\\\n         &= \\binom{n}{\\,n-y\\,}\\, p^{\\,n-y}\\, (1-p)^{\\,n-(n-y)} \\\\\n         &= \\binom{n}{\\,n-y\\,}\\, p^{\\,n-y}\\, (1-p)^{\\,y} \\\\\n         &= \\binom{n}{y}\\, (1-p)^{y}\\, p^{\\,n-y},\n         \\qquad \\text{uma vez que } \\binom{n}{n-y} = \\binom{n}{y}\n\\end{aligned}\n\\]\nque equivale a dizer que \\(Y \\sim binomial(n, 1-p)\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nMétodo da Função de Distribuição\nTeorema: Consideremos uma variável aleatória contínua \\(X\\) com função de distribuição de probabilidade \\(F_X\\) conhecida e a função \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\), então \\(Y = g(X)\\) é uma variável aleatória com função distribuição dada por\n\\[F_Y(y) = P(Y \\le y) = P(X \\in g^{-1}\\big((-\\infty, y]\\big) = \\int_{g^{-1}\\big((-\\infty, y]\\big)}f_X(x)\\,\\,dx\\]\nem que \\(g^{-1}(y)\\) é a função inversa de \\(g\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-1",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-1",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\n\nEsse método consiste em encontrar a função de distribuição da variável transformada \\(Y = g(X)\\) a partir da função de distribuição de \\(X\\).\nSe \\(Y\\) for variável aleatória continua, podemos então obter a sua função densidade a partir da derivada da função de distribuição já encontrada.\nNão necessariamente \\(Y = g(X)\\) será variável aleatória contínua, \\(Y\\) por ser contínua, discreta e até mesmo uma variável aleatória que não seja nem discreta nem contínua."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-2",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-2",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 05: Considere que \\(X \\sim Exp(\\lambda)\\), sendo \\(\\lambda &gt; 0\\) conhecido, com função densidade de probabilidade dada por\n\\[\nf_X(x| \\lambda) =\n\\begin{cases}\n\\lambda \\,\\, e^{-\\lambda x} & \\text{para } x &gt; 0  \\\\[6pt]\n0, & c.c.\n\\end{cases}\n\\] Para \\(Y = g(X)\\) dada por\n\\[\nY = g(X) =\n\\begin{cases}\n0 & \\text{se }  X \\le \\dfrac{1}{\\lambda}  \\\\[6pt]\n1, & c.c.\n\\end{cases}\n\\] obter a distribuição de \\(Y\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-3",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-3",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nSolução:\nComo o evento \\(\\{Y = 0\\}\\) ocorre quando \\(X \\le 1/\\lambda\\) e a função de distribuição exponencial é \\(F_X(x) = 1 - \\exp(-\\lambda x)\\), então\n\\[P(Y=0) = F_X\\Bigg( \\dfrac{1}{\\lambda}\\Bigg) = 1 - \\exp \\Bigg(-\\lambda \\times \\dfrac{1}{\\lambda}\\Bigg) = 1-e^{-1}\\]\nTemos então, que\n\\[P(Y = 1) = 1 - F_X\\Bigg( \\dfrac{1}{\\lambda}\\Bigg) = 1 - (1 - e^{-1}) = e^{-1}\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-4",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-4",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nLogo, \\(Y\\) é uma variável aleatória discreta, pois \\(S_Y = \\{0,1\\}\\). Além disso, \\(Y \\sim Bernoulli(p = e^{-1})\\), com fp dada por\n\\[\np_Y(y) =\n\\begin{cases}\np^y(1-p)^{1-y} & \\text{para } y \\in \\{0,1\\}  \\\\[6pt]\n0, & c.c.\n\\end{cases}\n\\] com \\(p = e^{-1}\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-5",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-5",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 06: Seja \\(X\\) uma variável aleatória tal que \\(X \\sim N(0,1)\\), cuja fdp é dada por\n\\[f_X(x) = \\dfrac{1}{\\sqrt{2\\pi}}\n\\exp\\left( -\\dfrac{x^2}{2} \\right), \\quad x \\in \\mathbb{R}\\]\nConsiderando \\(Y = g(X) = X^2\\), obter a função densidade de probabilidade de \\(Y\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-6",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-6",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nSolução:\nTemos que o evento \\(\\{Y \\le y\\}\\), para \\(y\\) fixado e pertencente ao conjunto suporte \\(S_Y = [0, \\infty) \\subset \\mathbb{R}\\), cuja equivalência em relação aos eventos pertencentes ao suporte de \\(X\\), \\(S_X = \\mathbb{R}\\), é dada por \\(\\{Y \\le y\\} = \\{-\\sqrt{y} \\le X \\le \\sqrt{y}\\}\\), conforme ilustrado abaixo"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-7",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-7",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nPortanto,\n\\[F_Y(y) = P(Y \\le y) = P(-\\sqrt{y} \\le X \\le \\sqrt{y}) = \\Phi_X(\\sqrt{y}) - \\Phi_X(-\\sqrt{y})\\] para \\(y &gt; 0\\), sendo \\(\\Phi_X\\), a função de distribuição de probabilidade da normal padrão."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-8",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-8",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nSe derivarmos \\(F_y(y)\\) em relação a \\(y\\), e usando o fato de \\(\\Gamma\\Big(\\frac{1}{2}\\Big) =  \\sqrt{\\pi}\\), temos\n\\[\\small\n\\begin{aligned}\nf_Y(y)\n&= \\frac{dF_Y(y)}{dy}\n   = \\frac{d\\Big[ \\Phi_X(\\sqrt{y}) - \\Phi_X(-\\sqrt{y}) \\Big]}{dy} \\\\[6pt]\n&= f_X(\\sqrt{y}) \\cdot \\frac{1}{2\\sqrt{y}}\n  + f_X(-\\sqrt{y}) \\cdot \\frac{1}{2\\sqrt{y}}\n   \\qquad \\text{(regra da cadeia)} \\\\[6pt]\n&= f_X(\\sqrt{y}) \\cdot \\frac{1}{\\sqrt{y}}\n   \\qquad \\text{(simetria da normal)} \\\\[6pt]\n&= \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{(\\sqrt{y})^{2}}{2}\\right)\n    \\cdot \\frac{1}{\\sqrt{y}} = \\frac{1}{2^{1/2}\\sqrt{\\pi}}\\,e^{-y/2}\\,y^{-1/2} = \\chi^2_1(y).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-9",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-9",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nMétodo do Jacobiano\nTeorema: Seja \\(X\\) com fdp \\(f_X(x)\\) e \\(Y=g(X)\\), onde \\(g\\) é uma função monótona. Sejam \\(S_X = \\{x: f_X(x) &gt; 0\\}\\) e \\(S_Y = \\{y: y = g(x) \\,\\, \\text{para algum } \\, x \\in S_X\\}\\). Suponha que \\(f_X(x)\\) seja contínua em \\(S_X\\) e que \\(g^{-1}(y)\\) tenha uma derivada contínua em \\(S_Y\\). Então,\n\\[\nf_Y(y) =\n\\begin{cases}\nf_X \\Big(g^{-1}(y)\\Big) \\Bigg|\\dfrac{d}{dy}g^{-1}(y)\\Bigg| & y \\in S_Y  \\\\[6pt]\n0, & c.c.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-10",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-10",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 07: Suponha uma variável aleatória contínua \\[\nX \\sim N(\\mu, \\sigma^2), \\quad \\sigma &gt; 0.\n\\]\nSua função densidade é \\[\nf_X(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\n\\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right), \\quad x \\in \\mathbb{R}\n\\]\nDefinimos a nova variável aleatória \\[\nY = \\frac{X - \\mu}{\\sigma}.\n\\]\nQueremos encontrar a distribuição de \\(Y\\) usando o método do jacobiano."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-11",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-11",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nPasso 1: Escrever a transformação e a inversa\nA transformação é \\[\nY = g(X) = \\frac{X - \\mu}{\\sigma}.\n\\]\nIsolando \\(X\\) em função de \\(Y\\), obtemos a inversa: \\[\nX = \\sigma Y + \\mu.\n\\]\nIsto é, \\[\nx = g^{-1}(y) = \\sigma y + \\mu.\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-12",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-12",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nPasso 2: Calcular o jacobiano em 1D\nNo caso unidimensional, o jacobiano é o valor absoluto da derivada de \\(x\\) em relação a \\(y\\): \\[\n\\dfrac{d}{dy} x= \\dfrac{d}{dy} \\,\\sigma y + \\mu  =  \\sigma \\quad \\Rightarrow \\quad \\left| \\dfrac{d}{dy} \\,\\sigma y + \\mu \\right| = \\sigma\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-13",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-13",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nPasso 3: Para \\(Y = g(X)\\) com \\(g\\) monotônica, a densidade de \\(Y\\) é dada por\n\\[\nf_Y(y) = f_X\\big(g^{-1}(y)\\big)\\,\\left|\\frac{d}{dy} g^{-1}(y)\\right|\n\\]\nNo nosso caso:\n\\[\n\\begin{aligned}\nf_Y(y)\n&= f_X(\\sigma y + \\mu)\\,\\sigma \\\\[6pt]\n&= \\frac{1}{\\sigma\\sqrt{2\\pi}}\n    \\exp\\!\\left(\n      -\\frac{(\\sigma y + \\mu - \\mu)^2}{2\\sigma^2}\n    \\right)\\,\\sigma \\\\[6pt]\n&= \\frac{1}{\\sigma\\sqrt{2\\pi}}\n    \\exp\\!\\left(\n      -\\frac{(\\sigma y)^2}{2\\sigma^2}\n    \\right)\\,\\sigma = \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{y^2}{2} \\right).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-14",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-14",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nLogo, \\[\nf_Y(y) = \\sigma \\cdot \\dfrac{1}{\\sigma \\sqrt{2\\pi}}\n\\exp\\left( -\\dfrac{\\sigma^2 y^2}{2\\sigma^2} \\right)\n= \\dfrac{1}{\\sqrt{2\\pi}}\n\\exp\\left( -\\dfrac{y^2}{2} \\right), \\quad y \\in \\mathbb{R}\n\\]\nque é exatamente a densidade da Normal Padrão.\nPortanto, \\[\nY = \\frac{X - \\mu}{\\sigma} \\sim N(0,1).\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-15",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-15",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 08: Seja \\(X \\sim U(0,1)\\). Obtenha a função densidade de \\(Y = -\\ln(X)\\).\n\nSolução:\nSabemos que se \\(X \\sim U(0,1)\\), então sua função densidade \\(f_X(x)\\) é dada por\n\\[\nf_X(x) =\n\\begin{cases}\n1, & 0 &lt; x &lt; 1, \\\\\n0, & \\text{caso contrário.}\n\\end{cases}\n\\]\nTemos que \\(Y = -\\ln(X)\\). Como \\(0 &lt; X &lt; 1\\), então \\(Y &gt; 0\\).\nInvertendo:\n\\[\nY = -\\ln(X) \\;\\Rightarrow\\; -Y = \\ln(X) \\;\\Rightarrow\\; X = e^{-Y}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-16",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-16",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nPortanto:\n\\[\nx = g^{-1}(y) = e^{-y}\n\\]\nJacobiano\n\\[\n\\dfrac{d}{dy} x = \\dfrac{d}{dy} e^{-y} = -e^{-y} \\quad \\Rightarrow \\quad \\left| \\dfrac{d}{dy} x \\right| = e^{-y}\n\\]\nTemos que\n\\[\nf_Y(y) = f_X(g^{-1}(y)) \\left| \\frac{d}{dy} g^{-1}(y) \\right|\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-17",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-17",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nSubstituindo:\n\\[\nf_Y(y) = f_X(e^{-y}) \\cdot e^{-y}\n\\]\numa vez que \\(f_X(x) = 1\\) no intervalo \\((0, 1)\\).\n\\[\nf_Y(y) = 1 \\cdot e^{-y} = e^{-y}, \\quad y &gt; 0.\n\\]\nTemos que \\(Y \\sim Exp(\\lambda = 1)\\)"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-18",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-18",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nGeneralização do Método do Jacobiano\nSe \\(Y = g(X)\\) não é monótona em \\(\\mathbb{R}\\), podemos aplicar o método do Jacobiano em cada um dos intervalos em que \\(g\\) é monótona, da seguinte forma:\n\nDefina uma partição de \\(\\mathbb{R}_X\\) formada pelos intervalos \\(I_1, I_2, \\cdots I_k\\) tais que a função \\(g\\) é monótona em cada \\(I_j, \\,\\,\\, j= 1\\cdots k\\).\nObtenha \\(f_j(y) = f_X \\Big(g^{-1}(y)\\Big) \\Bigg|\\dfrac{d}{dy}g^{-1}(y)\\Bigg|\\) a cada intervalo \\(I_j\\).\nFinalmente, obtenha\n\n\\[f_Y(y) = \\sum_{j=1}^k f_j(y)\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-19",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-19",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 09: (Exemplo 06 revisitado) Seja \\(X\\) uma variável aleatória tal que \\(X \\sim N(0,1)\\), cuja fdp é dada por\n\\[f_X(x) = \\dfrac{1}{\\sqrt{2\\pi}}\n\\exp\\left( -\\dfrac{x^2}{2} \\right), \\quad x \\in \\mathbb{R}\\]\nConsiderando \\(Y = g(X) = X^2\\), obter a função densidade de probabilidade de \\(Y\\), usando o método do Jacobiano."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-20",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-20",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nSolução:\nNote que, neste caso, temos duas regiões disjuntas do suporte de \\(X\\), \\(S_X\\), em que \\(g(x) = x^2\\) é injetora. Temos, \\(S_{X_1} = (-\\infty, 0]\\) e \\(S_{X_2} = [0, \\infty)\\). Logo, \\(g^{-1}_1(y) = -\\sqrt{y}\\) para \\(x \\le 0\\) e \\(g^{-1}_2(y) = \\sqrt{y}\\) para \\(x &gt; 0\\). Portanto,"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-21",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-21",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\n\\[\n\\begin{aligned}\nf_Y(y)\n&= f_X(g_1^{-1}(y)) \\left| \\frac{d}{dy} g_1^{-1}(y) \\right|\n  + f_X(g_2^{-1}(y)) \\left| \\frac{d}{dy} g_2^{-1}(y) \\right| \\\\[6pt]\n&= \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{(-\\sqrt{y})^2}{2} \\right)\n    \\left| \\frac{d}{dy} (-\\sqrt{y}) \\right|\n  + \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{(\\sqrt{y})^2}{2} \\right)\n    \\left| \\frac{d}{dy} \\sqrt{y} \\right| \\\\[6pt]\n&= \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{y}{2} \\right)\n    \\left| -\\frac{1}{2 \\sqrt{y}} \\right|\n  + \\frac{1}{\\sqrt{2\\pi}}\n    \\exp\\!\\left( -\\frac{y}{2} \\right)\n    \\left| \\frac{1}{2 \\sqrt{y}}  \\right| \\\\[6pt]\n&= \\frac{1}{\\sqrt{2\\pi}}\n    e^{-y/2}\\,\\frac{1}{2 \\sqrt{y}}\n  + \\frac{1}{\\sqrt{2\\pi}}\n    e^{-y/2}\\,\\frac{1}{2 \\sqrt{y}} \\\\[6pt]\n&= \\frac{2}{\\sqrt{2\\pi}}\\,e^{-y/2}\\,\\frac{1}{2 \\sqrt{y}} = \\frac{1}{\\sqrt{2\\pi}}\\,e^{-y/2}\\,y^{-1/2}\n  = \\frac{1}{2^{1/2}\\sqrt{\\pi}}\\,e^{-y/2}\\,y^{-1/2}\n  = \\chi^2_1(y).\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-22",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-22",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nExemplo 10: Seja \\(X\\sim U(-1,1)\\). Qual a distribuição de \\(Y=X^2\\)?\n\nSolução:\nDefinindo a função indicadora de um conjunto \\(A\\) como\n\\[\nI_A(x) =\n\\begin{cases}\n1, & \\text{se } x \\in A, \\\\\n0, & \\text{se } x \\notin A\n\\end{cases}\n\\]\npodemos escrever a fução densidade de \\(X\\) como \\(f_X(x) = \\dfrac{1}{2}I_{(-1,1)}(x)\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-23",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-23",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nComo \\(Y = X^2\\) não é monótona em \\((−1, 1)\\), mas o é em \\((−1, 0)\\) e \\((0, 1)\\) podemos utilizar a generalização do método do Jacobiano, ou seja, no intervalo \\((−1, 0)\\), \\(g_1^{-1}(y) = -\\sqrt{y}\\) e no intervalo \\((0, 1)\\) \\(g_2^{-1}(y) = \\sqrt{y}\\). Assim,"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-24",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-24",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\n\\[\n\\begin{aligned}\nf_Y(y)\n&= f_X(g_1^{-1}(y)) \\left| \\frac{d}{dy} g_1^{-1}(y) \\right|\n  + f_X(g_2^{-1}(y)) \\left| \\frac{d}{dy} g_2^{-1}(y) \\right| \\\\[6pt]\n&= f_X(-\\sqrt{y}) \\left| \\frac{d}{dy} (-\\sqrt{y}) \\right|\n  + f_X(\\sqrt{y}) \\left| \\frac{d}{dy} \\sqrt{y} \\right| \\\\[6pt]\n&= \\frac{1}{2} \\cdot \\left| -\\frac{1}{2 \\sqrt{y}} \\right|\n  + \\frac{1}{2} \\cdot \\left| \\frac{1}{2 \\sqrt{y}} \\right| \\\\[6pt]\n&= \\frac{1}{2} \\cdot \\frac{1}{2 \\sqrt{y}}\n  + \\frac{1}{2} \\cdot \\frac{1}{2 \\sqrt{y}} \\\\[6pt]\n&= \\frac{1}{4 \\sqrt{y}} + \\frac{1}{4 \\sqrt{y}}\n  = \\frac{1}{2 \\sqrt{y}}, \\qquad 0&lt;y&lt;1\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-25",
    "href": "aulas/transformacoes/transformacoes.html#função-de-variável-aleatória-caso-contínuo-25",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "Função de Variável Aleatória: Caso Contínuo",
    "text": "Função de Variável Aleatória: Caso Contínuo\nLogo, se \\(X\\sim U(-1,1)\\), a distribuição de \\(Y=X^2\\) é dada por\n\\[f_Y(y) = \\dfrac{1}{2 \\sqrt{y}}I_{(0,1)}(y)\\]\nque é exatamente a densidade \\(Beta(1/2, 1).\\)\n\nAssim, se \\(X\\sim U(-1,1)\\), \\(Y=X^2 \\sim Beta(1/2, 1).\\)"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nUm importante e conhecido teorema é o Teorema da Probabilidade Integral, que relaciona a distribuição uniforme contínua com todas as outras distribuições de probabilidade.\n\nSeu resultado é importante na Estatística Computacional, pois permite que sejam simuladas amostras aleatórias de qualquer distribuição de probabilidade."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-1",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-1",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nTeorema da probabilidade integral: Consideremos \\(X\\) uma variável aleatória absolutamente contínua com função de distribuição acumulada \\(F_X\\). Então \\(U = F_X(X)\\) possui distribuição uniforme no intervalo \\([0,1]\\). Por outro lado, se \\(U \\sim U(0,1)\\), então \\(X = F^{-1}_X(U)\\) possui função de distribuição acumulada \\(F_X\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-2",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-2",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nDemonstração: Considere \\(X\\) uma variável aleatória absolutamente contínua com função de distribuição acumulada \\(F_X\\), então\n\\[\nF_U(u) = P(U \\le u)= P(F_X(X) \\le u) = P(X \\le F_X^{-1}(u)) = F_X(F_X^{-1}(u)) = u\n\\] Por outro lado, se \\(U \\sim U(0,1)\\), então\n\\[\n{\\small  \nP(X \\le x) = P(F^{-1}_X(U) \\le x) = P(U \\le F_X(x)) = F_U(F_X(x)) = F_X(x), \\,\\, \\text{pois } U \\text{ é uniforme}\n}\n\\] Assim \\(X\\) possui função de distribuição \\(F_X\\)."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-3",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-3",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nExemplo 11: (Geração de variáveis da distribuição exponencial) Considere que \\(X \\sim Exp(\\lambda)\\), cuja função de distribuição de probabilidade é dada por\n\\[ F_X(x) = 1 - e^{-\\lambda x}, \\qquad x \\ge 0 \\]\nSe \\(U \\sim U(0,1)\\), qual é a distribuição de \\(X = F_X^{-1}(U)\\)?\n\nSolução:\nA função inversa é dada por\n\\[\nu = 1 - e^{-\\lambda x} \\Rightarrow e^{-\\lambda x} = 1 - u \\Rightarrow x = -\\frac{1}{\\lambda} \\ln(1-u)\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-4",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-4",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nAssim, pelo teorema da transformação integral,\n\\[X = F_X^{-1}(U) = -\\frac{1}{\\lambda} \\ln(1-U)\\] possui distribuição exponencial com função de distribuição \\(F_X\\). Podemos utilizar esse resultado para gerar realizações de uma amostra aleatória da distribuição exponencial. Para isso, basta gerarmos realizações uniformes \\(u\\) e aplicarmos a relação anterior."
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-5",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-5",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nExemplo 12: (Geração de variáveis da distribuição Weibull) Considere que \\(X \\sim Weibull(\\alpha, \\beta)\\), cuja função de distribuição de probabilidade é dada por\n\\[F_X(x) = 1 - e^{-(x/\\alpha)^{\\beta}}, \\qquad x \\ge 0\\]\nSe \\(U \\sim U(0,1)\\), qual é a distribuição de \\(X = F_X^{-1}(U)\\)?\n\nSolução:\nA função inversa é dada por\n\\[\nu = 1 - e^{-(x/\\alpha)^{\\beta}} \\Rightarrow e^{-(x/\\alpha)^{\\beta}} = 1 - u \\Rightarrow (x/\\alpha)^{\\beta} = -\\ln(1-u) \\Rightarrow x = \\alpha \\,[-\\ln(1-u)]^{1/\\beta}\n\\]"
  },
  {
    "objectID": "aulas/transformacoes/transformacoes.html#a-transformação-integral-6",
    "href": "aulas/transformacoes/transformacoes.html#a-transformação-integral-6",
    "title": "Transformação de Variáveis Unidimensionais",
    "section": "A Transformação Integral",
    "text": "A Transformação Integral\nAssim, pelo teorema da transformação integral,\n\\[X = F_X^{-1}(U) = \\alpha \\,[-\\ln(1-U)]^{1/\\beta}\\] possui distribuição Weibull com função de distribuição \\(F_X\\)."
  },
  {
    "objectID": "cronograma.html",
    "href": "cronograma.html",
    "title": "Cronograma da Disciplina",
    "section": "",
    "text": "Esta página contém um esboço dos tópicos, conteúdos e tarefas para o semestre. Este cronograma será atualizado conforme o semestre avança.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemana\nData\nTópico\nArtigo\nSlides\nEC\nLE\nScript\nMC\nProjeto\n\n\n\n\n6\nTer, 11/11\nOutras Distribuições Contínuas\n\n\n\n\n\n\n\n\n\n\nQui, 13/11\nOutras Distribuições Contínuas\n\n\n\n\n\n\n\n\n\n7\nTer, 18/11\nNão haverá aula\n\n\n\n\n\n\n\n\n\n\nQui, 20/11\nFeriado: não haverá aula\n\n\n\n\n\n\n\n\n\n8\nTer, 25/11\nOutras Distribuições Contínuas\n\n\n\n\n\n\n\n\n\n\nQui, 27/11\nTransformação de Variáveis Aleatórias\n\n\n\n\n\n\n\n\n\n9\nTer, 02/12\nTransformação de Variáveis Aleatórias\n\n\n\n\n\n\n\n\n\n\nQui, 04/12\nTransformação de Variáveis Aleatórias",
    "crumbs": [
      "Cronograma da Disciplina"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilidade II",
    "section": "",
    "text": "Página dedicada à disciplina EST304 - Probabilidade I\nA disciplina Probabilidade II aprofunda o estudo de modelos probabilísticos contínuos e suas aplicações formais, desenvolvendo ferramentas essenciais para análise rigorosa de incerteza em contextos mais gerais. São abordadas as principais distribuições contínuas de probabilidade, os métodos de transformação de variáveis aleatórias (particularmente no caso unidimensional) e o uso de funções geradoras, com destaque para a Função Geradora de Momentos e a Função Característica, como instrumentos teóricos potentes para derivar propriedades e resultados assintóticos. A disciplina também introduz a avaliação de integrais em múltiplas dimensões, o formalismo de vetores aleatórios contínuos, bem como a dedução e interpretação de distribuições marginais e condicionais, estabelecendo assim a base matemática necessária para estudos posteriores em inferência estatística, teoria assintótica e modelos estocásticos."
  },
  {
    "objectID": "index.html#avaliações",
    "href": "index.html#avaliações",
    "title": "Probabilidade II",
    "section": "Avaliações",
    "text": "Avaliações\n\n\n\n\n\n\nCritérios de Avaliação\n\n\n\nA nota final do semestre será computada da seguinte forma:\n\nDuas provas valendo 70 pontos, distribuídos da seguinte forma:\n\n\\(1^{\\text{a}}\\) Prova: 35 pontos — a ser realizada em 29/01/26\n\\(2^{\\text{a}}\\) Prova: 35 pontos — a ser realizada em 26/02/26\n\nListas de exercícios a serem entregues ao longo do semestre no valor de 30 pontos.\nExame Final: 05/03/26"
  },
  {
    "objectID": "programacao/semana-6.html",
    "href": "programacao/semana-6.html",
    "title": "Semana 06",
    "section": "",
    "text": "Outras Distribuições Contínuas \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-6.html#slides",
    "href": "programacao/semana-6.html#slides",
    "title": "Semana 06",
    "section": "",
    "text": "Outras Distribuições Contínuas \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-8.html",
    "href": "programacao/semana-8.html",
    "title": "Semana 08",
    "section": "",
    "text": "Outras Distribuições Contínuas \n\n\nVer slides PDF\n\n\n\n\n Transformação de variáveis Aleatórias \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-8.html#slides",
    "href": "programacao/semana-8.html#slides",
    "title": "Semana 08",
    "section": "",
    "text": "Outras Distribuições Contínuas \n\n\nVer slides PDF\n\n\n\n\n Transformação de variáveis Aleatórias \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-8.html#entrega-lista-de-exercícios-01",
    "href": "programacao/semana-8.html#entrega-lista-de-exercícios-01",
    "title": "Semana 08",
    "section": "Entrega lista de exercícios 01",
    "text": "Entrega lista de exercícios 01\n\n\n\n\n\n\nFique Atento!\n\n\n\n Lista de exercícios 01\nEntrega na sala de aula!\n\nData de entrega:\n\n25 de novembro de 2025"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-20",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-20",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nReorganizando,\n\\[\nM_X(t)\n= p e^t \\sum_{k=1}^{\\infty} \\big[(1-p)e^{t}\\big]^{\\,k-1}\n\\]\nA soma é uma série geométrica com razão\n\\[\nr=(1-p)e^{t}\n\\]\nA série converge se e somente se:\n\\[\n|(1-p)e^{t}| &lt; 1\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-21",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-21",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nUsando a soma da série geométrica,\n\\[\n\\sum_{k=0}^{\\infty} r^k = \\frac{1}{1-r},\n\\]\ntemos:\n\\[\nM_X(t) = \\frac{p e^t}{1 - (1-p)e^{t}}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-22",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-22",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nPortanto,\n\\[\n\\boxed{M_X(t) = \\frac{p e^{t}}{1-(1-p)e^{t}}, \\quad \\text{para } t &lt; \\ln\\Bigg(\\frac{1}{1-p}\\Bigg)}\n\\]\nNote que, pela Tip 1, \\(M_X(0) = \\dfrac{p e^{0}}{1-(1-p)e^{0}} = \\dfrac{p}{1-(1-p)} =  \\dfrac{p}{p} =1\\)\n\nSabemos que:\n\\[\nE(X) = M_X'(0)\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-23",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-23",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nVamos então encontrar a derivada de primeira ordem de\n\\[\nM_X(t) = \\frac{p e^{t}}{1 - (1-p)e^{t}}\n\\]\nUse regra do quociente, temos\n\\[\nM_X'(t)\n= \\frac{p e^t \\big[1 - (1-p)e^{t}\\big] - p e^{t}\\big[-(1-p)e^{t}\\big]}{\\big[1 - (1-p)e^{t}\\big]^2}\n\\]\nSimplificando o numerador:\n\\[\np e^{t}\\left[1 - (1-p)e^{t} + (1-p)e^{t}\\right]\n= p e^{t}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-24",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-24",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nPortanto,\n\\[\nM_X'(t) = \\frac{p e^{t}}{\\left[1 - (1-p)e^{t}\\right]^2}\n\\]\nAvaliando em \\(t=0\\):\n\n\\(e^0=1\\)\n\\(1 - (1-p)e^{0} = 1-(1-p) = p\\)\n\nLogo,\n\\[E(X) = M_X'(0)\n= \\frac{p}{p^2}\n= \\frac{1}{p}\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-25",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-25",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nEncontrando \\(\\operatorname{Var}(X)\\), usamos,\n\\[\n\\operatorname{Var}(X) = M_X''(0) - \\Big[M_X'(0)\\Big]^2\n\\]\nA derivada segunda é dada por\n\\[\nM_X''(t)\n= \\frac{p e^{t}\\big[1+(1-p)e^{t}\\big]}{\\left[1-(1-p)e^{t}\\right]^3}\n\\]\nde forma que\n\\[M_X''(0)\n= \\frac{p(1+(1-p))}{p^3}\n= \\frac{p(2-p)}{p^3}\n= \\frac{2-p}{p^2}\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-26",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-26",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\ne, portanto,\n\\[\\operatorname{Var}(X)\n= M_X''(0) - \\Big[M_X'(0)\\Big]^2\n= \\frac{2-p}{p^2} - \\left(\\frac{1}{p}\\right)^2\n= \\frac{2-p-1}{p^2}\n= \\frac{1-p}{p^2}\\]\n\nVeja que neste exemplo, a função geradora de momentos de \\(X ∼ Geo(p)\\) não está definida para todo \\(t \\in \\mathbb{R}\\), mas está bem definida para \\(t &lt; \\ln\\Big(\\frac{1}{1-p}\\Big)\\). E como \\(\\ln\\Big(\\frac{1}{1-p}\\Big) &gt; 0\\), a função geradora de momentos está bem definida para \\(t\\) em uma vizinhança de zero."
  },
  {
    "objectID": "exercicios/lista02.html",
    "href": "exercicios/lista02.html",
    "title": "Distribuições Contínuas",
    "section": "",
    "text": "Data de entrega: 18 de dezembro de 2025\n\n\n\nEncontre os valores numéricos das integrais a seguir, sem resolver as integrais, usando apenas as propriedades da função gamma. Use o seguinte resultado: \\(\\Gamma(1/2) = \\sqrt{\\pi}\\).\n\n\n\\(\\int_{0}^{\\infty} x^{2} e^{-3x}\\,dx\\)\n\\(\\int_{0}^{\\infty} x^{4} e^{-x/5}\\,dx\\)\n\\(\\int_{0}^{\\infty} \\sqrt{x}\\, e^{-2x/3}\\,dx\\)\n\n\n\nSeja \\(X \\sim \\text{Gamma}\\Big(3,\\tfrac{1}{2}\\Big)\\).\n\n\nEncontre a função de distribuição de \\(X\\).\nVerifique se a derivada da função de distribuição encontrada no item (a) é a função densidade de \\(X\\).\n\n\n\nSegundo o protocolo do departamento de TI de uma empresa, um de seus sistemas passa por manutenção quando apresentar a 4ª falha, contada a partir da última manutenção. Considere que o tempo (em dias) entre duas manutenções consecutivas desse sistema seja uma variável aleatória com distribuição Gama, com média de 48 dias e desvio padrão de 24 dias.\n\n\nPara um sistema que acabou de sair da manutenção, qual é a probabilidade de ele funcionar pelos próximos 60 dias sem precisar de manutenção?\nDado que o sistema está funcionando há 40 dias desde a última manutenção, qual é a probabilidade de ele funcionar por mais 20 dias?\nSe 3 sistemas idênticos e independentes voltam a funcionar simultaneamente depois de uma manutenção, qual é a probabilidade de pelo menos 2 não passarem por manutenção nos próximos 60 dias?\n\n\n\nA seguir, são apresentadas algumas funções densidade de variáveis aleatórias com distribuição gamma de parâmetros \\(\\alpha\\) e \\(\\lambda\\). Para cada uma delas, determine os valores dos parâmetros.\n\n\n\\(f_X(x) = \\frac{8}{3}\\,x^{3} e^{-2x}, \\quad x &gt; 0\\)\n\\(f_X(x) = \\frac{1}{4}\\,x e^{-x/2}, \\quad x &gt; 0\\)\n\\(f_X(x) = \\sqrt{\\frac{3}{\\pi x}}\\,e^{-3x}, \\quad x &gt; 0\\)\n\n\n\nEncontre os valores numéricos para as expressões a seguir, onde \\(B\\) é a função Beta. Use novamente o seguinte resultado: \\(\\Gamma(1/2) = \\sqrt{\\pi}\\).\n\n\n\\(B(2,3)\\)\n\\(B(3,1)\\)\n\\(B\\!\\left(\\tfrac{1}{2}, 4\\right)\\)\n\\(B\\!\\left(\\tfrac{3}{2}, \\tfrac{1}{2}\\right)\\)\n\n\n\nSeja \\(X \\sim \\text{Beta}(2,3)\\).\n\n\nApresente a função densidade de \\(X\\).\nApresente a função de distribuição de \\(X\\).\nDetermine \\(E(X)\\).\nDetermine \\(\\operatorname{Var}(X)\\).\nCalcule \\(P\\!\\big(X \\geq E(X)\\big)\\) e \\(P\\!\\big(X &gt; E(X)\\,\\big|\\,X &lt; E(X) + DP(X)\\big)\\), onde \\(DP(X)\\) denota o desvio padrão de \\(X\\).\n\n\n\nUma fábrica produz misturas industrializadas para bolos. Sabe-se que a proporção de farinha de trigo em relação aos demais ingredientes secos nessa mistura é uma variável aleatória com distribuição Beta de parâmetros \\(\\alpha = 3/2\\) e \\(\\beta = 3\\). Após alguns testes, concluiu-se que:\n\n\nse a proporção de farinha de trigo for maior que 50%, o bolo fica muito seco;\n\nse essa proporção for menor que 10%, o bolo sola.\n\nNesses dois casos, o bolo não segue os padrões de qualidades estipulados pela fábrica.\n\nEm média, qual é a proporção de farinha de trigo para os demais ingredientes secos em uma mistura para bolo feita nessa fábrica?\nQual é a probabilidade de uma mistura para bolo produzida nessa fábrica não seguir os padrões de qualidade estipulados pela própria fábrica?\nSabendo que certa unidade de mistura não segue os padrões de qualidade estipulados pela fábrica, qual é a probabilidade de a proporção de farinha nesta unidade estar abaixo da média?\nEm um experimento, unidades dessa mistura para bolo são testadas até que se encontre 3 que não seguem os padrões de qualidade. Em média, nesse experimento, quantas unidades dentro do padrão de qualidade são testadas?\n\n\n\nA seguir, são apresentadas algumas funções densidade de variáveis aleatórias com distribuição Beta de parâmetros \\(a\\) e \\(b\\). Para cada uma delas, determine os valores dos parâmetros.\n\n\n\\(f_X(x) = 105 x^{2}(1 - x)^{4}, \\quad 0 &lt; x &lt; 1\\)\n\\(f_X(x) = 20\\big(x^{3} - x^{4}\\big), \\quad 0 &lt; x &lt; 1\\)\n\\(f_X(x) = \\frac{1}{2\\sqrt{x}}, \\quad 0 &lt; x &lt; 1\\)\n\n\n\nSeja \\(X \\sim \\text{Weibull}(2,2)\\).\n\n\nApresente a função densidade de \\(X\\).\nApresente a função de distribuição de \\(X\\).\nDetermine \\(E(X)\\).\nDetermine \\(\\operatorname{Var}(X)\\).\nCalcule \\(P(X &gt; 1)\\) e \\(P(X &gt; 1 \\mid X &lt; 2)\\).\n\n\n\nUma fábrica opera com 5 máquinas e a manutenção só é chamada quando 4 das 5 máquinas quebram. Suponha que o tempo, em dias, entre duas manutenções seja considerado uma variável aleatória com distribuição de Weibull de parâmetros \\(\\alpha = 0{,}5\\) e \\(\\beta = 4\\).\n\n\nQual o tempo médio entre duas manutenções seguidas?\nQual o desvio padrão do tempo entre duas manutenções seguidas?\nQual a probabilidade de a manutenção ficar mais de 10 dias sem aparecer na fábrica?\nSabendo que hoje completa 5 dias desde a última manutenção, qual a probabilidade de a próxima manutenção não ocorrer nos próximos 3 dias?\nQual o menor tempo \\(t\\), em dias, para o qual podemos dizer que, em 90% das vezes, a manutenção ocorre antes de \\(t\\)?\n\n\n\nA seguir são apresentadas algumas funções de densidade de variáveis aleatórias com distribuição de Weibull de parâmetros \\(\\alpha\\) e \\(\\beta\\). Para cada uma delas, determine os valores dos parâmetros.\n\n\n\\(f_X(x) = \\frac{3}{8} x^{2} e^{-x^{3}/8}, \\quad x &gt; 0\\)\n\\(f_X(x) = \\frac{1}{4\\sqrt{x}} e^{-\\sqrt{x}/2}, \\quad x &gt; 0\\)\n\\(f_X(x) = 18 x e^{-9x^{2}}, \\quad x &gt; 0\\)\n\n\n\nMostre que, para \\(\\alpha\\) e \\(\\beta\\) positivos, \\(f(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} (x - a)^{\\alpha - 1} e^{-\\beta(x-a)} I_{(a,\\infty)}(x)\\) é função densidade de probabilidade. Alguns autores definem o modelo Gamma dessa forma, sendo que, nesse caso, o modelo tem um terceiro parâmetro \\(a\\).\n\n\n\nA variável \\(X\\) segue o modelo Beta de parâmetros \\(a, b &gt; 0\\) se sua densidade for \\(f(x) = \\frac{1}{B(a, b)} x^{a -1} (1-x)^{b -1} I_{(0,1)}(x)\\). Verifique que a densidade Beta com parâmetros \\(a = b = 1\\) é a distribuição \\(U(0,1).\\)\n\n\n\nMostre que se \\(X \\sim Gamma(\\alpha, \\lambda)\\), então \\(E(X) = \\dfrac{\\alpha}{\\lambda}\\) e \\(\\operatorname{Var}(X) = \\dfrac{\\alpha}{\\lambda^2}\\).\n\n\n\nMostre que se \\(X \\sim Beta(a, b)\\), então \\(E(X) = \\dfrac{a}{a+b}\\) e \\(\\operatorname{Var}(X) = \\dfrac{ab}{(a+b+1)(a+b)^2}\\)\n\n\n\nMostre que se \\(X \\sim Weibull(\\alpha, \\beta)\\), então \\(E(X) = \\alpha \\Gamma\\left( \\dfrac{1}{\\beta} + 1\\right)\\) e \\(\\operatorname{Var}(X) = \\alpha^2\\left\\{\\Gamma\\left( \\dfrac{2}{\\beta} + 1\\right) - \\left[\\Gamma\\left( \\dfrac{1}{\\beta} + 1\\right)\\right]^2\\right\\}\\)"
  },
  {
    "objectID": "programacao/semana-9.html",
    "href": "programacao/semana-9.html",
    "title": "Semana 08",
    "section": "",
    "text": "Transformação de variáveis Aleatórias \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-9.html#slides",
    "href": "programacao/semana-9.html#slides",
    "title": "Semana 08",
    "section": "",
    "text": "Transformação de variáveis Aleatórias \n\n\nVer slides PDF"
  },
  {
    "objectID": "programacao/semana-9.html#entrega-lista-de-exercícios-02",
    "href": "programacao/semana-9.html#entrega-lista-de-exercícios-02",
    "title": "Semana 08",
    "section": "Entrega lista de exercícios 02",
    "text": "Entrega lista de exercícios 02\n\n\n\n\n\n\nFique Atento!\n\n\n\n Lista de exercícios 02\nEntrega na sala de aula!\n\nData de entrega:\n\n18 de dezembro de 2025"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-27",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-27",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 05: Distribuição de Poisson\n\n\nSeja \\(X \\sim Poisson(\\lambda)\\). Encontre sua função geradora de momentos e a partir dela, encontre \\(E(X)\\) e \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\nSolução: Seja \\(X \\sim Poisson(\\lambda)\\), cuja função de probabilidade é\n\\[\nP(X = k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}, \\quad k = 0,1,2,\\ldots\n\\]\nAssim, a função geradora de momentos (fgm) de \\(X\\) é dada por,\n\\[\nM_X(t) = \\sum_{k=0}^\\infty e^{tk}\\,\\frac{e^{-\\lambda}\\lambda^k}{k!}\n       = e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{(\\lambda e^t)^k}{k!}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-28",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-28",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nA série\n\\[\n\\sum_{k=0}^\\infty \\frac{(\\lambda e^t)^k}{k!}\n\\]\né a expansão em série de Taylor de \\(e^{\\lambda e^t}\\). Assim,\n\\[\nM_X(t) = e^{-\\lambda} e^{\\lambda e^t}\n       = \\exp\\{\\lambda(e^t - 1)\\}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-29",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-29",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nPortanto, a fgm de \\(X\\) é \\[\n\\boxed{M_X(t) = \\exp\\big(\\lambda(e^t - 1)\\big)}\n\\]\nNote que, pela Tip 1, \\(M_X(0) = \\exp\\big(\\lambda(e^0 - 1)\\big) = \\exp\\big(0\\big) =  1\\)\n\nVamos calcular as derivadas de ordem primeira e ordem segunda para calcular os respectivos momentos:\nPela regra da cadeia,\n\\[\nM_X'(t) = \\exp\\big(\\lambda(e^t - 1)\\big)\\cdot \\lambda e^t\n        = \\lambda e^t\\, M_X(t)\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-30",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-30",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nLogo,\n\\[\nE(X) = M_X'(0) = \\lambda e^0\\, M_X(0) = \\lambda \\cdot 1 \\cdot 1 = \\lambda\n\\]\n\nA segunda derivada de \\(M_X(t)\\) é dada por:\n\\[\n\\begin{aligned}\nM_X''(t)\n&= \\frac{d}{dt}\\big[\\lambda e^t\\, M_X(t)\\big] \\\\\n&= \\lambda e^t\\, M_X(t) + \\lambda e^t\\, M_X'(t) \\\\\n&= \\lambda e^t\\, M_X(t) + \\lambda e^t\\,[\\lambda e^t\\, M_X(t)] \\\\\n&= \\lambda e^t\\, M_X(t)\\,\\big[1 + \\lambda e^t\\big]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-31",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-31",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAgora, avaliando em \\(t=0\\):\n\\[\n\\begin{aligned}\nM_X''(0) = \\lambda e^0\\, M_X(0)\\,\\big[1 + \\lambda e^0\\big] = \\lambda \\cdot 1 \\cdot 1 \\cdot (1+\\lambda) = \\lambda(1+\\lambda)\n\\end{aligned}\n\\]\nPortanto,\n\\[\nE(X^2) = M_X''(0) = \\lambda(1+\\lambda)\n\\]\nAssim,\n\\[\n\\begin{aligned}\n\\text{Var}(X)\n&= M_X''(0) - \\Big[M_X'(0)\\Big]^2 \\\\\n&= \\lambda(1+\\lambda) - \\lambda^2 \\\\\n&= \\lambda\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-32",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-32",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 06: Distribuição Exponencial\n\n\nSeja \\(X \\sim exp(\\lambda)\\). Encontre sua função geradora de momentos e a partir dela, encontre \\(E(X)\\) e \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\nSolução: Seja \\(X \\sim exp(\\lambda)\\), cuja função densidade é\n\\[\nf(x) = \\lambda e^{-\\lambda x}, \\quad x &gt; 0\n\\]\nNeste caso, a função geradora de momentos (fgm) de \\(X\\) é definida por \\[\nM_X(t) = E(e^{tX}) = \\int_0^\\infty e^{tx}\\,\\lambda e^{-\\lambda x}\\,dx = \\int_0^\\infty \\lambda e^{-(\\lambda - t)x} \\, dx\n\\]\nválida para \\(t &lt; \\lambda\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-33",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-33",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nAssim, como\n\\[\n\\int_0^\\infty \\lambda e^{-(\\lambda - t)x} =  \\lambda \\frac{e^{-(\\lambda - t)x}}{-(\\lambda - t)} \\Bigg|_0^{\\infty} = \\frac{\\lambda}{\\lambda - t}, \\,\\,\\,\\, \\lambda - t &gt; 0\n\\]\nLogo,\n\\[\n\\boxed{M_X(t) = \\frac{\\lambda}{\\lambda - t}, \\qquad t &lt; \\lambda}\n\\]\nNote que, pela Tip 1, $ M_X(0) = = 1$"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-34",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-34",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nDerivando,\n\\[\nM_X'(t) = \\frac{\\lambda}{(\\lambda - t)^2}\n\\]\nPortanto,\n\\[\nE(X) = M_X'(0) = \\frac{\\lambda}{\\lambda^2} = \\frac{1}{\\lambda}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-35",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-35",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nA segunda derivada é dada por,\n\\[\nM_X''(t) = \\frac{2\\lambda}{(\\lambda - t)^3}\n\\]\nLogo,\n\\[\nE(X^2) = M_X''(0) = \\frac{2\\lambda}{\\lambda^3} = \\frac{2}{\\lambda^2}\n\\]\nDe forma que,\n\\[\n\\text{Var}(X)\n= E(X^2) - \\Big[E(X) \\Big]^2\n= \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2}\n= \\frac{1}{\\lambda^2}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-36",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-36",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 07: Distribuição Gamma\n\n\nSeja \\(X \\sim Gamma(\\alpha, \\lambda)\\). Encontre sua função geradora de momentos.\n\n\n\n\n\nSolução: Seja \\(X \\sim Gamma(\\alpha, \\lambda)\\), cuja função densidade é\n\\[\nf(x) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\lambda x},\n\\qquad x&gt;0\n\\]\nA função geradora de momentos é\n\\[\nM_X(t)\n= \\int_0^\\infty e^{tx}\n\\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\lambda x}\\,dx\n= \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}\n\\int_0^\\infty x^{\\alpha-1}e^{-(\\lambda - t)x}\\,dx\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-37",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-37",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nUsamos agora o resultado da função Gamma:\n\\[\n\\int_0^\\infty x^{\\alpha-1}e^{-bx}\\,dx\n= \\frac{\\Gamma(\\alpha)}{b^\\alpha}, \\qquad b&gt;0\n\\]\nAqui, \\(b = \\lambda - t\\) (precisamos de \\(\\lambda - t &gt; 0\\), isto é, \\(t&lt;\\lambda\\)). Logo,\n\\[\n\\int_0^\\infty x^{\\alpha-1}e^{-(\\lambda - t)x}\\,dx\n= \\frac{\\Gamma(\\alpha)}{(\\lambda - t)^\\alpha}\n\\]\nPortanto,\n\\[\nM_X(t)\n= \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}\n\\cdot\n\\frac{\\Gamma(\\alpha)}{(\\lambda - t)^\\alpha}\n= \\left(\\frac{\\lambda}{\\lambda - t}\\right)^\\alpha,\n\\qquad t&lt;\\lambda\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-38",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-38",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 07: Distribuição Normal Padrão\n\n\nSeja \\(X \\sim N(0, 1)\\). Encontre sua função geradora de momentos.\n\n\n\n\n\nSolução: Seja \\(X \\sim N(0, 1)\\), cuja função densidade é\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}, \\qquad x \\in \\mathbb{R}\n\\]\nQueremos encontrar a função geradora de momentos (fgm) dada por\n\\[\nM_X(t)\n= \\int_{-\\infty}^{\\infty} e^{tx}\\,\\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\\,dx\n= \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}\n\\exp\\Big(tx - \\frac{x^2}{2}\\Big)\\,dx\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-39",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-39",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nVamos usar a técnica de completar quadrados no expoente, \\[\n\\begin{aligned}\ntx - \\frac{x^2}{2}\n&= -\\frac{1}{2}\\big(x^2 - 2tx\\big) = -\\frac{1}{2}\\big(x^2 - 2tx + t^2 - t^2\\big) \\\\\n&= -\\frac{1}{2}\\big[(x - t)^2 - t^2\\big] = -\\frac{(x - t)^2}{2} + \\frac{t^2}{2}\n\\end{aligned}\n\\]\nAssim,\n\\[\\small\nM_X(t)\n= \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}\n\\exp\\!\\left(-\\frac{(x - t)^2}{2} + \\frac{t^2}{2}\\right)\\,dx\n= \\exp\\!\\left(\\frac{t^2}{2}\\right)\n\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}\n\\exp\\!\\left(-\\frac{(x - t)^2}{2}\\right)\\,dx\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-40",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-40",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nA integral\n\\[\n\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}\n\\exp\\!\\left(-\\frac{(x - t)^2}{2}\\right)\\,dx\n\\] é a área total sob a curva de uma normal \\(N(t,1)\\), e portanto é igual a \\(1\\).\nLogo, \\[\n\\boxed{M_X(t) = \\exp\\!\\left(\\frac{t^2}{2}\\right), \\qquad t \\in \\mathbb{R}}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-41",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-41",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nProposição 01: Transformações Lineares\n\n\nSeja \\(X\\) uma variável aleatória com função geradora de momentos \\(M_X\\). Seja \\(Y = aX + b\\). Então, a função geradora de momentos de \\(Y\\) é dada por\n\\[M_Y(t) = e^{bt} M_X(at)\\]\n\n\n\n\n\nDemonstração:\n\\[M_Y(t) = E(e^{tY}) = E(e^{t(aX+b)}) = E\\Big(e^{atX} e^{bt} \\Big) = e^{bt} E\\Big(e^{atX}\\Big) =  e^{bt} M_X(at)\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-42",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-42",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 07: Distribuição Normal Padrão\n\n\nSeja \\(X \\sim N(\\mu, \\sigma^2)\\). Encontre sua função geradora de momentos.\n\n\n\n\n\nSolução: Se \\(X \\sim N(\\mu, \\sigma^2)\\), então \\(X = \\sigma Z + \\mu\\), em que \\(Z\\sim N(0,1)\\), com função geradora de momentos dada por \\(M_X(t) = \\exp\\!\\left(\\frac{t^2}{2}\\right)\\). Assim,\n\\[M_X(t) = e^{\\mu t} M_X(\\sigma t) = e^{\\mu t} \\exp\\!\\left(\\frac{(\\sigma t)^2}{2}\\right) = e^{\\mu t} \\exp\\!\\left(\\frac{\\sigma^2 t^2}{2}\\right)\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-43",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-43",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nLogo,\nSe \\(X \\sim N(\\mu, \\sigma^2)\\), então\n\\[\\boxed{M_X(t)= \\exp \\Bigg(\\mu t + \\frac{\\sigma^2 t^2}{2} \\Bigg)}\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-44",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-44",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nTeorema 02\n\n\nSe duas variáveis aleatórias têm funções geradoras de momentos que existem, e são iguais, então elas têm a mesma função de distribuição.\n\n\n\n\n\nA demonstração desse Teorema será omitida, pois ela usa conceitos não estudados neste curso. Veja que o Teorema 02 nos mostra que se duas variáveis aleatórias tem mesma função geradora de momentos então estas variáveis aleatórias são identicamente distribuídas.\nIsso significa que podemos identificar a distribuição de uma variável aleatória a partir da sua função geradora de momentos, assim como identificamos a distribuição da variável aleatória a partir da sua função de distribuição, função densidade ou função de probabilidade."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-45",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-45",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 08\n\n\nSeja \\(X \\sim Gamma(\\alpha, \\lambda)\\). Considere também \\(Y = cX,\\,\\, c\\in \\mathbb{R}\\). Mostre, a partir da função geradora de momentos, que \\(Y \\sim Gamma(\\alpha, \\lambda/c)\\).\n\n\n\n\n\nSolução: Por definição,\n\\[\nM_Y(t) = E(e^{tY}) = E(e^{t(cX)}) = E(e^{(ct)X})\n\\]\nLogo,\n\\[\nM_Y(t) = M_X(ct) = \\left(\\frac{\\lambda}{\\lambda - ct}\\right)^{\\alpha},\n\\qquad ct &lt; \\lambda \\;\\; \\Rightarrow \\;\\; t &lt; \\frac{\\lambda}{c}\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-46",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-46",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nou seja,\n\\[\nM_Y(t)\n= \\left(\\frac{\\lambda}{\\lambda - ct}\\right)^{\\alpha}\n= \\left(\\frac{\\lambda/c}{(\\lambda/c) - t}\\right)^{\\alpha},\n\\qquad t &lt; \\frac{\\lambda}{c}.\n\\]\nVeja que trata-se da função geradora de momentos de uma variável aleatória com distribuição \\(Gamma(\\alpha,\\lambda/c)\\). Logo, \\(Y \\sim Gamma(\\alpha,\\lambda/c)\\)."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-característica",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-característica",
    "title": "Função Geradora de Momentos",
    "section": "Função Característica",
    "text": "Função Característica\nA função característica é uma das ferramentas mais importantes da Teoria das Probabilidades.\n\nEla desempenha um papel similar ao da função geradora de momentos (fgm), mas com vantagens significativas: sempre existe, determina unicamente a distribuição e facilita o estudo de somas de variáveis aleatórias."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-47",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-47",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nTeorema 03: Soma de variáveis independentes\n\n\nSejam \\(X_1, X_2, \\cdots, X_n\\) variáveis aleatórias independentes e funções geradoras de momentos, respectivamente, iguais a \\(M_{X_j}(t), \\,\\, j = 1, 2, \\cdots, n\\) para \\(t\\) em alguma vizinhança de zero. Se \\(Y = X_1 + X_2 + \\cdots + X_n\\), então a função geradora de momentos de \\(Y\\) existe e é dada por:\n\\[M_Y(t) =  \\prod_{j = 1}^n M_{X_j}(t)\\]\n\n\n\n\n\nDemonstração: Pela definição, temos\n\\[\n\\begin{aligned}\nM_Y(t) &= E(e^{t(X_1 + X_2 + \\cdots + X_n)}) \\\\ &= E(e^{tX_1}e^{tX_2} \\cdots e^{tX_n}) \\\\ &= E(e^{tX_1})E(e^{tX_2})\\cdots E(e^{tX_n})\n\\end{aligned}\n\\] e daí segue o resultado desejado."
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-48",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-48",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\n\n\n\n\n\n\n\nExemplo 09\n\n\nSejam \\(X_1, X_2, \\cdots, X_n\\) variáveis aleatórias independentes com distribuição Bernoulli de parâmetro \\(p\\). Se \\(Y = X_1 + X_2 + \\cdots + X_n\\), mostre, a partir da função geradora de momentos, que \\(Y =  \\sim Binomial(n,p)\\).\n\n\n\n\n\nSolução: Temos que se \\(X_1, X_2, \\cdots, X_n\\) são variáveis aleatórias independentes com distribuição Bernoulli de parâmetro \\(p\\), então\n\\[\nM_{X_j}(t) = 1 - p + p e^{t}, \\quad j = 1,2, \\cdots n\n\\]"
  },
  {
    "objectID": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-49",
    "href": "aulas/func_geradora_momentos/func_gera_momentos.html#função-geradora-de-momentos-49",
    "title": "Função Geradora de Momentos",
    "section": "Função Geradora de Momentos",
    "text": "Função Geradora de Momentos\nEntão, pelo Teorema 03, temos\n\\[\nM_Y(t) = \\prod_{j = 1}^n M_{X_j}(t) = \\big(1 - p + p e^{t}\\big)^n\n\\]\nque corresponde à função geradora de momentos de uma variável aleatória Binomial com parâmetros \\(n\\) e \\(p\\). Logo, temos que \\(X_1 + X_2 + \\cdots + X_n \\sim Binomial(n,p)\\)."
  }
]